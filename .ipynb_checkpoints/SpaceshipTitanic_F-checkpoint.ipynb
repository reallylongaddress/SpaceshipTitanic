{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7aec626f-e152-4bbe-a281-54f45fb0cd8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./kaggle/input/spaceship-titanic/neural_network_pred.csv\n",
      "./kaggle/input/spaceship-titanic/best_model_pred.csv\n",
      "./kaggle/input/spaceship-titanic/.DS_Store\n",
      "./kaggle/input/spaceship-titanic/test.csv\n",
      "./kaggle/input/spaceship-titanic/submission.csv\n",
      "./kaggle/input/spaceship-titanic/spaceship-titanic.zip\n",
      "./kaggle/input/spaceship-titanic/train.csv\n",
      "./kaggle/input/spaceship-titanic/sample_submission.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('./kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae302d34-1c96-41b0-add5-f109f3761357",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0aa46b00-90dc-47a6-a027-5064983cf3eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dbd/opt/miniconda3/lib/python3.8/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "from sklearn import set_config\n",
    "set_config(transform_output=\"pandas\")\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15cad526-93e5-4207-902e-6968444783f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Name</th>\n",
       "      <th>Transported</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>B/0/P</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>39.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Maham Ofracculy</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>24.0</td>\n",
       "      <td>False</td>\n",
       "      <td>109.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>Juanna Vines</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0003_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>58.0</td>\n",
       "      <td>True</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3576.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6715.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>Altark Susent</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0003_02</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>33.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>3329.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>Solam Susent</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0004_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/1/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>16.0</td>\n",
       "      <td>False</td>\n",
       "      <td>303.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Willy Santantines</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8688</th>\n",
       "      <td>9276_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/98/P</td>\n",
       "      <td>55 Cancri e</td>\n",
       "      <td>41.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6819.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1643.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>Gravior Noxnuther</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8689</th>\n",
       "      <td>9278_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>True</td>\n",
       "      <td>G/1499/S</td>\n",
       "      <td>PSO J318.5-22</td>\n",
       "      <td>18.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Kurta Mondalley</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8690</th>\n",
       "      <td>9279_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>G/1500/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>26.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1872.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Fayey Connon</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8691</th>\n",
       "      <td>9280_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>E/608/S</td>\n",
       "      <td>55 Cancri e</td>\n",
       "      <td>32.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1049.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>353.0</td>\n",
       "      <td>3235.0</td>\n",
       "      <td>Celeon Hontichre</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8692</th>\n",
       "      <td>9280_02</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>E/608/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>44.0</td>\n",
       "      <td>False</td>\n",
       "      <td>126.0</td>\n",
       "      <td>4688.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Propsh Hontichre</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8693 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId HomePlanet CryoSleep     Cabin    Destination   Age    VIP  \\\n",
       "0        0001_01     Europa     False     B/0/P    TRAPPIST-1e  39.0  False   \n",
       "1        0002_01      Earth     False     F/0/S    TRAPPIST-1e  24.0  False   \n",
       "2        0003_01     Europa     False     A/0/S    TRAPPIST-1e  58.0   True   \n",
       "3        0003_02     Europa     False     A/0/S    TRAPPIST-1e  33.0  False   \n",
       "4        0004_01      Earth     False     F/1/S    TRAPPIST-1e  16.0  False   \n",
       "...          ...        ...       ...       ...            ...   ...    ...   \n",
       "8688     9276_01     Europa     False    A/98/P    55 Cancri e  41.0   True   \n",
       "8689     9278_01      Earth      True  G/1499/S  PSO J318.5-22  18.0  False   \n",
       "8690     9279_01      Earth     False  G/1500/S    TRAPPIST-1e  26.0  False   \n",
       "8691     9280_01     Europa     False   E/608/S    55 Cancri e  32.0  False   \n",
       "8692     9280_02     Europa     False   E/608/S    TRAPPIST-1e  44.0  False   \n",
       "\n",
       "      RoomService  FoodCourt  ShoppingMall     Spa  VRDeck               Name  \\\n",
       "0             0.0        0.0           0.0     0.0     0.0    Maham Ofracculy   \n",
       "1           109.0        9.0          25.0   549.0    44.0       Juanna Vines   \n",
       "2            43.0     3576.0           0.0  6715.0    49.0      Altark Susent   \n",
       "3             0.0     1283.0         371.0  3329.0   193.0       Solam Susent   \n",
       "4           303.0       70.0         151.0   565.0     2.0  Willy Santantines   \n",
       "...           ...        ...           ...     ...     ...                ...   \n",
       "8688          0.0     6819.0           0.0  1643.0    74.0  Gravior Noxnuther   \n",
       "8689          0.0        0.0           0.0     0.0     0.0    Kurta Mondalley   \n",
       "8690          0.0        0.0        1872.0     1.0     0.0       Fayey Connon   \n",
       "8691          0.0     1049.0           0.0   353.0  3235.0   Celeon Hontichre   \n",
       "8692        126.0     4688.0           0.0     0.0    12.0   Propsh Hontichre   \n",
       "\n",
       "      Transported  \n",
       "0           False  \n",
       "1            True  \n",
       "2           False  \n",
       "3           False  \n",
       "4            True  \n",
       "...           ...  \n",
       "8688        False  \n",
       "8689        False  \n",
       "8690         True  \n",
       "8691        False  \n",
       "8692         True  \n",
       "\n",
       "[8693 rows x 14 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('./kaggle/input/spaceship-titanic/train.csv')\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d613db09-c51d-48f8-a692-476ea8bca9d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0013_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>True</td>\n",
       "      <td>G/3/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>27.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Nelly Carsoning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0018_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/4/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>19.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2823.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Lerome Peckers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0019_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>True</td>\n",
       "      <td>C/0/S</td>\n",
       "      <td>55 Cancri e</td>\n",
       "      <td>31.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Sabih Unhearfus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0021_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>C/1/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>38.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6652.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>585.0</td>\n",
       "      <td>Meratz Caltilter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0023_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/5/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>20.0</td>\n",
       "      <td>False</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>635.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Brence Harperez</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  PassengerId HomePlanet CryoSleep  Cabin  Destination   Age    VIP  \\\n",
       "0     0013_01      Earth      True  G/3/S  TRAPPIST-1e  27.0  False   \n",
       "1     0018_01      Earth     False  F/4/S  TRAPPIST-1e  19.0  False   \n",
       "2     0019_01     Europa      True  C/0/S  55 Cancri e  31.0  False   \n",
       "3     0021_01     Europa     False  C/1/S  TRAPPIST-1e  38.0  False   \n",
       "4     0023_01      Earth     False  F/5/S  TRAPPIST-1e  20.0  False   \n",
       "\n",
       "   RoomService  FoodCourt  ShoppingMall     Spa  VRDeck              Name  \n",
       "0          0.0        0.0           0.0     0.0     0.0   Nelly Carsoning  \n",
       "1          0.0        9.0           0.0  2823.0     0.0    Lerome Peckers  \n",
       "2          0.0        0.0           0.0     0.0     0.0   Sabih Unhearfus  \n",
       "3          0.0     6652.0           0.0   181.0   585.0  Meratz Caltilter  \n",
       "4         10.0        0.0         635.0     0.0     0.0   Brence Harperez  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv('./kaggle/input/spaceship-titanic/test.csv')\n",
    "test_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54b7ede0-e3a9-4ad2-b829-231b7566619f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "PassengerId      object\n",
    "HomePlanet       object\n",
    "CryoSleep        object\n",
    "Cabin            object\n",
    "Destination      object\n",
    "Age             float64\n",
    "VIP              object\n",
    "RoomService     float64\n",
    "FoodCourt       float64\n",
    "ShoppingMall    float64\n",
    "Spa             float64\n",
    "VRDeck          float64\n",
    "Name             object\n",
    "Transported        bool\n",
    "\n",
    "X\n",
    "HomePlanet       object -> categorical (OH), how to fill? (null: 201)\n",
    "CryoSleep        object -> bool, fill most common or False/0? (null: 217)\n",
    "Destination      object -> categorical (OH), how to fill (null: )\n",
    "Age             float64 -> int(8), fill mean (null: 179)\n",
    "VIP              object -> bool, fill False (if not listed as VIP assume not VIP) (null: 203)\n",
    "\n",
    "For these, check to see if 0 is most common, then fill most common.  \n",
    "Assuming if there's no record of money being spent at an attraction, no money was spent there.\n",
    "\n",
    "DBD ZERO FILL\n",
    "RoomService     float64 -> float64 (null: 181)\n",
    "FoodCourt       float64(null: 183)\n",
    "ShoppingMall    float64(null: 208)\n",
    "Spa             float64(null: 183)\n",
    "VRDeck          float64(null: 188)\n",
    "\n",
    "\n",
    "Y\n",
    "Transported        bool (null: 0)\n",
    "\n",
    "DROP\n",
    "\n",
    "\n",
    "BEFORE DROPPING - check to see how many other fields are null when name is null.\n",
    "If high number, maybe best to drop all where name==null\n",
    "** Very low number.  \n",
    "DBD DROP NAME\n",
    "Name             object (null: 200)\n",
    "\n",
    "UNSURE\n",
    "--BREAK APART string into components to see if there's any interesting information hidden in there....\n",
    "Cabin            object (unique 6561, total 8693)(null: 199)\n",
    "PassengerId      object (null: 0)\n",
    "''';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f52b7db-8a38-47e1-acbd-910601523cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RoomService     float64\n",
    "# FoodCourt       float64\n",
    "# ShoppingMall    float64\n",
    "# Spa             float64\n",
    "# VRDeck          float64\n",
    "\n",
    "#DBD DO ZERO FILL\n",
    "# shopping_features = ['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']\n",
    "\n",
    "# for feature in shopping_features:\n",
    "#     print(f'----{feature}-----')\n",
    "#     display(train_df[feature].value_counts().head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9517ac1b-87c5-4b2b-9e30-2b622212b57e",
   "metadata": {},
   "source": [
    "# Build a preprocessing processing pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac1d9a79-f38d-48a7-a1fe-d3ff0f25c5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class parsePassengerId(BaseEstimator, TransformerMixin):\n",
    "\n",
    "  def __init__(self):\n",
    "    pass\n",
    "\n",
    "  def transform(self,X,y=None):\n",
    "        \n",
    "    X_temp = X.copy()\n",
    "\n",
    "    passenger_id_A = ''\n",
    "    passenger_id_B = ''\n",
    "\n",
    "    traveling_in_group = []\n",
    "    \n",
    "    for index, row in X_temp.iterrows():\n",
    "        #break into parts to see what's relevant\n",
    "        '''\n",
    "        PassengerId - A unique Id for each passenger. Each Id takes the form gggg_pp where gggg \n",
    "        indicates a group the passenger is travelling with and pp is their number within the group. \n",
    "        People in a group are often family members, but not always.\n",
    "        '''\n",
    "        passenger_parts = row[\"PassengerId\"].split('_')\n",
    "\n",
    "        passenger_id_A = passenger_parts[0]\n",
    "        passenger_id_B = passenger_parts[1]\n",
    "\n",
    "        X_temp.at[index, 'PassengerId_A'] = passenger_id_A\n",
    "        X_temp.at[index, 'PassengerId_B'] = passenger_id_B\n",
    "        \n",
    "        #is this person traveling in a group?\n",
    "        if int(passenger_id_B) > 1:\n",
    "            traveling_in_group.append(passenger_id_A)\n",
    "            \n",
    "    #remove duplicates\n",
    "    traveling_in_group = [*set(traveling_in_group)]\n",
    "\n",
    "    #append new feature\n",
    "    X_temp['traveling_in_group'] = 0\n",
    "    #set feature flag\n",
    "    for group_id in traveling_in_group:\n",
    "        X_temp.loc[X_temp['PassengerId_A'] == group_id, 'traveling_in_group'] = 1\n",
    "    \n",
    "    self.columns = X_temp.columns\n",
    "    \n",
    "    return X_temp\n",
    "\n",
    "  def fit(self, X, y=None):\n",
    "    self.columns = X.columns\n",
    "    # print(f'parsePassengerId: {len(self.columns)}')\n",
    "    return self   \n",
    "\n",
    "  def get_feature_names_out(self, arg):\n",
    "    return self.columns\n",
    "\n",
    "##---------------------\n",
    "\n",
    "class parseAndImputeCabins(BaseEstimator, TransformerMixin):\n",
    "\n",
    "  def __init__(self):\n",
    "    pass\n",
    "\n",
    "  def transform(self,X,y=None):\n",
    "\n",
    "    X_temp = X.copy()\n",
    "\n",
    "    #parse the cabin into 3 parts\n",
    "    for index, row in X_temp.iterrows():\n",
    "        cabin_A = np.nan\n",
    "        cabin_B = np.nan\n",
    "        cabin_C = np.nan\n",
    "\n",
    "        if (row[\"Cabin\"] is not np.nan) and (len(row[\"Cabin\"].split('/')) == 3):\n",
    "            #break into parts to see what's relevant\n",
    "            '''\n",
    "            Cabin - The cabin number where the passenger is staying. Takes the form deck/num/side, \n",
    "            where side can be either P for Port or S for Starboard.\n",
    "            '''\n",
    "            cabin_parts = row[\"Cabin\"].split('/')\n",
    "\n",
    "            cabin_A = cabin_parts[0]\n",
    "            cabin_B = cabin_parts[1]\n",
    "            cabin_C = cabin_parts[2]\n",
    "            \n",
    "        X_temp.at[index, 'Cabin_A'] = cabin_A\n",
    "        X_temp.at[index, 'Cabin_B'] = cabin_B\n",
    "        X_temp.at[index, 'Cabin_C'] = cabin_C\n",
    "    \n",
    "    #impute the cabin parts\n",
    "    cabin_mf_imputer = SimpleImputer(strategy='most_frequent', missing_values=np.nan)\n",
    "    X_temp[['Cabin_A', 'Cabin_C']] = cabin_mf_imputer.fit_transform(X_temp[['Cabin_A', 'Cabin_C']])\n",
    "    \n",
    "    cabin_mean_imputer = SimpleImputer(strategy='mean', missing_values=np.nan)\n",
    "    X_temp[['Cabin_B']] = cabin_mean_imputer.fit_transform(X_temp[['Cabin_B']])\n",
    "    X_temp['Cabin_B'] = X_temp['Cabin_B'].astype(int)\n",
    "        \n",
    "    self.columns = X_temp.columns\n",
    "\n",
    "    return X_temp\n",
    "    \n",
    "  def fit(self, X, y=None):\n",
    "    self.columns = X.columns\n",
    "    # print(f'parseAndImputeCabins: {len(self.columns)}')\n",
    "    return self   \n",
    "\n",
    "  def get_feature_names_out(self, arg):\n",
    "    return self.columns\n",
    "\n",
    "\n",
    "##---------------------\n",
    "\n",
    "class planetImputerEncoder(BaseEstimator, TransformerMixin):\n",
    "\n",
    "  def __init__(self):\n",
    "    pass\n",
    "\n",
    "  def transform(self,X,y=None):\n",
    "    \n",
    "    X_temp = X.copy()\n",
    "\n",
    "    imputer = SimpleImputer(strategy='most_frequent')\n",
    "    \n",
    "    imputer = imputer.fit(X_temp[['HomePlanet']])\n",
    "    X_temp['HomePlanet'] = imputer.transform(X_temp[['HomePlanet']])\n",
    "    \n",
    "    imputer = imputer.fit(X_temp[['Destination']])\n",
    "    X_temp['Destination'] = imputer.transform(X_temp[['Destination']])\n",
    "    \n",
    "    self.columns = X_temp.columns\n",
    "    \n",
    "    return X_temp\n",
    "    \n",
    "  def fit(self, X, y=None):\n",
    "    self.columns = X.columns\n",
    "    # print(f'planetImputerEncoder: {len(self.columns)}')\n",
    "    return self   \n",
    "\n",
    "  def get_feature_names_out(self, arg):\n",
    "    return self.columns\n",
    "\n",
    "##---------------------\n",
    "\n",
    "class cryoVIPEncoder(BaseEstimator, TransformerMixin):\n",
    "\n",
    "  def __init__(self):\n",
    "    pass\n",
    "\n",
    "  def transform(self,X,y=None):\n",
    "    \n",
    "    X_temp = X.copy()\n",
    "    \n",
    "    #impute with most frequent (True/False) then convert to (1/0)\n",
    "    imputer = SimpleImputer(strategy='most_frequent')\n",
    "\n",
    "    imputer = imputer.fit(X_temp[['CryoSleep']])\n",
    "    X_temp['CryoSleep'] = imputer.transform(X_temp[['CryoSleep']])\n",
    "    X_temp['CryoSleep_bool'] = X_temp['CryoSleep'].map({True:1, False:0})\n",
    "    \n",
    "    \n",
    "    imputer = imputer.fit(X_temp[['VIP']])\n",
    "    X_temp['VIP'] = imputer.transform(X_temp[['VIP']])\n",
    "    X_temp['VIP_bool'] = X_temp['VIP'].map({True:1, False:0})\n",
    "    \n",
    "    self.columns = X_temp.columns\n",
    "    \n",
    "    return X_temp\n",
    "    \n",
    "  def fit(self, X, y=None):\n",
    "    self.columns = X.columns\n",
    "    # print(f'cryoVIPEncoder: {len(self.columns)}')\n",
    "    return self   \n",
    "\n",
    "  def get_feature_names_out(self, arg):\n",
    "    return self.columns\n",
    "\n",
    "##---------------------\n",
    "\n",
    "class TrueFalseEncoder(BaseEstimator, TransformerMixin):\n",
    "\n",
    "  def __init__(self):\n",
    "    pass\n",
    "\n",
    "  def transform(self,X,y=None):\n",
    "\n",
    "    X_temp = X.copy()\n",
    "        \n",
    "    for column in X.columns:\n",
    "        X_temp[f'{column}_bool'] = X_temp[column].map({True:1, False:0})\n",
    "        \n",
    "    self.columns = X_temp.columns\n",
    "    \n",
    "    return X_temp\n",
    "\n",
    "  def fit(self, X, y=None):\n",
    "    self.columns = X.columns\n",
    "    # print(f'TrueFalseEncoder: {len(self.columns)}')\n",
    "    return self   \n",
    "\n",
    "  def get_feature_names_out(self, arg):\n",
    "    return self.columns\n",
    "\n",
    "##---------------------\n",
    "\n",
    "class columnDropperTransformer(BaseEstimator, TransformerMixin):\n",
    "\n",
    "  def __init__(self,drop_columns):\n",
    "    # print(f'columnDropperTransformer a')\n",
    "    self.drop_columns = drop_columns\n",
    "    self.columns = None\n",
    "\n",
    "  def transform(self,X,y=None):\n",
    "    # print(f'columnDropperTransformer b')\n",
    "\n",
    "    X_temp = X.copy().drop(columns=self.drop_columns, axis=1)\n",
    "    self.columns = X_temp.columns\n",
    "    \n",
    "    return X_temp\n",
    "\n",
    "  def fit(self, X, y=None):\n",
    "    # print(f'columnDropperTransformer c')\n",
    "    self.columns = X.columns\n",
    "    # print(f'columnDropperTransformer: {len(self.columns)}')\n",
    "    return self \n",
    "\n",
    "  def get_feature_names_out(self, arg):\n",
    "    # print(f'columnDropperTransformer d')\n",
    "\n",
    "    return self.columns\n",
    "##---------------------\n",
    "\n",
    "class oneHotEncoderWrapper(BaseEstimator, TransformerMixin):\n",
    "\n",
    "  def __init__(self):\n",
    "    # print(f'------------oneHotEncoderWrapper init')    \n",
    "    self.ohe = None\n",
    "\n",
    "  def transform(self,X,y=None):\n",
    "    \n",
    "    X_trans = pd.DataFrame(self.ohe.transform(X), columns=self.ohe_columns)    \n",
    "    return X_trans\n",
    "\n",
    "  def fit(self, X, y=None):\n",
    "        \n",
    "    # self.original_columns = X.columns\n",
    "    \n",
    "    if self.ohe is None:\n",
    "        self.ohe = OneHotEncoder(sparse_output=False, handle_unknown='ignore')        \n",
    "    self.ohe = self.ohe.fit(X)\n",
    "\n",
    "    self.ohe_columns = self.ohe.get_feature_names_out()\n",
    "    return self \n",
    "\n",
    "  def get_feature_names_out(self, arg):\n",
    "    return self.ohe_columns\n",
    "\n",
    "\n",
    "##---------------------\n",
    "\n",
    "# class scalerWrapperTransfromer(BaseEstimator, TransformerMixin):\n",
    "\n",
    "#   def __init__(self):\n",
    "#     pass\n",
    "\n",
    "#   def transform(self,X,y=None):\n",
    "    \n",
    "#     X_temp = X.copy()\n",
    "    \n",
    "#     #scale all columns except target\n",
    "#     X_temp[self.scale_features] = self.scaler.transform(X_temp[self.scale_features])\n",
    "\n",
    "#     self.columns = X_temp.columns\n",
    "    \n",
    "#     return X_temp\n",
    "\n",
    "#   def fit(self, X, y=None):\n",
    "        \n",
    "#     #don't scale the target\n",
    "#     self.scale_features = X.columns.difference(['Transported_bool'])\n",
    "#     self.scaler = StandardScaler().fit(X[self.scale_features], y)\n",
    "    \n",
    "#     self.columns = X.columns\n",
    "    \n",
    "#     return self \n",
    "\n",
    "#   def get_feature_names_out(self, arg):\n",
    "#     return self.columns\n",
    "\n",
    "##---------------------\n",
    "\n",
    "# class doNothingTransformer(BaseEstimator, TransformerMixin):\n",
    "\n",
    "#   def __init__(self):\n",
    "#     print(f'doNothingTransfromer init')\n",
    "#     pass\n",
    "\n",
    "#   def transform(self,X,y=None):\n",
    "#     self.columns = X.columns\n",
    "#     print(f'doNothingTransfromer transform: {len(self.columns)}::{self.columns}')\n",
    "#     return X\n",
    "\n",
    "#   def fit(self, X, y=None):\n",
    "#     self.columns = X.columns\n",
    "#     print(f'doNothingTransfromer fit: {len(self.columns)}::{self.columns}')\n",
    "     \n",
    "#     return self \n",
    "\n",
    "#   def get_feature_names_out(self, arg):\n",
    "#     print(f'doNothingTransfromer get_feature_names_out')\n",
    "#     return self.columns\n",
    "\n",
    "##---------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64ed8b3c-4839-4b82-ae5c-8bf95df6c99f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;imputer_ct&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;parse_passenger_id&#x27;,\n",
       "                                                  parsePassengerId(),\n",
       "                                                  [&#x27;PassengerId&#x27;]),\n",
       "                                                 (&#x27;imput_zero&#x27;,\n",
       "                                                  SimpleImputer(fill_value=0,\n",
       "                                                                strategy=&#x27;constant&#x27;),\n",
       "                                                  [&#x27;RoomService&#x27;, &#x27;FoodCourt&#x27;,\n",
       "                                                   &#x27;ShoppingMall&#x27;, &#x27;Spa&#x27;,\n",
       "                                                   &#x27;VRDeck&#x27;]),\n",
       "                                                 (&#x27;imp_mean&#x27;, SimpleImputer(),\n",
       "                                                  [&#x27;Age&#x27;]),\n",
       "                                                 (&#x27;planet_transformer&#x27;,\n",
       "                                                  planetImputerEncoder(),\n",
       "                                                  [&#x27;H...\n",
       "                                   verbose_feature_names_out=False)),\n",
       "                (&#x27;oh_ct&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;encoder_oh&#x27;,\n",
       "                                                  oneHotEncoderWrapper(),\n",
       "                                                  [&#x27;Cabin_A&#x27;, &#x27;Cabin_C&#x27;,\n",
       "                                                   &#x27;HomePlanet&#x27;,\n",
       "                                                   &#x27;Destination&#x27;])],\n",
       "                                   verbose_feature_names_out=False)),\n",
       "                (&#x27;column_dropper&#x27;,\n",
       "                 columnDropperTransformer(drop_columns=[&#x27;Name&#x27;, &#x27;Cabin&#x27;,\n",
       "                                                        &#x27;CryoSleep&#x27;,\n",
       "                                                        &#x27;PassengerId&#x27;,\n",
       "                                                        &#x27;VIP&#x27;])),\n",
       "                (&#x27;standard_scaler&#x27;, StandardScaler())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;imputer_ct&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;parse_passenger_id&#x27;,\n",
       "                                                  parsePassengerId(),\n",
       "                                                  [&#x27;PassengerId&#x27;]),\n",
       "                                                 (&#x27;imput_zero&#x27;,\n",
       "                                                  SimpleImputer(fill_value=0,\n",
       "                                                                strategy=&#x27;constant&#x27;),\n",
       "                                                  [&#x27;RoomService&#x27;, &#x27;FoodCourt&#x27;,\n",
       "                                                   &#x27;ShoppingMall&#x27;, &#x27;Spa&#x27;,\n",
       "                                                   &#x27;VRDeck&#x27;]),\n",
       "                                                 (&#x27;imp_mean&#x27;, SimpleImputer(),\n",
       "                                                  [&#x27;Age&#x27;]),\n",
       "                                                 (&#x27;planet_transformer&#x27;,\n",
       "                                                  planetImputerEncoder(),\n",
       "                                                  [&#x27;H...\n",
       "                                   verbose_feature_names_out=False)),\n",
       "                (&#x27;oh_ct&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;encoder_oh&#x27;,\n",
       "                                                  oneHotEncoderWrapper(),\n",
       "                                                  [&#x27;Cabin_A&#x27;, &#x27;Cabin_C&#x27;,\n",
       "                                                   &#x27;HomePlanet&#x27;,\n",
       "                                                   &#x27;Destination&#x27;])],\n",
       "                                   verbose_feature_names_out=False)),\n",
       "                (&#x27;column_dropper&#x27;,\n",
       "                 columnDropperTransformer(drop_columns=[&#x27;Name&#x27;, &#x27;Cabin&#x27;,\n",
       "                                                        &#x27;CryoSleep&#x27;,\n",
       "                                                        &#x27;PassengerId&#x27;,\n",
       "                                                        &#x27;VIP&#x27;])),\n",
       "                (&#x27;standard_scaler&#x27;, StandardScaler())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">imputer_ct: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                  transformers=[(&#x27;parse_passenger_id&#x27;, parsePassengerId(),\n",
       "                                 [&#x27;PassengerId&#x27;]),\n",
       "                                (&#x27;imput_zero&#x27;,\n",
       "                                 SimpleImputer(fill_value=0,\n",
       "                                               strategy=&#x27;constant&#x27;),\n",
       "                                 [&#x27;RoomService&#x27;, &#x27;FoodCourt&#x27;, &#x27;ShoppingMall&#x27;,\n",
       "                                  &#x27;Spa&#x27;, &#x27;VRDeck&#x27;]),\n",
       "                                (&#x27;imp_mean&#x27;, SimpleImputer(), [&#x27;Age&#x27;]),\n",
       "                                (&#x27;planet_transformer&#x27;, planetImputerEncoder(),\n",
       "                                 [&#x27;HomePlanet&#x27;, &#x27;Destination&#x27;]),\n",
       "                                (&#x27;cryo_vip_transformer&#x27;, cryoVIPEncoder(),\n",
       "                                 [&#x27;CryoSleep&#x27;, &#x27;VIP&#x27;]),\n",
       "                                (&#x27;parse_and_impute_cabins&#x27;,\n",
       "                                 parseAndImputeCabins(), [&#x27;Cabin&#x27;])],\n",
       "                  verbose_feature_names_out=False)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">parse_passenger_id</label><div class=\"sk-toggleable__content\"><pre>[&#x27;PassengerId&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">parsePassengerId</label><div class=\"sk-toggleable__content\"><pre>parsePassengerId()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">imput_zero</label><div class=\"sk-toggleable__content\"><pre>[&#x27;RoomService&#x27;, &#x27;FoodCourt&#x27;, &#x27;ShoppingMall&#x27;, &#x27;Spa&#x27;, &#x27;VRDeck&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(fill_value=0, strategy=&#x27;constant&#x27;)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">imp_mean</label><div class=\"sk-toggleable__content\"><pre>[&#x27;Age&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">planet_transformer</label><div class=\"sk-toggleable__content\"><pre>[&#x27;HomePlanet&#x27;, &#x27;Destination&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">planetImputerEncoder</label><div class=\"sk-toggleable__content\"><pre>planetImputerEncoder()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">cryo_vip_transformer</label><div class=\"sk-toggleable__content\"><pre>[&#x27;CryoSleep&#x27;, &#x27;VIP&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">cryoVIPEncoder</label><div class=\"sk-toggleable__content\"><pre>cryoVIPEncoder()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">parse_and_impute_cabins</label><div class=\"sk-toggleable__content\"><pre>[&#x27;Cabin&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">parseAndImputeCabins</label><div class=\"sk-toggleable__content\"><pre>parseAndImputeCabins()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">remainder</label><div class=\"sk-toggleable__content\"><pre></pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">passthrough</label><div class=\"sk-toggleable__content\"><pre>passthrough</pre></div></div></div></div></div></div></div></div><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">oh_ct: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                  transformers=[(&#x27;encoder_oh&#x27;, oneHotEncoderWrapper(),\n",
       "                                 [&#x27;Cabin_A&#x27;, &#x27;Cabin_C&#x27;, &#x27;HomePlanet&#x27;,\n",
       "                                  &#x27;Destination&#x27;])],\n",
       "                  verbose_feature_names_out=False)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">encoder_oh</label><div class=\"sk-toggleable__content\"><pre>[&#x27;Cabin_A&#x27;, &#x27;Cabin_C&#x27;, &#x27;HomePlanet&#x27;, &#x27;Destination&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" ><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">oneHotEncoderWrapper</label><div class=\"sk-toggleable__content\"><pre>oneHotEncoderWrapper()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" ><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">remainder</label><div class=\"sk-toggleable__content\"><pre></pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" ><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">passthrough</label><div class=\"sk-toggleable__content\"><pre>passthrough</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-22\" type=\"checkbox\" ><label for=\"sk-estimator-id-22\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">columnDropperTransformer</label><div class=\"sk-toggleable__content\"><pre>columnDropperTransformer(drop_columns=[&#x27;Name&#x27;, &#x27;Cabin&#x27;, &#x27;CryoSleep&#x27;,\n",
       "                                       &#x27;PassengerId&#x27;, &#x27;VIP&#x27;])</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-23\" type=\"checkbox\" ><label for=\"sk-estimator-id-23\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('imputer_ct',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('parse_passenger_id',\n",
       "                                                  parsePassengerId(),\n",
       "                                                  ['PassengerId']),\n",
       "                                                 ('imput_zero',\n",
       "                                                  SimpleImputer(fill_value=0,\n",
       "                                                                strategy='constant'),\n",
       "                                                  ['RoomService', 'FoodCourt',\n",
       "                                                   'ShoppingMall', 'Spa',\n",
       "                                                   'VRDeck']),\n",
       "                                                 ('imp_mean', SimpleImputer(),\n",
       "                                                  ['Age']),\n",
       "                                                 ('planet_transformer',\n",
       "                                                  planetImputerEncoder(),\n",
       "                                                  ['H...\n",
       "                                   verbose_feature_names_out=False)),\n",
       "                ('oh_ct',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('encoder_oh',\n",
       "                                                  oneHotEncoderWrapper(),\n",
       "                                                  ['Cabin_A', 'Cabin_C',\n",
       "                                                   'HomePlanet',\n",
       "                                                   'Destination'])],\n",
       "                                   verbose_feature_names_out=False)),\n",
       "                ('column_dropper',\n",
       "                 columnDropperTransformer(drop_columns=['Name', 'Cabin',\n",
       "                                                        'CryoSleep',\n",
       "                                                        'PassengerId',\n",
       "                                                        'VIP'])),\n",
       "                ('standard_scaler', StandardScaler())])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verbose_pipeline = False\n",
    "\n",
    "imputer_ct = ColumnTransformer(\n",
    "    [\n",
    "        ('parse_passenger_id', parsePassengerId(), ['PassengerId']),\n",
    "        ('imput_zero', SimpleImputer(strategy='constant', fill_value=0), ['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']),\n",
    "        ('imp_mean', SimpleImputer(strategy='mean'), ['Age']),\n",
    "        ('planet_transformer', planetImputerEncoder(), ['HomePlanet', 'Destination']),\n",
    "        ('cryo_vip_transformer', cryoVIPEncoder(), ['CryoSleep', 'VIP']),\n",
    "        ('parse_and_impute_cabins', parseAndImputeCabins(), ['Cabin']),\n",
    "    ],\n",
    "    remainder='passthrough',\n",
    "    verbose_feature_names_out=False,\n",
    "    verbose=verbose_pipeline\n",
    ")\n",
    "\n",
    "oh_ct = ColumnTransformer(\n",
    "    [\n",
    "        ('encoder_oh', oneHotEncoderWrapper(), ['Cabin_A', 'Cabin_C', 'HomePlanet', 'Destination']),\n",
    "    ],\n",
    "    remainder='passthrough',\n",
    "    verbose_feature_names_out=False,\n",
    "    verbose=verbose_pipeline,\n",
    "        \n",
    ")\n",
    "\n",
    "cols_to_drop = ['Name', 'Cabin', 'CryoSleep', 'PassengerId', 'VIP']\n",
    "preprocessor = Pipeline(\n",
    "    [\n",
    "        ('imputer_ct', imputer_ct),\n",
    "        # ('do_nothing', doNothingTransformer()),\n",
    "        ('oh_ct', oh_ct),\n",
    "        # ('do_nothing_too', doNothingTransformer()),\n",
    "        ('column_dropper', columnDropperTransformer(cols_to_drop)),\n",
    "        ('standard_scaler', StandardScaler()),\n",
    "    ],\n",
    "    verbose=verbose_pipeline\n",
    ")\n",
    "preprocessor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c477691-b82c-456f-a57d-9cde3d4dcbb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "_train = train_df.copy()\n",
    "_X_test = test_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "60250a70-4a01-455b-9571-51e6cebedb73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>B/0/P</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>39.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Maham Ofracculy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>24.0</td>\n",
       "      <td>False</td>\n",
       "      <td>109.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>Juanna Vines</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0003_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>58.0</td>\n",
       "      <td>True</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3576.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6715.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>Altark Susent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0003_02</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>33.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>3329.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>Solam Susent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0004_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/1/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>16.0</td>\n",
       "      <td>False</td>\n",
       "      <td>303.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Willy Santantines</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8688</th>\n",
       "      <td>9276_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/98/P</td>\n",
       "      <td>55 Cancri e</td>\n",
       "      <td>41.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6819.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1643.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>Gravior Noxnuther</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8689</th>\n",
       "      <td>9278_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>True</td>\n",
       "      <td>G/1499/S</td>\n",
       "      <td>PSO J318.5-22</td>\n",
       "      <td>18.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Kurta Mondalley</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8690</th>\n",
       "      <td>9279_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>G/1500/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>26.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1872.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Fayey Connon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8691</th>\n",
       "      <td>9280_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>E/608/S</td>\n",
       "      <td>55 Cancri e</td>\n",
       "      <td>32.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1049.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>353.0</td>\n",
       "      <td>3235.0</td>\n",
       "      <td>Celeon Hontichre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8692</th>\n",
       "      <td>9280_02</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>E/608/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>44.0</td>\n",
       "      <td>False</td>\n",
       "      <td>126.0</td>\n",
       "      <td>4688.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Propsh Hontichre</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8693 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId HomePlanet CryoSleep     Cabin    Destination   Age    VIP  \\\n",
       "0        0001_01     Europa     False     B/0/P    TRAPPIST-1e  39.0  False   \n",
       "1        0002_01      Earth     False     F/0/S    TRAPPIST-1e  24.0  False   \n",
       "2        0003_01     Europa     False     A/0/S    TRAPPIST-1e  58.0   True   \n",
       "3        0003_02     Europa     False     A/0/S    TRAPPIST-1e  33.0  False   \n",
       "4        0004_01      Earth     False     F/1/S    TRAPPIST-1e  16.0  False   \n",
       "...          ...        ...       ...       ...            ...   ...    ...   \n",
       "8688     9276_01     Europa     False    A/98/P    55 Cancri e  41.0   True   \n",
       "8689     9278_01      Earth      True  G/1499/S  PSO J318.5-22  18.0  False   \n",
       "8690     9279_01      Earth     False  G/1500/S    TRAPPIST-1e  26.0  False   \n",
       "8691     9280_01     Europa     False   E/608/S    55 Cancri e  32.0  False   \n",
       "8692     9280_02     Europa     False   E/608/S    TRAPPIST-1e  44.0  False   \n",
       "\n",
       "      RoomService  FoodCourt  ShoppingMall     Spa  VRDeck               Name  \n",
       "0             0.0        0.0           0.0     0.0     0.0    Maham Ofracculy  \n",
       "1           109.0        9.0          25.0   549.0    44.0       Juanna Vines  \n",
       "2            43.0     3576.0           0.0  6715.0    49.0      Altark Susent  \n",
       "3             0.0     1283.0         371.0  3329.0   193.0       Solam Susent  \n",
       "4           303.0       70.0         151.0   565.0     2.0  Willy Santantines  \n",
       "...           ...        ...           ...     ...     ...                ...  \n",
       "8688          0.0     6819.0           0.0  1643.0    74.0  Gravior Noxnuther  \n",
       "8689          0.0        0.0           0.0     0.0     0.0    Kurta Mondalley  \n",
       "8690          0.0        0.0        1872.0     1.0     0.0       Fayey Connon  \n",
       "8691          0.0     1049.0           0.0   353.0  3235.0   Celeon Hontichre  \n",
       "8692        126.0     4688.0           0.0     0.0    12.0   Propsh Hontichre  \n",
       "\n",
       "[8693 rows x 13 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_X_train = _train.drop(columns='Transported')\n",
    "_X_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fef1bbea-bde2-494e-a397-08e0f8e8ff8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Transported</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8688</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8689</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8690</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8691</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8692</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8693 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Transported\n",
       "0               0\n",
       "1               1\n",
       "2               0\n",
       "3               0\n",
       "4               1\n",
       "...           ...\n",
       "8688            0\n",
       "8689            0\n",
       "8690            1\n",
       "8691            0\n",
       "8692            1\n",
       "\n",
       "[8693 rows x 1 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_y_train = _train['Transported']\n",
    "_y_train_int = pd.DataFrame(_y_train).replace({True: 1, False: 0})\n",
    "_y_train_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1237bf89-4062-4fe8-9dcd-c7bce6797d83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;imputer_ct&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;parse_passenger_id&#x27;,\n",
       "                                                  parsePassengerId(),\n",
       "                                                  [&#x27;PassengerId&#x27;]),\n",
       "                                                 (&#x27;imput_zero&#x27;,\n",
       "                                                  SimpleImputer(fill_value=0,\n",
       "                                                                strategy=&#x27;constant&#x27;),\n",
       "                                                  [&#x27;RoomService&#x27;, &#x27;FoodCourt&#x27;,\n",
       "                                                   &#x27;ShoppingMall&#x27;, &#x27;Spa&#x27;,\n",
       "                                                   &#x27;VRDeck&#x27;]),\n",
       "                                                 (&#x27;imp_mean&#x27;, SimpleImputer(),\n",
       "                                                  [&#x27;Age&#x27;]),\n",
       "                                                 (&#x27;planet_transformer&#x27;,\n",
       "                                                  planetImputerEncoder(),\n",
       "                                                  [&#x27;H...\n",
       "                                   verbose_feature_names_out=False)),\n",
       "                (&#x27;oh_ct&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;encoder_oh&#x27;,\n",
       "                                                  oneHotEncoderWrapper(),\n",
       "                                                  [&#x27;Cabin_A&#x27;, &#x27;Cabin_C&#x27;,\n",
       "                                                   &#x27;HomePlanet&#x27;,\n",
       "                                                   &#x27;Destination&#x27;])],\n",
       "                                   verbose_feature_names_out=False)),\n",
       "                (&#x27;column_dropper&#x27;,\n",
       "                 columnDropperTransformer(drop_columns=[&#x27;Name&#x27;, &#x27;Cabin&#x27;,\n",
       "                                                        &#x27;CryoSleep&#x27;,\n",
       "                                                        &#x27;PassengerId&#x27;,\n",
       "                                                        &#x27;VIP&#x27;])),\n",
       "                (&#x27;standard_scaler&#x27;, StandardScaler())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-24\" type=\"checkbox\" ><label for=\"sk-estimator-id-24\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;imputer_ct&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;parse_passenger_id&#x27;,\n",
       "                                                  parsePassengerId(),\n",
       "                                                  [&#x27;PassengerId&#x27;]),\n",
       "                                                 (&#x27;imput_zero&#x27;,\n",
       "                                                  SimpleImputer(fill_value=0,\n",
       "                                                                strategy=&#x27;constant&#x27;),\n",
       "                                                  [&#x27;RoomService&#x27;, &#x27;FoodCourt&#x27;,\n",
       "                                                   &#x27;ShoppingMall&#x27;, &#x27;Spa&#x27;,\n",
       "                                                   &#x27;VRDeck&#x27;]),\n",
       "                                                 (&#x27;imp_mean&#x27;, SimpleImputer(),\n",
       "                                                  [&#x27;Age&#x27;]),\n",
       "                                                 (&#x27;planet_transformer&#x27;,\n",
       "                                                  planetImputerEncoder(),\n",
       "                                                  [&#x27;H...\n",
       "                                   verbose_feature_names_out=False)),\n",
       "                (&#x27;oh_ct&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;encoder_oh&#x27;,\n",
       "                                                  oneHotEncoderWrapper(),\n",
       "                                                  [&#x27;Cabin_A&#x27;, &#x27;Cabin_C&#x27;,\n",
       "                                                   &#x27;HomePlanet&#x27;,\n",
       "                                                   &#x27;Destination&#x27;])],\n",
       "                                   verbose_feature_names_out=False)),\n",
       "                (&#x27;column_dropper&#x27;,\n",
       "                 columnDropperTransformer(drop_columns=[&#x27;Name&#x27;, &#x27;Cabin&#x27;,\n",
       "                                                        &#x27;CryoSleep&#x27;,\n",
       "                                                        &#x27;PassengerId&#x27;,\n",
       "                                                        &#x27;VIP&#x27;])),\n",
       "                (&#x27;standard_scaler&#x27;, StandardScaler())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-25\" type=\"checkbox\" ><label for=\"sk-estimator-id-25\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">imputer_ct: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                  transformers=[(&#x27;parse_passenger_id&#x27;, parsePassengerId(),\n",
       "                                 [&#x27;PassengerId&#x27;]),\n",
       "                                (&#x27;imput_zero&#x27;,\n",
       "                                 SimpleImputer(fill_value=0,\n",
       "                                               strategy=&#x27;constant&#x27;),\n",
       "                                 [&#x27;RoomService&#x27;, &#x27;FoodCourt&#x27;, &#x27;ShoppingMall&#x27;,\n",
       "                                  &#x27;Spa&#x27;, &#x27;VRDeck&#x27;]),\n",
       "                                (&#x27;imp_mean&#x27;, SimpleImputer(), [&#x27;Age&#x27;]),\n",
       "                                (&#x27;planet_transformer&#x27;, planetImputerEncoder(),\n",
       "                                 [&#x27;HomePlanet&#x27;, &#x27;Destination&#x27;]),\n",
       "                                (&#x27;cryo_vip_transformer&#x27;, cryoVIPEncoder(),\n",
       "                                 [&#x27;CryoSleep&#x27;, &#x27;VIP&#x27;]),\n",
       "                                (&#x27;parse_and_impute_cabins&#x27;,\n",
       "                                 parseAndImputeCabins(), [&#x27;Cabin&#x27;])],\n",
       "                  verbose_feature_names_out=False)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-26\" type=\"checkbox\" ><label for=\"sk-estimator-id-26\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">parse_passenger_id</label><div class=\"sk-toggleable__content\"><pre>[&#x27;PassengerId&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-27\" type=\"checkbox\" ><label for=\"sk-estimator-id-27\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">parsePassengerId</label><div class=\"sk-toggleable__content\"><pre>parsePassengerId()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-28\" type=\"checkbox\" ><label for=\"sk-estimator-id-28\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">imput_zero</label><div class=\"sk-toggleable__content\"><pre>[&#x27;RoomService&#x27;, &#x27;FoodCourt&#x27;, &#x27;ShoppingMall&#x27;, &#x27;Spa&#x27;, &#x27;VRDeck&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-29\" type=\"checkbox\" ><label for=\"sk-estimator-id-29\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(fill_value=0, strategy=&#x27;constant&#x27;)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-30\" type=\"checkbox\" ><label for=\"sk-estimator-id-30\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">imp_mean</label><div class=\"sk-toggleable__content\"><pre>[&#x27;Age&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-31\" type=\"checkbox\" ><label for=\"sk-estimator-id-31\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-32\" type=\"checkbox\" ><label for=\"sk-estimator-id-32\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">planet_transformer</label><div class=\"sk-toggleable__content\"><pre>[&#x27;HomePlanet&#x27;, &#x27;Destination&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-33\" type=\"checkbox\" ><label for=\"sk-estimator-id-33\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">planetImputerEncoder</label><div class=\"sk-toggleable__content\"><pre>planetImputerEncoder()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-34\" type=\"checkbox\" ><label for=\"sk-estimator-id-34\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">cryo_vip_transformer</label><div class=\"sk-toggleable__content\"><pre>[&#x27;CryoSleep&#x27;, &#x27;VIP&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-35\" type=\"checkbox\" ><label for=\"sk-estimator-id-35\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">cryoVIPEncoder</label><div class=\"sk-toggleable__content\"><pre>cryoVIPEncoder()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-36\" type=\"checkbox\" ><label for=\"sk-estimator-id-36\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">parse_and_impute_cabins</label><div class=\"sk-toggleable__content\"><pre>[&#x27;Cabin&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-37\" type=\"checkbox\" ><label for=\"sk-estimator-id-37\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">parseAndImputeCabins</label><div class=\"sk-toggleable__content\"><pre>parseAndImputeCabins()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-38\" type=\"checkbox\" ><label for=\"sk-estimator-id-38\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">remainder</label><div class=\"sk-toggleable__content\"><pre>[&#x27;Name&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-39\" type=\"checkbox\" ><label for=\"sk-estimator-id-39\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">passthrough</label><div class=\"sk-toggleable__content\"><pre>passthrough</pre></div></div></div></div></div></div></div></div><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-40\" type=\"checkbox\" ><label for=\"sk-estimator-id-40\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">oh_ct: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                  transformers=[(&#x27;encoder_oh&#x27;, oneHotEncoderWrapper(),\n",
       "                                 [&#x27;Cabin_A&#x27;, &#x27;Cabin_C&#x27;, &#x27;HomePlanet&#x27;,\n",
       "                                  &#x27;Destination&#x27;])],\n",
       "                  verbose_feature_names_out=False)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-41\" type=\"checkbox\" ><label for=\"sk-estimator-id-41\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">encoder_oh</label><div class=\"sk-toggleable__content\"><pre>[&#x27;Cabin_A&#x27;, &#x27;Cabin_C&#x27;, &#x27;HomePlanet&#x27;, &#x27;Destination&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-42\" type=\"checkbox\" ><label for=\"sk-estimator-id-42\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">oneHotEncoderWrapper</label><div class=\"sk-toggleable__content\"><pre>oneHotEncoderWrapper()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-43\" type=\"checkbox\" ><label for=\"sk-estimator-id-43\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">remainder</label><div class=\"sk-toggleable__content\"><pre>[&#x27;PassengerId&#x27;, &#x27;PassengerId_A&#x27;, &#x27;PassengerId_B&#x27;, &#x27;traveling_in_group&#x27;, &#x27;RoomService&#x27;, &#x27;FoodCourt&#x27;, &#x27;ShoppingMall&#x27;, &#x27;Spa&#x27;, &#x27;VRDeck&#x27;, &#x27;Age&#x27;, &#x27;CryoSleep&#x27;, &#x27;VIP&#x27;, &#x27;CryoSleep_bool&#x27;, &#x27;VIP_bool&#x27;, &#x27;Cabin&#x27;, &#x27;Cabin_B&#x27;, &#x27;Name&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-44\" type=\"checkbox\" ><label for=\"sk-estimator-id-44\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">passthrough</label><div class=\"sk-toggleable__content\"><pre>passthrough</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-45\" type=\"checkbox\" ><label for=\"sk-estimator-id-45\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">columnDropperTransformer</label><div class=\"sk-toggleable__content\"><pre>columnDropperTransformer(drop_columns=[&#x27;Name&#x27;, &#x27;Cabin&#x27;, &#x27;CryoSleep&#x27;,\n",
       "                                       &#x27;PassengerId&#x27;, &#x27;VIP&#x27;])</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-46\" type=\"checkbox\" ><label for=\"sk-estimator-id-46\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('imputer_ct',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('parse_passenger_id',\n",
       "                                                  parsePassengerId(),\n",
       "                                                  ['PassengerId']),\n",
       "                                                 ('imput_zero',\n",
       "                                                  SimpleImputer(fill_value=0,\n",
       "                                                                strategy='constant'),\n",
       "                                                  ['RoomService', 'FoodCourt',\n",
       "                                                   'ShoppingMall', 'Spa',\n",
       "                                                   'VRDeck']),\n",
       "                                                 ('imp_mean', SimpleImputer(),\n",
       "                                                  ['Age']),\n",
       "                                                 ('planet_transformer',\n",
       "                                                  planetImputerEncoder(),\n",
       "                                                  ['H...\n",
       "                                   verbose_feature_names_out=False)),\n",
       "                ('oh_ct',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('encoder_oh',\n",
       "                                                  oneHotEncoderWrapper(),\n",
       "                                                  ['Cabin_A', 'Cabin_C',\n",
       "                                                   'HomePlanet',\n",
       "                                                   'Destination'])],\n",
       "                                   verbose_feature_names_out=False)),\n",
       "                ('column_dropper',\n",
       "                 columnDropperTransformer(drop_columns=['Name', 'Cabin',\n",
       "                                                        'CryoSleep',\n",
       "                                                        'PassengerId',\n",
       "                                                        'VIP'])),\n",
       "                ('standard_scaler', StandardScaler())])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor.fit(_X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a17f03dc-31d9-4c9a-b3c7-7adf841f5360",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8693, 28), (4277, 28))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_X_train_scaled = preprocessor.transform(_X_train)\n",
    "_X_test_scaled = preprocessor.transform(_X_test)\n",
    "\n",
    "_X_train_scaled.shape, _X_test_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "da5331be-6804-4026-b37b-3fecc401591f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cabin_A_A</th>\n",
       "      <th>Cabin_A_B</th>\n",
       "      <th>Cabin_A_C</th>\n",
       "      <th>Cabin_A_D</th>\n",
       "      <th>Cabin_A_E</th>\n",
       "      <th>Cabin_A_F</th>\n",
       "      <th>Cabin_A_G</th>\n",
       "      <th>Cabin_A_T</th>\n",
       "      <th>Cabin_C_P</th>\n",
       "      <th>Cabin_C_S</th>\n",
       "      <th>HomePlanet_Earth</th>\n",
       "      <th>HomePlanet_Europa</th>\n",
       "      <th>HomePlanet_Mars</th>\n",
       "      <th>Destination_55 Cancri e</th>\n",
       "      <th>Destination_PSO J318.5-22</th>\n",
       "      <th>Destination_TRAPPIST-1e</th>\n",
       "      <th>PassengerId_A</th>\n",
       "      <th>PassengerId_B</th>\n",
       "      <th>traveling_in_group</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Age</th>\n",
       "      <th>CryoSleep_bool</th>\n",
       "      <th>VIP_bool</th>\n",
       "      <th>Cabin_B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.174191</td>\n",
       "      <td>3.187347</td>\n",
       "      <td>-0.30661</td>\n",
       "      <td>-0.241218</td>\n",
       "      <td>-0.334759</td>\n",
       "      <td>-0.724629</td>\n",
       "      <td>-0.645897</td>\n",
       "      <td>-0.02399</td>\n",
       "      <td>1.032865</td>\n",
       "      <td>-1.032865</td>\n",
       "      <td>-1.111173</td>\n",
       "      <td>1.754795</td>\n",
       "      <td>-0.503664</td>\n",
       "      <td>-0.511013</td>\n",
       "      <td>-0.317487</td>\n",
       "      <td>0.652521</td>\n",
       "      <td>-1.734409</td>\n",
       "      <td>-0.491161</td>\n",
       "      <td>-0.899532</td>\n",
       "      <td>-0.333105</td>\n",
       "      <td>-0.281027</td>\n",
       "      <td>-0.283579</td>\n",
       "      <td>-0.270626</td>\n",
       "      <td>-0.263003</td>\n",
       "      <td>0.709437</td>\n",
       "      <td>-0.732770</td>\n",
       "      <td>-0.153063</td>\n",
       "      <td>-1.186610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.174191</td>\n",
       "      <td>-0.313741</td>\n",
       "      <td>-0.30661</td>\n",
       "      <td>-0.241218</td>\n",
       "      <td>-0.334759</td>\n",
       "      <td>1.380016</td>\n",
       "      <td>-0.645897</td>\n",
       "      <td>-0.02399</td>\n",
       "      <td>-0.968181</td>\n",
       "      <td>0.968181</td>\n",
       "      <td>0.899950</td>\n",
       "      <td>-0.569867</td>\n",
       "      <td>-0.503664</td>\n",
       "      <td>-0.511013</td>\n",
       "      <td>-0.317487</td>\n",
       "      <td>0.652521</td>\n",
       "      <td>-1.734034</td>\n",
       "      <td>-0.491161</td>\n",
       "      <td>-0.899532</td>\n",
       "      <td>-0.168073</td>\n",
       "      <td>-0.275387</td>\n",
       "      <td>-0.241771</td>\n",
       "      <td>0.217158</td>\n",
       "      <td>-0.224205</td>\n",
       "      <td>-0.336717</td>\n",
       "      <td>-0.732770</td>\n",
       "      <td>-0.153063</td>\n",
       "      <td>-1.186610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.740821</td>\n",
       "      <td>-0.313741</td>\n",
       "      <td>-0.30661</td>\n",
       "      <td>-0.241218</td>\n",
       "      <td>-0.334759</td>\n",
       "      <td>-0.724629</td>\n",
       "      <td>-0.645897</td>\n",
       "      <td>-0.02399</td>\n",
       "      <td>-0.968181</td>\n",
       "      <td>0.968181</td>\n",
       "      <td>-1.111173</td>\n",
       "      <td>1.754795</td>\n",
       "      <td>-0.503664</td>\n",
       "      <td>-0.511013</td>\n",
       "      <td>-0.317487</td>\n",
       "      <td>0.652521</td>\n",
       "      <td>-1.733660</td>\n",
       "      <td>-0.491161</td>\n",
       "      <td>1.111690</td>\n",
       "      <td>-0.268001</td>\n",
       "      <td>1.959998</td>\n",
       "      <td>-0.283579</td>\n",
       "      <td>5.695623</td>\n",
       "      <td>-0.219796</td>\n",
       "      <td>2.034566</td>\n",
       "      <td>-0.732770</td>\n",
       "      <td>6.533255</td>\n",
       "      <td>-1.186610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.740821</td>\n",
       "      <td>-0.313741</td>\n",
       "      <td>-0.30661</td>\n",
       "      <td>-0.241218</td>\n",
       "      <td>-0.334759</td>\n",
       "      <td>-0.724629</td>\n",
       "      <td>-0.645897</td>\n",
       "      <td>-0.02399</td>\n",
       "      <td>-0.968181</td>\n",
       "      <td>0.968181</td>\n",
       "      <td>-1.111173</td>\n",
       "      <td>1.754795</td>\n",
       "      <td>-0.503664</td>\n",
       "      <td>-0.511013</td>\n",
       "      <td>-0.317487</td>\n",
       "      <td>0.652521</td>\n",
       "      <td>-1.733660</td>\n",
       "      <td>0.457443</td>\n",
       "      <td>1.111690</td>\n",
       "      <td>-0.333105</td>\n",
       "      <td>0.523010</td>\n",
       "      <td>0.336851</td>\n",
       "      <td>2.687176</td>\n",
       "      <td>-0.092818</td>\n",
       "      <td>0.290975</td>\n",
       "      <td>-0.732770</td>\n",
       "      <td>-0.153063</td>\n",
       "      <td>-1.186610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.174191</td>\n",
       "      <td>-0.313741</td>\n",
       "      <td>-0.30661</td>\n",
       "      <td>-0.241218</td>\n",
       "      <td>-0.334759</td>\n",
       "      <td>1.380016</td>\n",
       "      <td>-0.645897</td>\n",
       "      <td>-0.02399</td>\n",
       "      <td>-0.968181</td>\n",
       "      <td>0.968181</td>\n",
       "      <td>0.899950</td>\n",
       "      <td>-0.569867</td>\n",
       "      <td>-0.503664</td>\n",
       "      <td>-0.511013</td>\n",
       "      <td>-0.317487</td>\n",
       "      <td>0.652521</td>\n",
       "      <td>-1.733286</td>\n",
       "      <td>-0.491161</td>\n",
       "      <td>-0.899532</td>\n",
       "      <td>0.125652</td>\n",
       "      <td>-0.237159</td>\n",
       "      <td>-0.031059</td>\n",
       "      <td>0.231374</td>\n",
       "      <td>-0.261240</td>\n",
       "      <td>-0.894666</td>\n",
       "      <td>-0.732770</td>\n",
       "      <td>-0.153063</td>\n",
       "      <td>-1.184634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8688</th>\n",
       "      <td>5.740821</td>\n",
       "      <td>-0.313741</td>\n",
       "      <td>-0.30661</td>\n",
       "      <td>-0.241218</td>\n",
       "      <td>-0.334759</td>\n",
       "      <td>-0.724629</td>\n",
       "      <td>-0.645897</td>\n",
       "      <td>-0.02399</td>\n",
       "      <td>1.032865</td>\n",
       "      <td>-1.032865</td>\n",
       "      <td>-1.111173</td>\n",
       "      <td>1.754795</td>\n",
       "      <td>-0.503664</td>\n",
       "      <td>1.956897</td>\n",
       "      <td>-0.317487</td>\n",
       "      <td>-1.532519</td>\n",
       "      <td>1.738236</td>\n",
       "      <td>-0.491161</td>\n",
       "      <td>-0.899532</td>\n",
       "      <td>-0.333105</td>\n",
       "      <td>3.992336</td>\n",
       "      <td>-0.283579</td>\n",
       "      <td>1.189173</td>\n",
       "      <td>-0.197751</td>\n",
       "      <td>0.848924</td>\n",
       "      <td>-0.732770</td>\n",
       "      <td>6.533255</td>\n",
       "      <td>-0.992913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8689</th>\n",
       "      <td>-0.174191</td>\n",
       "      <td>-0.313741</td>\n",
       "      <td>-0.30661</td>\n",
       "      <td>-0.241218</td>\n",
       "      <td>-0.334759</td>\n",
       "      <td>-0.724629</td>\n",
       "      <td>1.548235</td>\n",
       "      <td>-0.02399</td>\n",
       "      <td>-0.968181</td>\n",
       "      <td>0.968181</td>\n",
       "      <td>0.899950</td>\n",
       "      <td>-0.569867</td>\n",
       "      <td>-0.503664</td>\n",
       "      <td>-0.511013</td>\n",
       "      <td>3.149739</td>\n",
       "      <td>-1.532519</td>\n",
       "      <td>1.738984</td>\n",
       "      <td>-0.491161</td>\n",
       "      <td>-0.899532</td>\n",
       "      <td>-0.333105</td>\n",
       "      <td>-0.281027</td>\n",
       "      <td>-0.283579</td>\n",
       "      <td>-0.270626</td>\n",
       "      <td>-0.263003</td>\n",
       "      <td>-0.755179</td>\n",
       "      <td>1.364685</td>\n",
       "      <td>-0.153063</td>\n",
       "      <td>1.776164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8690</th>\n",
       "      <td>-0.174191</td>\n",
       "      <td>-0.313741</td>\n",
       "      <td>-0.30661</td>\n",
       "      <td>-0.241218</td>\n",
       "      <td>-0.334759</td>\n",
       "      <td>-0.724629</td>\n",
       "      <td>1.548235</td>\n",
       "      <td>-0.02399</td>\n",
       "      <td>-0.968181</td>\n",
       "      <td>0.968181</td>\n",
       "      <td>0.899950</td>\n",
       "      <td>-0.569867</td>\n",
       "      <td>-0.503664</td>\n",
       "      <td>-0.511013</td>\n",
       "      <td>-0.317487</td>\n",
       "      <td>0.652521</td>\n",
       "      <td>1.739359</td>\n",
       "      <td>-0.491161</td>\n",
       "      <td>-0.899532</td>\n",
       "      <td>-0.333105</td>\n",
       "      <td>-0.281027</td>\n",
       "      <td>2.846999</td>\n",
       "      <td>-0.269737</td>\n",
       "      <td>-0.263003</td>\n",
       "      <td>-0.197230</td>\n",
       "      <td>-0.732770</td>\n",
       "      <td>-0.153063</td>\n",
       "      <td>1.778140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8691</th>\n",
       "      <td>-0.174191</td>\n",
       "      <td>-0.313741</td>\n",
       "      <td>-0.30661</td>\n",
       "      <td>-0.241218</td>\n",
       "      <td>2.987225</td>\n",
       "      <td>-0.724629</td>\n",
       "      <td>-0.645897</td>\n",
       "      <td>-0.02399</td>\n",
       "      <td>-0.968181</td>\n",
       "      <td>0.968181</td>\n",
       "      <td>-1.111173</td>\n",
       "      <td>1.754795</td>\n",
       "      <td>-0.503664</td>\n",
       "      <td>1.956897</td>\n",
       "      <td>-0.317487</td>\n",
       "      <td>-1.532519</td>\n",
       "      <td>1.739733</td>\n",
       "      <td>-0.491161</td>\n",
       "      <td>1.111690</td>\n",
       "      <td>-0.333105</td>\n",
       "      <td>0.376365</td>\n",
       "      <td>-0.283579</td>\n",
       "      <td>0.043013</td>\n",
       "      <td>2.589576</td>\n",
       "      <td>0.221232</td>\n",
       "      <td>-0.732770</td>\n",
       "      <td>-0.153063</td>\n",
       "      <td>0.015102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8692</th>\n",
       "      <td>-0.174191</td>\n",
       "      <td>-0.313741</td>\n",
       "      <td>-0.30661</td>\n",
       "      <td>-0.241218</td>\n",
       "      <td>2.987225</td>\n",
       "      <td>-0.724629</td>\n",
       "      <td>-0.645897</td>\n",
       "      <td>-0.02399</td>\n",
       "      <td>-0.968181</td>\n",
       "      <td>0.968181</td>\n",
       "      <td>-1.111173</td>\n",
       "      <td>1.754795</td>\n",
       "      <td>-0.503664</td>\n",
       "      <td>-0.511013</td>\n",
       "      <td>-0.317487</td>\n",
       "      <td>0.652521</td>\n",
       "      <td>1.739733</td>\n",
       "      <td>0.457443</td>\n",
       "      <td>1.111690</td>\n",
       "      <td>-0.142335</td>\n",
       "      <td>2.656871</td>\n",
       "      <td>-0.283579</td>\n",
       "      <td>-0.270626</td>\n",
       "      <td>-0.252422</td>\n",
       "      <td>1.058155</td>\n",
       "      <td>-0.732770</td>\n",
       "      <td>-0.153063</td>\n",
       "      <td>0.015102</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8693 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Cabin_A_A  Cabin_A_B  Cabin_A_C  Cabin_A_D  Cabin_A_E  Cabin_A_F  \\\n",
       "0     -0.174191   3.187347   -0.30661  -0.241218  -0.334759  -0.724629   \n",
       "1     -0.174191  -0.313741   -0.30661  -0.241218  -0.334759   1.380016   \n",
       "2      5.740821  -0.313741   -0.30661  -0.241218  -0.334759  -0.724629   \n",
       "3      5.740821  -0.313741   -0.30661  -0.241218  -0.334759  -0.724629   \n",
       "4     -0.174191  -0.313741   -0.30661  -0.241218  -0.334759   1.380016   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "8688   5.740821  -0.313741   -0.30661  -0.241218  -0.334759  -0.724629   \n",
       "8689  -0.174191  -0.313741   -0.30661  -0.241218  -0.334759  -0.724629   \n",
       "8690  -0.174191  -0.313741   -0.30661  -0.241218  -0.334759  -0.724629   \n",
       "8691  -0.174191  -0.313741   -0.30661  -0.241218   2.987225  -0.724629   \n",
       "8692  -0.174191  -0.313741   -0.30661  -0.241218   2.987225  -0.724629   \n",
       "\n",
       "      Cabin_A_G  Cabin_A_T  Cabin_C_P  Cabin_C_S  HomePlanet_Earth  \\\n",
       "0     -0.645897   -0.02399   1.032865  -1.032865         -1.111173   \n",
       "1     -0.645897   -0.02399  -0.968181   0.968181          0.899950   \n",
       "2     -0.645897   -0.02399  -0.968181   0.968181         -1.111173   \n",
       "3     -0.645897   -0.02399  -0.968181   0.968181         -1.111173   \n",
       "4     -0.645897   -0.02399  -0.968181   0.968181          0.899950   \n",
       "...         ...        ...        ...        ...               ...   \n",
       "8688  -0.645897   -0.02399   1.032865  -1.032865         -1.111173   \n",
       "8689   1.548235   -0.02399  -0.968181   0.968181          0.899950   \n",
       "8690   1.548235   -0.02399  -0.968181   0.968181          0.899950   \n",
       "8691  -0.645897   -0.02399  -0.968181   0.968181         -1.111173   \n",
       "8692  -0.645897   -0.02399  -0.968181   0.968181         -1.111173   \n",
       "\n",
       "      HomePlanet_Europa  HomePlanet_Mars  Destination_55 Cancri e  \\\n",
       "0              1.754795        -0.503664                -0.511013   \n",
       "1             -0.569867        -0.503664                -0.511013   \n",
       "2              1.754795        -0.503664                -0.511013   \n",
       "3              1.754795        -0.503664                -0.511013   \n",
       "4             -0.569867        -0.503664                -0.511013   \n",
       "...                 ...              ...                      ...   \n",
       "8688           1.754795        -0.503664                 1.956897   \n",
       "8689          -0.569867        -0.503664                -0.511013   \n",
       "8690          -0.569867        -0.503664                -0.511013   \n",
       "8691           1.754795        -0.503664                 1.956897   \n",
       "8692           1.754795        -0.503664                -0.511013   \n",
       "\n",
       "      Destination_PSO J318.5-22  Destination_TRAPPIST-1e  PassengerId_A  \\\n",
       "0                     -0.317487                 0.652521      -1.734409   \n",
       "1                     -0.317487                 0.652521      -1.734034   \n",
       "2                     -0.317487                 0.652521      -1.733660   \n",
       "3                     -0.317487                 0.652521      -1.733660   \n",
       "4                     -0.317487                 0.652521      -1.733286   \n",
       "...                         ...                      ...            ...   \n",
       "8688                  -0.317487                -1.532519       1.738236   \n",
       "8689                   3.149739                -1.532519       1.738984   \n",
       "8690                  -0.317487                 0.652521       1.739359   \n",
       "8691                  -0.317487                -1.532519       1.739733   \n",
       "8692                  -0.317487                 0.652521       1.739733   \n",
       "\n",
       "      PassengerId_B  traveling_in_group  RoomService  FoodCourt  ShoppingMall  \\\n",
       "0         -0.491161           -0.899532    -0.333105  -0.281027     -0.283579   \n",
       "1         -0.491161           -0.899532    -0.168073  -0.275387     -0.241771   \n",
       "2         -0.491161            1.111690    -0.268001   1.959998     -0.283579   \n",
       "3          0.457443            1.111690    -0.333105   0.523010      0.336851   \n",
       "4         -0.491161           -0.899532     0.125652  -0.237159     -0.031059   \n",
       "...             ...                 ...          ...        ...           ...   \n",
       "8688      -0.491161           -0.899532    -0.333105   3.992336     -0.283579   \n",
       "8689      -0.491161           -0.899532    -0.333105  -0.281027     -0.283579   \n",
       "8690      -0.491161           -0.899532    -0.333105  -0.281027      2.846999   \n",
       "8691      -0.491161            1.111690    -0.333105   0.376365     -0.283579   \n",
       "8692       0.457443            1.111690    -0.142335   2.656871     -0.283579   \n",
       "\n",
       "           Spa    VRDeck       Age  CryoSleep_bool  VIP_bool   Cabin_B  \n",
       "0    -0.270626 -0.263003  0.709437       -0.732770 -0.153063 -1.186610  \n",
       "1     0.217158 -0.224205 -0.336717       -0.732770 -0.153063 -1.186610  \n",
       "2     5.695623 -0.219796  2.034566       -0.732770  6.533255 -1.186610  \n",
       "3     2.687176 -0.092818  0.290975       -0.732770 -0.153063 -1.186610  \n",
       "4     0.231374 -0.261240 -0.894666       -0.732770 -0.153063 -1.184634  \n",
       "...        ...       ...       ...             ...       ...       ...  \n",
       "8688  1.189173 -0.197751  0.848924       -0.732770  6.533255 -0.992913  \n",
       "8689 -0.270626 -0.263003 -0.755179        1.364685 -0.153063  1.776164  \n",
       "8690 -0.269737 -0.263003 -0.197230       -0.732770 -0.153063  1.778140  \n",
       "8691  0.043013  2.589576  0.221232       -0.732770 -0.153063  0.015102  \n",
       "8692 -0.270626 -0.252422  1.058155       -0.732770 -0.153063  0.015102  \n",
       "\n",
       "[8693 rows x 28 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_X_train_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f4e3632e-bddc-4864-9a82-eef511d62db4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cabin_A_A</th>\n",
       "      <th>Cabin_A_B</th>\n",
       "      <th>Cabin_A_C</th>\n",
       "      <th>Cabin_A_D</th>\n",
       "      <th>Cabin_A_E</th>\n",
       "      <th>Cabin_A_F</th>\n",
       "      <th>Cabin_A_G</th>\n",
       "      <th>Cabin_A_T</th>\n",
       "      <th>Cabin_C_P</th>\n",
       "      <th>Cabin_C_S</th>\n",
       "      <th>HomePlanet_Earth</th>\n",
       "      <th>HomePlanet_Europa</th>\n",
       "      <th>HomePlanet_Mars</th>\n",
       "      <th>Destination_55 Cancri e</th>\n",
       "      <th>Destination_PSO J318.5-22</th>\n",
       "      <th>Destination_TRAPPIST-1e</th>\n",
       "      <th>PassengerId_A</th>\n",
       "      <th>PassengerId_B</th>\n",
       "      <th>traveling_in_group</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Age</th>\n",
       "      <th>CryoSleep_bool</th>\n",
       "      <th>VIP_bool</th>\n",
       "      <th>Cabin_B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.174191</td>\n",
       "      <td>-0.313741</td>\n",
       "      <td>-0.306610</td>\n",
       "      <td>-0.241218</td>\n",
       "      <td>-0.334759</td>\n",
       "      <td>-0.724629</td>\n",
       "      <td>1.548235</td>\n",
       "      <td>-0.02399</td>\n",
       "      <td>-0.968181</td>\n",
       "      <td>0.968181</td>\n",
       "      <td>0.899950</td>\n",
       "      <td>-0.569867</td>\n",
       "      <td>-0.503664</td>\n",
       "      <td>-0.511013</td>\n",
       "      <td>-0.317487</td>\n",
       "      <td>0.652521</td>\n",
       "      <td>-1.729916</td>\n",
       "      <td>-0.491161</td>\n",
       "      <td>-0.899532</td>\n",
       "      <td>-0.333105</td>\n",
       "      <td>-0.281027</td>\n",
       "      <td>-0.283579</td>\n",
       "      <td>-0.270626</td>\n",
       "      <td>-0.263003</td>\n",
       "      <td>-1.274865e-01</td>\n",
       "      <td>1.364685</td>\n",
       "      <td>-0.153063</td>\n",
       "      <td>-1.180681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.174191</td>\n",
       "      <td>-0.313741</td>\n",
       "      <td>-0.306610</td>\n",
       "      <td>-0.241218</td>\n",
       "      <td>-0.334759</td>\n",
       "      <td>1.380016</td>\n",
       "      <td>-0.645897</td>\n",
       "      <td>-0.02399</td>\n",
       "      <td>-0.968181</td>\n",
       "      <td>0.968181</td>\n",
       "      <td>0.899950</td>\n",
       "      <td>-0.569867</td>\n",
       "      <td>-0.503664</td>\n",
       "      <td>-0.511013</td>\n",
       "      <td>-0.317487</td>\n",
       "      <td>0.652521</td>\n",
       "      <td>-1.728044</td>\n",
       "      <td>-0.491161</td>\n",
       "      <td>-0.899532</td>\n",
       "      <td>-0.333105</td>\n",
       "      <td>-0.275387</td>\n",
       "      <td>-0.283579</td>\n",
       "      <td>2.237598</td>\n",
       "      <td>-0.263003</td>\n",
       "      <td>-6.854354e-01</td>\n",
       "      <td>-0.732770</td>\n",
       "      <td>-0.153063</td>\n",
       "      <td>-1.178704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.174191</td>\n",
       "      <td>-0.313741</td>\n",
       "      <td>3.261474</td>\n",
       "      <td>-0.241218</td>\n",
       "      <td>-0.334759</td>\n",
       "      <td>-0.724629</td>\n",
       "      <td>-0.645897</td>\n",
       "      <td>-0.02399</td>\n",
       "      <td>-0.968181</td>\n",
       "      <td>0.968181</td>\n",
       "      <td>-1.111173</td>\n",
       "      <td>1.754795</td>\n",
       "      <td>-0.503664</td>\n",
       "      <td>1.956897</td>\n",
       "      <td>-0.317487</td>\n",
       "      <td>-1.532519</td>\n",
       "      <td>-1.727669</td>\n",
       "      <td>-0.491161</td>\n",
       "      <td>-0.899532</td>\n",
       "      <td>-0.333105</td>\n",
       "      <td>-0.281027</td>\n",
       "      <td>-0.283579</td>\n",
       "      <td>-0.270626</td>\n",
       "      <td>-0.263003</td>\n",
       "      <td>1.514880e-01</td>\n",
       "      <td>1.364685</td>\n",
       "      <td>-0.153063</td>\n",
       "      <td>-1.186610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.174191</td>\n",
       "      <td>-0.313741</td>\n",
       "      <td>3.261474</td>\n",
       "      <td>-0.241218</td>\n",
       "      <td>-0.334759</td>\n",
       "      <td>-0.724629</td>\n",
       "      <td>-0.645897</td>\n",
       "      <td>-0.02399</td>\n",
       "      <td>-0.968181</td>\n",
       "      <td>0.968181</td>\n",
       "      <td>-1.111173</td>\n",
       "      <td>1.754795</td>\n",
       "      <td>-0.503664</td>\n",
       "      <td>-0.511013</td>\n",
       "      <td>-0.317487</td>\n",
       "      <td>0.652521</td>\n",
       "      <td>-1.726921</td>\n",
       "      <td>-0.491161</td>\n",
       "      <td>-0.899532</td>\n",
       "      <td>-0.333105</td>\n",
       "      <td>3.887680</td>\n",
       "      <td>-0.283579</td>\n",
       "      <td>-0.109808</td>\n",
       "      <td>0.252842</td>\n",
       "      <td>6.396933e-01</td>\n",
       "      <td>-0.732770</td>\n",
       "      <td>-0.153063</td>\n",
       "      <td>-1.184634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.174191</td>\n",
       "      <td>-0.313741</td>\n",
       "      <td>-0.306610</td>\n",
       "      <td>-0.241218</td>\n",
       "      <td>-0.334759</td>\n",
       "      <td>1.380016</td>\n",
       "      <td>-0.645897</td>\n",
       "      <td>-0.02399</td>\n",
       "      <td>-0.968181</td>\n",
       "      <td>0.968181</td>\n",
       "      <td>0.899950</td>\n",
       "      <td>-0.569867</td>\n",
       "      <td>-0.503664</td>\n",
       "      <td>-0.511013</td>\n",
       "      <td>-0.317487</td>\n",
       "      <td>0.652521</td>\n",
       "      <td>-1.726172</td>\n",
       "      <td>-0.491161</td>\n",
       "      <td>-0.899532</td>\n",
       "      <td>-0.317964</td>\n",
       "      <td>-0.281027</td>\n",
       "      <td>0.778343</td>\n",
       "      <td>-0.270626</td>\n",
       "      <td>-0.263003</td>\n",
       "      <td>-6.156918e-01</td>\n",
       "      <td>-0.732770</td>\n",
       "      <td>-0.153063</td>\n",
       "      <td>-1.176728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4272</th>\n",
       "      <td>-0.174191</td>\n",
       "      <td>-0.313741</td>\n",
       "      <td>-0.306610</td>\n",
       "      <td>-0.241218</td>\n",
       "      <td>-0.334759</td>\n",
       "      <td>-0.724629</td>\n",
       "      <td>1.548235</td>\n",
       "      <td>-0.02399</td>\n",
       "      <td>-0.968181</td>\n",
       "      <td>0.968181</td>\n",
       "      <td>0.899950</td>\n",
       "      <td>-0.569867</td>\n",
       "      <td>-0.503664</td>\n",
       "      <td>-0.511013</td>\n",
       "      <td>-0.317487</td>\n",
       "      <td>0.652521</td>\n",
       "      <td>1.734492</td>\n",
       "      <td>0.457443</td>\n",
       "      <td>1.111690</td>\n",
       "      <td>-0.333105</td>\n",
       "      <td>-0.281027</td>\n",
       "      <td>-0.283579</td>\n",
       "      <td>-0.270626</td>\n",
       "      <td>-0.263003</td>\n",
       "      <td>3.607188e-01</td>\n",
       "      <td>1.364685</td>\n",
       "      <td>-0.153063</td>\n",
       "      <td>1.770234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4273</th>\n",
       "      <td>-0.174191</td>\n",
       "      <td>-0.313741</td>\n",
       "      <td>-0.306610</td>\n",
       "      <td>-0.241218</td>\n",
       "      <td>-0.334759</td>\n",
       "      <td>1.380016</td>\n",
       "      <td>-0.645897</td>\n",
       "      <td>-0.02399</td>\n",
       "      <td>-0.968181</td>\n",
       "      <td>0.968181</td>\n",
       "      <td>0.899950</td>\n",
       "      <td>-0.569867</td>\n",
       "      <td>-0.503664</td>\n",
       "      <td>-0.511013</td>\n",
       "      <td>-0.317487</td>\n",
       "      <td>0.652521</td>\n",
       "      <td>1.735615</td>\n",
       "      <td>-0.491161</td>\n",
       "      <td>-0.899532</td>\n",
       "      <td>-0.333105</td>\n",
       "      <td>0.249775</td>\n",
       "      <td>-0.255149</td>\n",
       "      <td>-0.261741</td>\n",
       "      <td>-0.136026</td>\n",
       "      <td>9.186678e-01</td>\n",
       "      <td>-0.732770</td>\n",
       "      <td>-0.153063</td>\n",
       "      <td>0.019055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4274</th>\n",
       "      <td>-0.174191</td>\n",
       "      <td>-0.313741</td>\n",
       "      <td>-0.306610</td>\n",
       "      <td>4.145623</td>\n",
       "      <td>-0.334759</td>\n",
       "      <td>-0.724629</td>\n",
       "      <td>-0.645897</td>\n",
       "      <td>-0.02399</td>\n",
       "      <td>1.032865</td>\n",
       "      <td>-1.032865</td>\n",
       "      <td>-1.111173</td>\n",
       "      <td>-0.569867</td>\n",
       "      <td>1.985450</td>\n",
       "      <td>1.956897</td>\n",
       "      <td>-0.317487</td>\n",
       "      <td>-1.532519</td>\n",
       "      <td>1.736364</td>\n",
       "      <td>-0.491161</td>\n",
       "      <td>-0.899532</td>\n",
       "      <td>-0.333105</td>\n",
       "      <td>-0.281027</td>\n",
       "      <td>-0.283579</td>\n",
       "      <td>-0.270626</td>\n",
       "      <td>-0.263003</td>\n",
       "      <td>-2.477791e-16</td>\n",
       "      <td>1.364685</td>\n",
       "      <td>-0.153063</td>\n",
       "      <td>-0.601566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4275</th>\n",
       "      <td>-0.174191</td>\n",
       "      <td>-0.313741</td>\n",
       "      <td>-0.306610</td>\n",
       "      <td>4.145623</td>\n",
       "      <td>-0.334759</td>\n",
       "      <td>-0.724629</td>\n",
       "      <td>-0.645897</td>\n",
       "      <td>-0.02399</td>\n",
       "      <td>1.032865</td>\n",
       "      <td>-1.032865</td>\n",
       "      <td>-1.111173</td>\n",
       "      <td>1.754795</td>\n",
       "      <td>-0.503664</td>\n",
       "      <td>-0.511013</td>\n",
       "      <td>-0.317487</td>\n",
       "      <td>0.652521</td>\n",
       "      <td>1.737112</td>\n",
       "      <td>-0.491161</td>\n",
       "      <td>-0.899532</td>\n",
       "      <td>-0.333105</td>\n",
       "      <td>1.398488</td>\n",
       "      <td>-0.283579</td>\n",
       "      <td>-0.270626</td>\n",
       "      <td>0.198171</td>\n",
       "      <td>-2.477791e-16</td>\n",
       "      <td>-0.732770</td>\n",
       "      <td>-0.153063</td>\n",
       "      <td>-0.599590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4276</th>\n",
       "      <td>-0.174191</td>\n",
       "      <td>-0.313741</td>\n",
       "      <td>-0.306610</td>\n",
       "      <td>-0.241218</td>\n",
       "      <td>-0.334759</td>\n",
       "      <td>-0.724629</td>\n",
       "      <td>1.548235</td>\n",
       "      <td>-0.02399</td>\n",
       "      <td>-0.968181</td>\n",
       "      <td>0.968181</td>\n",
       "      <td>0.899950</td>\n",
       "      <td>-0.569867</td>\n",
       "      <td>-0.503664</td>\n",
       "      <td>-0.511013</td>\n",
       "      <td>3.149739</td>\n",
       "      <td>-1.532519</td>\n",
       "      <td>1.738610</td>\n",
       "      <td>-0.491161</td>\n",
       "      <td>-0.899532</td>\n",
       "      <td>-0.333105</td>\n",
       "      <td>-0.281027</td>\n",
       "      <td>-0.283579</td>\n",
       "      <td>-0.270626</td>\n",
       "      <td>-0.263003</td>\n",
       "      <td>9.884114e-01</td>\n",
       "      <td>1.364685</td>\n",
       "      <td>-0.153063</td>\n",
       "      <td>1.774187</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4277 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Cabin_A_A  Cabin_A_B  Cabin_A_C  Cabin_A_D  Cabin_A_E  Cabin_A_F  \\\n",
       "0     -0.174191  -0.313741  -0.306610  -0.241218  -0.334759  -0.724629   \n",
       "1     -0.174191  -0.313741  -0.306610  -0.241218  -0.334759   1.380016   \n",
       "2     -0.174191  -0.313741   3.261474  -0.241218  -0.334759  -0.724629   \n",
       "3     -0.174191  -0.313741   3.261474  -0.241218  -0.334759  -0.724629   \n",
       "4     -0.174191  -0.313741  -0.306610  -0.241218  -0.334759   1.380016   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "4272  -0.174191  -0.313741  -0.306610  -0.241218  -0.334759  -0.724629   \n",
       "4273  -0.174191  -0.313741  -0.306610  -0.241218  -0.334759   1.380016   \n",
       "4274  -0.174191  -0.313741  -0.306610   4.145623  -0.334759  -0.724629   \n",
       "4275  -0.174191  -0.313741  -0.306610   4.145623  -0.334759  -0.724629   \n",
       "4276  -0.174191  -0.313741  -0.306610  -0.241218  -0.334759  -0.724629   \n",
       "\n",
       "      Cabin_A_G  Cabin_A_T  Cabin_C_P  Cabin_C_S  HomePlanet_Earth  \\\n",
       "0      1.548235   -0.02399  -0.968181   0.968181          0.899950   \n",
       "1     -0.645897   -0.02399  -0.968181   0.968181          0.899950   \n",
       "2     -0.645897   -0.02399  -0.968181   0.968181         -1.111173   \n",
       "3     -0.645897   -0.02399  -0.968181   0.968181         -1.111173   \n",
       "4     -0.645897   -0.02399  -0.968181   0.968181          0.899950   \n",
       "...         ...        ...        ...        ...               ...   \n",
       "4272   1.548235   -0.02399  -0.968181   0.968181          0.899950   \n",
       "4273  -0.645897   -0.02399  -0.968181   0.968181          0.899950   \n",
       "4274  -0.645897   -0.02399   1.032865  -1.032865         -1.111173   \n",
       "4275  -0.645897   -0.02399   1.032865  -1.032865         -1.111173   \n",
       "4276   1.548235   -0.02399  -0.968181   0.968181          0.899950   \n",
       "\n",
       "      HomePlanet_Europa  HomePlanet_Mars  Destination_55 Cancri e  \\\n",
       "0             -0.569867        -0.503664                -0.511013   \n",
       "1             -0.569867        -0.503664                -0.511013   \n",
       "2              1.754795        -0.503664                 1.956897   \n",
       "3              1.754795        -0.503664                -0.511013   \n",
       "4             -0.569867        -0.503664                -0.511013   \n",
       "...                 ...              ...                      ...   \n",
       "4272          -0.569867        -0.503664                -0.511013   \n",
       "4273          -0.569867        -0.503664                -0.511013   \n",
       "4274          -0.569867         1.985450                 1.956897   \n",
       "4275           1.754795        -0.503664                -0.511013   \n",
       "4276          -0.569867        -0.503664                -0.511013   \n",
       "\n",
       "      Destination_PSO J318.5-22  Destination_TRAPPIST-1e  PassengerId_A  \\\n",
       "0                     -0.317487                 0.652521      -1.729916   \n",
       "1                     -0.317487                 0.652521      -1.728044   \n",
       "2                     -0.317487                -1.532519      -1.727669   \n",
       "3                     -0.317487                 0.652521      -1.726921   \n",
       "4                     -0.317487                 0.652521      -1.726172   \n",
       "...                         ...                      ...            ...   \n",
       "4272                  -0.317487                 0.652521       1.734492   \n",
       "4273                  -0.317487                 0.652521       1.735615   \n",
       "4274                  -0.317487                -1.532519       1.736364   \n",
       "4275                  -0.317487                 0.652521       1.737112   \n",
       "4276                   3.149739                -1.532519       1.738610   \n",
       "\n",
       "      PassengerId_B  traveling_in_group  RoomService  FoodCourt  ShoppingMall  \\\n",
       "0         -0.491161           -0.899532    -0.333105  -0.281027     -0.283579   \n",
       "1         -0.491161           -0.899532    -0.333105  -0.275387     -0.283579   \n",
       "2         -0.491161           -0.899532    -0.333105  -0.281027     -0.283579   \n",
       "3         -0.491161           -0.899532    -0.333105   3.887680     -0.283579   \n",
       "4         -0.491161           -0.899532    -0.317964  -0.281027      0.778343   \n",
       "...             ...                 ...          ...        ...           ...   \n",
       "4272       0.457443            1.111690    -0.333105  -0.281027     -0.283579   \n",
       "4273      -0.491161           -0.899532    -0.333105   0.249775     -0.255149   \n",
       "4274      -0.491161           -0.899532    -0.333105  -0.281027     -0.283579   \n",
       "4275      -0.491161           -0.899532    -0.333105   1.398488     -0.283579   \n",
       "4276      -0.491161           -0.899532    -0.333105  -0.281027     -0.283579   \n",
       "\n",
       "           Spa    VRDeck           Age  CryoSleep_bool  VIP_bool   Cabin_B  \n",
       "0    -0.270626 -0.263003 -1.274865e-01        1.364685 -0.153063 -1.180681  \n",
       "1     2.237598 -0.263003 -6.854354e-01       -0.732770 -0.153063 -1.178704  \n",
       "2    -0.270626 -0.263003  1.514880e-01        1.364685 -0.153063 -1.186610  \n",
       "3    -0.109808  0.252842  6.396933e-01       -0.732770 -0.153063 -1.184634  \n",
       "4    -0.270626 -0.263003 -6.156918e-01       -0.732770 -0.153063 -1.176728  \n",
       "...        ...       ...           ...             ...       ...       ...  \n",
       "4272 -0.270626 -0.263003  3.607188e-01        1.364685 -0.153063  1.770234  \n",
       "4273 -0.261741 -0.136026  9.186678e-01       -0.732770 -0.153063  0.019055  \n",
       "4274 -0.270626 -0.263003 -2.477791e-16        1.364685 -0.153063 -0.601566  \n",
       "4275 -0.270626  0.198171 -2.477791e-16       -0.732770 -0.153063 -0.599590  \n",
       "4276 -0.270626 -0.263003  9.884114e-01        1.364685 -0.153063  1.774187  \n",
       "\n",
       "[4277 rows x 28 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_X_test_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f58b3b6-b383-4014-9fa5-9d66ff9a90bd",
   "metadata": {},
   "source": [
    "# Begin Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eca1a59f-260b-4e37-9143-9f63d73e7087",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-47\" type=\"checkbox\" checked><label for=\"sk-estimator-id-47\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(_X_train_scaled, _y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "22d776a1-2ba1-491e-b538-d964bf527d85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Transported</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0013_01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0018_01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0019_01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0021_01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0023_01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4272</th>\n",
       "      <td>9266_02</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4273</th>\n",
       "      <td>9269_01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4274</th>\n",
       "      <td>9271_01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4275</th>\n",
       "      <td>9273_01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4276</th>\n",
       "      <td>9277_01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4277 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Transported\n",
       "0        0013_01         True\n",
       "1        0018_01        False\n",
       "2        0019_01         True\n",
       "3        0021_01         True\n",
       "4        0023_01         True\n",
       "...          ...          ...\n",
       "4272     9266_02         True\n",
       "4273     9269_01         True\n",
       "4274     9271_01         True\n",
       "4275     9273_01         True\n",
       "4276     9277_01         True\n",
       "\n",
       "[4277 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = lr.predict(_X_test_scaled)\n",
    "\n",
    "submission = pd.DataFrame({'PassengerId':_X_test['PassengerId'], 'Transported':y_pred})\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a4fae31b-644e-4b00-8385-3effeecb3a69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4277,), array([ True, False,  True, ...,  True,  True,  True]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "12214bc2-95dd-41b9-b662-86535cd98612",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('./kaggle/input/spaceship-titanic/submission.csv', index=None)\n",
    "\n",
    "#DBD BASELINE ACCURACY. 0.79261\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4ae5b616-3b9e-4d7a-9fa4-f70ff05ed391",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId_A                0.033738\n",
       "VRDeck                       0.032983\n",
       "Cabin_A_T                    0.026255\n",
       "Cabin_B                      0.026036\n",
       "Cabin_A_G                    0.024265\n",
       "Age                          0.022374\n",
       "HomePlanet_Mars              0.018142\n",
       "CryoSleep_bool               0.016377\n",
       "RoomService                  0.010605\n",
       "Cabin_A_A                    0.005123\n",
       "VIP_bool                     0.004439\n",
       "Destination_PSO J318.5-22    0.004050\n",
       "Cabin_A_D                    0.002117\n",
       "Destination_55 Cancri e      0.001836\n",
       "Cabin_C_P                    0.000785\n",
       "traveling_in_group          -0.000111\n",
       "Cabin_C_S                   -0.000785\n",
       "HomePlanet_Earth            -0.002552\n",
       "Destination_TRAPPIST-1e     -0.004183\n",
       "PassengerId_B               -0.004523\n",
       "Cabin_A_E                   -0.006159\n",
       "Cabin_A_F                   -0.006498\n",
       "FoodCourt                   -0.008416\n",
       "Cabin_A_C                   -0.011134\n",
       "ShoppingMall                -0.011225\n",
       "HomePlanet_Europa           -0.014636\n",
       "Spa                         -0.016076\n",
       "Cabin_A_B                   -0.018404\n",
       "dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_X_test_scaled.corrwith(_y_train).sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a5fd56c3-c782-4aee-a687-ca619b747b02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       False\n",
       "1        True\n",
       "2       False\n",
       "3       False\n",
       "4        True\n",
       "        ...  \n",
       "8688    False\n",
       "8689    False\n",
       "8690     True\n",
       "8691    False\n",
       "8692     True\n",
       "Name: Transported, Length: 8693, dtype: bool"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_y_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e4681a19-e6b3-4928-93e1-65ecdcec3824",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize= (10,10))\n",
    "# sns.heatmap(airbnb.corr())\n",
    "# plt.title(\"Correlation\",fontsize=15)\n",
    "# sns.despine()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974f9932-6faf-4454-9166-916317d71ba5",
   "metadata": {},
   "source": [
    "### AutoML\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1d38c4d5-76e1-4277-beb1-04e621a25b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split( _X_train_scaled, _y_train, test_size=0.3)\n",
    "X_train.shape, X_val.shape, y_train.shape, y_val.shape\n",
    "\n",
    "full_train = X_train.copy()\n",
    "full_train['target'] = y_train\n",
    "\n",
    "full_val = X_val.copy()\n",
    "full_val['target'] = y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7b94a105-5f20-4849-ad28-44f4e1dada46",
   "metadata": {},
   "outputs": [],
   "source": [
    "do_automl = False\n",
    "\n",
    "# !! pip install h2o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e715194f-a23e-4d7c-aa70-3f10ba93396d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if do_automl:\n",
    "\n",
    "    import h2o\n",
    "    from h2o.automl import H2OAutoML\n",
    "    h2o.init()\n",
    "    \n",
    "    aml = H2OAutoML(max_models =25,\n",
    "                    # balance_classes=True,\n",
    "                    seed=1)\n",
    "\n",
    "    h2o_train = h2o.H2OFrame(full_train)\n",
    "    aml.train(training_frame=h2o_train, y='target')\n",
    "    \n",
    "    lb = aml.leaderboard\n",
    "    lb.head(rows=lb.nrows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f0539df4-ab50-4a21-8f84-89836f1bd748",
   "metadata": {},
   "outputs": [],
   "source": [
    "if do_automl:\n",
    "    best_model = aml.get_best_model()\n",
    "    print(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d66b6008-1902-469d-bfe9-c39d208235ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "if do_automl:\n",
    "    h2o_val = h2o.H2OFrame(full_val)\n",
    "    best_model.model_performance(h2o_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2be88731-fc07-4915-9dd1-22b8c0801fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if do_automl:\n",
    "    y_pred_best_model = best_model.predict(h2o.H2OFrame(_X_test_scaled))\n",
    "    y_pred_best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "65234b3c-ed48-4763-8ede-1be4bf2a277c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if do_automl:\n",
    "    y_pred_best_model_df = y_pred_best_model.as_data_frame()\n",
    "    y_pred_best_model_df = y_pred_best_model_df.drop(columns=['False', 'True'])\n",
    "    y_pred_best_model_df.columns = ['Transported']\n",
    "    y_pred_best_model_df['PassengerId'] = _X_test['PassengerId']\n",
    "    y_pred_best_model_df.to_csv('./kaggle/input/spaceship-titanic/best_model_pred.csv', index=0)\n",
    "    \n",
    "    y_pred_best_model_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3273b62e-fa0d-4668-a1af-caf84f560a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# explain_model = aml.explain(frame = h2o_train, figsize = (8,6))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c74fd6-8a4b-481c-a385-3f1487e37834",
   "metadata": {},
   "source": [
    "## Dense Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f51b86c5-b4da-40b8-becd-f206cfc0a69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(history, metric='acc'):\n",
    "    fig, (ax1, ax2) = plt.subplots(1,2, figsize=(13,4))\n",
    "    ax1.plot(history.history['loss'])\n",
    "    ax1.plot(history.history['val_loss'])\n",
    "    ax1.set_title('Model loss')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylim(ymin=0, ymax=1)\n",
    "    ax1.legend(['Train', 'Validation'], loc='best')\n",
    "    ax1.grid(axis=\"x\",linewidth=0.5)\n",
    "    ax1.grid(axis=\"y\",linewidth=0.5)    \n",
    "    \n",
    "    ax2.plot(history.history[f'{metric}'])\n",
    "    ax2.plot(history.history[f'val_{metric}'])\n",
    "    ax2.set_title(f'{metric}')\n",
    "    ax2.set_ylabel(f'{metric}')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylim(ymin=0, ymax=1)\n",
    "    ax2.legend(['Train', 'Validation'], loc='best')\n",
    "    ax2.grid(axis=\"x\",linewidth=0.5)\n",
    "    ax2.grid(axis=\"y\",linewidth=0.5)    \n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dbdc0dde-213e-4939-a9d5-153255a002de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "def initialize_model():\n",
    "    model = models.Sequential()\n",
    "    \n",
    "    model.add(layers.Dense(40, activation='relu', input_dim=X_train.shape[-1]))\n",
    "    model.add(layers.Dropout(.1))\n",
    "    model.add(layers.Dense(20, activation='relu'))\n",
    "    # model.add(layers.Dropout(.1))\n",
    "    model.add(layers.Dense(20, activation='relu'))\n",
    "    # model.add(layers.Dropout(.1))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "       \n",
    "    return model\n",
    "\n",
    "def compile_model(model, name):\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                 optimizer=name,\n",
    "                 metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "645a586f-cb83-4a74-b667-8cbdd354e064",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-29 16:12:59.368114: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82/82 [==============================] - 0s 346us/step - loss: 0.4104 - acc: 0.7914\n",
      "adam:: train_accuracy: 0.8201236065397871, val_accuracy: 0.8231612469287629, test_accuracy: 0.7914110422134399\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "best_test_accuracy = None\n",
    "best_model = None\n",
    "optimizers = ['adam']#, 'sgd', 'adadelta', 'adagrad', 'rmsprop']\n",
    "\n",
    "for optimizer in optimizers:\n",
    "    model = initialize_model()\n",
    "\n",
    "    # optimizer = 'adam'\n",
    "    compile_model(model, optimizer)\n",
    "\n",
    "    es = EarlyStopping(patience=30, restore_best_weights=True)\n",
    "\n",
    "    history = model.fit(X_train, \n",
    "                        y_train,\n",
    "                        validation_split=.2,\n",
    "                        epochs=500,\n",
    "                        batch_size=8,\n",
    "                        callbacks = [es],\n",
    "                        verbose=0,\n",
    "                       )\n",
    "        \n",
    "    test_accuracy = model.evaluate(X_val, y_val)[1]\n",
    "    if (best_test_accuracy is None) or (best_test_accuracy < test_accuracy):\n",
    "        best_test_accuracy = test_accuracy\n",
    "        best_model = model\n",
    "\n",
    "    print(f'{optimizer}:: train_accuracy: {np.mean(history.history[\"acc\"])}, val_accuracy: {np.mean(history.history[\"val_acc\"])}, test_accuracy: {test_accuracy}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f2303ef7-c3e1-4326-9cdf-30f3d6868bd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 936x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "02e1a579-5a9c-49db-8962-5848e4559f7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 0s 360us/step\n"
     ]
    }
   ],
   "source": [
    "y_pred_best_model = best_model.predict(_X_test_scaled)\n",
    "y_pred_best_model = ['True' if x>.6 else 'False' for x in y_pred_best_model]\n",
    "# y_pred_best_model\n",
    "\n",
    "y_pred_best_model_df = pd.DataFrame({'Transported':y_pred_best_model, 'PassengerId':_X_test['PassengerId']})\n",
    "# y_pred_best_model_df\n",
    "y_pred_best_model_df['Transported'].value_counts()\n",
    "\n",
    "y_pred_best_model_df.to_csv('./kaggle/input/spaceship-titanic/neural_network_pred.csv', index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc0d046-45ac-4207-b181-955228e6110e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "df23a978-8f07-448c-bd48-e9a7875a18e1",
   "metadata": {},
   "source": [
    "### Neural Network #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "991443d6-fb2d-4ae8-895b-3f444680cfce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "\n",
    "def build_classifier(optimizer):\n",
    "    classifier = Sequential()\n",
    "    classifier.add(Dense(units=10,kernel_initializer='uniform',activation='relu',input_dim=X_train.shape[-1]))\n",
    "    classifier.add(Dropout(rate = 0.2))\n",
    "    classifier.add(Dense(units=128,kernel_initializer='uniform',activation='relu'))\n",
    "    classifier.add(Dropout(rate = 0.2))\n",
    "    classifier.add(Dense(units=1,kernel_initializer='uniform',activation='sigmoid'))\n",
    "    classifier.compile(optimizer=optimizer,loss='binary_crossentropy',metrics=['accuracy'])\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "25df88ec-782e-42dc-97e1-880cc6664013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qp/5z2vy03j04s0yht5rwlccksw0000gn/T/ipykernel_58696/2392746968.py:3: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  classifier = KerasClassifier(build_fn = build_classifier)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "305/305 [==============================] - 0s 451us/step - loss: 0.5497 - accuracy: 0.7159\n",
      "Epoch 2/100\n",
      "305/305 [==============================] - 0s 426us/step - loss: 0.4458 - accuracy: 0.7833\n",
      "Epoch 3/100\n",
      "305/305 [==============================] - 0s 438us/step - loss: 0.4310 - accuracy: 0.7890\n",
      "Epoch 4/100\n",
      "305/305 [==============================] - 0s 422us/step - loss: 0.4256 - accuracy: 0.7919\n",
      "Epoch 5/100\n",
      "305/305 [==============================] - 0s 438us/step - loss: 0.4266 - accuracy: 0.7938\n",
      "Epoch 6/100\n",
      "305/305 [==============================] - 0s 423us/step - loss: 0.4227 - accuracy: 0.7977\n",
      "Epoch 7/100\n",
      "305/305 [==============================] - 0s 422us/step - loss: 0.4190 - accuracy: 0.8032\n",
      "Epoch 8/100\n",
      "305/305 [==============================] - 0s 429us/step - loss: 0.4188 - accuracy: 0.8057\n",
      "Epoch 9/100\n",
      "305/305 [==============================] - 0s 434us/step - loss: 0.4169 - accuracy: 0.7995\n",
      "Epoch 10/100\n",
      "305/305 [==============================] - 0s 435us/step - loss: 0.4165 - accuracy: 0.8034\n",
      "Epoch 11/100\n",
      "305/305 [==============================] - 0s 439us/step - loss: 0.4188 - accuracy: 0.8028\n",
      "Epoch 12/100\n",
      "305/305 [==============================] - 0s 429us/step - loss: 0.4155 - accuracy: 0.8020\n",
      "Epoch 13/100\n",
      "305/305 [==============================] - 0s 426us/step - loss: 0.4113 - accuracy: 0.8063\n",
      "Epoch 14/100\n",
      "305/305 [==============================] - 0s 430us/step - loss: 0.4103 - accuracy: 0.8012\n",
      "Epoch 15/100\n",
      "305/305 [==============================] - 0s 429us/step - loss: 0.4119 - accuracy: 0.8092\n",
      "Epoch 16/100\n",
      "305/305 [==============================] - 0s 425us/step - loss: 0.4134 - accuracy: 0.8038\n",
      "Epoch 17/100\n",
      "305/305 [==============================] - 0s 417us/step - loss: 0.4089 - accuracy: 0.8001\n",
      "Epoch 18/100\n",
      "305/305 [==============================] - 0s 415us/step - loss: 0.4089 - accuracy: 0.8051\n",
      "Epoch 19/100\n",
      "305/305 [==============================] - 0s 418us/step - loss: 0.4108 - accuracy: 0.8075\n",
      "Epoch 20/100\n",
      "305/305 [==============================] - 0s 428us/step - loss: 0.4097 - accuracy: 0.8055\n",
      "Epoch 21/100\n",
      "305/305 [==============================] - 0s 419us/step - loss: 0.4061 - accuracy: 0.8083\n",
      "Epoch 22/100\n",
      "305/305 [==============================] - 0s 415us/step - loss: 0.4109 - accuracy: 0.8042\n",
      "Epoch 23/100\n",
      "305/305 [==============================] - 0s 420us/step - loss: 0.4106 - accuracy: 0.8036\n",
      "Epoch 24/100\n",
      "305/305 [==============================] - 0s 424us/step - loss: 0.4051 - accuracy: 0.8118\n",
      "Epoch 25/100\n",
      "305/305 [==============================] - 0s 416us/step - loss: 0.4021 - accuracy: 0.8098\n",
      "Epoch 26/100\n",
      "305/305 [==============================] - 0s 414us/step - loss: 0.3988 - accuracy: 0.8077\n",
      "Epoch 27/100\n",
      "305/305 [==============================] - 0s 415us/step - loss: 0.4024 - accuracy: 0.8104\n",
      "Epoch 28/100\n",
      "305/305 [==============================] - 0s 418us/step - loss: 0.4025 - accuracy: 0.8083\n",
      "Epoch 29/100\n",
      "305/305 [==============================] - 0s 440us/step - loss: 0.4042 - accuracy: 0.8108\n",
      "Epoch 30/100\n",
      "305/305 [==============================] - 0s 426us/step - loss: 0.4062 - accuracy: 0.8081\n",
      "Epoch 31/100\n",
      "305/305 [==============================] - 0s 446us/step - loss: 0.4018 - accuracy: 0.8030\n",
      "Epoch 32/100\n",
      "305/305 [==============================] - 0s 433us/step - loss: 0.4045 - accuracy: 0.8073\n",
      "Epoch 33/100\n",
      "305/305 [==============================] - 0s 429us/step - loss: 0.4028 - accuracy: 0.8104\n",
      "Epoch 34/100\n",
      "305/305 [==============================] - 0s 470us/step - loss: 0.4026 - accuracy: 0.8040\n",
      "Epoch 35/100\n",
      "305/305 [==============================] - 0s 428us/step - loss: 0.4040 - accuracy: 0.8044\n",
      "Epoch 36/100\n",
      "305/305 [==============================] - 0s 440us/step - loss: 0.3999 - accuracy: 0.8088\n",
      "Epoch 37/100\n",
      "305/305 [==============================] - 0s 436us/step - loss: 0.4015 - accuracy: 0.8077\n",
      "Epoch 38/100\n",
      "305/305 [==============================] - 0s 427us/step - loss: 0.4061 - accuracy: 0.8071\n",
      "Epoch 39/100\n",
      "305/305 [==============================] - 0s 431us/step - loss: 0.3977 - accuracy: 0.8096\n",
      "Epoch 40/100\n",
      "305/305 [==============================] - 0s 439us/step - loss: 0.4003 - accuracy: 0.8110\n",
      "Epoch 41/100\n",
      "305/305 [==============================] - 0s 423us/step - loss: 0.3994 - accuracy: 0.8108\n",
      "Epoch 42/100\n",
      "305/305 [==============================] - 0s 428us/step - loss: 0.3991 - accuracy: 0.8110\n",
      "Epoch 43/100\n",
      "305/305 [==============================] - 0s 804us/step - loss: 0.3970 - accuracy: 0.8061\n",
      "Epoch 44/100\n",
      "305/305 [==============================] - 0s 427us/step - loss: 0.3955 - accuracy: 0.8108\n",
      "Epoch 45/100\n",
      "305/305 [==============================] - 0s 430us/step - loss: 0.4008 - accuracy: 0.8096\n",
      "Epoch 46/100\n",
      "305/305 [==============================] - 0s 429us/step - loss: 0.4028 - accuracy: 0.8051\n",
      "Epoch 47/100\n",
      "305/305 [==============================] - 0s 418us/step - loss: 0.4012 - accuracy: 0.8030\n",
      "Epoch 48/100\n",
      "305/305 [==============================] - 0s 416us/step - loss: 0.3955 - accuracy: 0.8053\n",
      "Epoch 49/100\n",
      "305/305 [==============================] - 0s 412us/step - loss: 0.3970 - accuracy: 0.8112\n",
      "Epoch 50/100\n",
      "305/305 [==============================] - 0s 429us/step - loss: 0.3973 - accuracy: 0.8059\n",
      "Epoch 51/100\n",
      "305/305 [==============================] - 0s 429us/step - loss: 0.3957 - accuracy: 0.8081\n",
      "Epoch 52/100\n",
      "305/305 [==============================] - 0s 446us/step - loss: 0.3934 - accuracy: 0.8139\n",
      "Epoch 53/100\n",
      "305/305 [==============================] - 0s 435us/step - loss: 0.3983 - accuracy: 0.8108\n",
      "Epoch 54/100\n",
      "305/305 [==============================] - 0s 429us/step - loss: 0.3930 - accuracy: 0.8081\n",
      "Epoch 55/100\n",
      "305/305 [==============================] - 0s 422us/step - loss: 0.3935 - accuracy: 0.8059\n",
      "Epoch 56/100\n",
      "305/305 [==============================] - 0s 418us/step - loss: 0.3919 - accuracy: 0.8073\n",
      "Epoch 57/100\n",
      "305/305 [==============================] - 0s 420us/step - loss: 0.3904 - accuracy: 0.8124\n",
      "Epoch 58/100\n",
      "305/305 [==============================] - 0s 424us/step - loss: 0.3991 - accuracy: 0.8048\n",
      "Epoch 59/100\n",
      "305/305 [==============================] - 0s 417us/step - loss: 0.3971 - accuracy: 0.8088\n",
      "Epoch 60/100\n",
      "305/305 [==============================] - 0s 424us/step - loss: 0.3916 - accuracy: 0.8129\n",
      "Epoch 61/100\n",
      "305/305 [==============================] - 0s 438us/step - loss: 0.3885 - accuracy: 0.8139\n",
      "Epoch 62/100\n",
      "305/305 [==============================] - 0s 423us/step - loss: 0.3952 - accuracy: 0.8092\n",
      "Epoch 63/100\n",
      "305/305 [==============================] - 0s 417us/step - loss: 0.3922 - accuracy: 0.8137\n",
      "Epoch 64/100\n",
      "305/305 [==============================] - 0s 415us/step - loss: 0.3892 - accuracy: 0.8131\n",
      "Epoch 65/100\n",
      "305/305 [==============================] - 0s 416us/step - loss: 0.3916 - accuracy: 0.8090\n",
      "Epoch 66/100\n",
      "305/305 [==============================] - 0s 414us/step - loss: 0.3926 - accuracy: 0.8108\n",
      "Epoch 67/100\n",
      "305/305 [==============================] - 0s 409us/step - loss: 0.3920 - accuracy: 0.8102\n",
      "Epoch 68/100\n",
      "305/305 [==============================] - 0s 413us/step - loss: 0.3938 - accuracy: 0.8067\n",
      "Epoch 69/100\n",
      "305/305 [==============================] - 0s 419us/step - loss: 0.3911 - accuracy: 0.8122\n",
      "Epoch 70/100\n",
      "305/305 [==============================] - 0s 426us/step - loss: 0.3938 - accuracy: 0.8116\n",
      "Epoch 71/100\n",
      "305/305 [==============================] - 0s 425us/step - loss: 0.3926 - accuracy: 0.8129\n",
      "Epoch 72/100\n",
      "305/305 [==============================] - 0s 421us/step - loss: 0.3938 - accuracy: 0.8108\n",
      "Epoch 73/100\n",
      "305/305 [==============================] - 0s 425us/step - loss: 0.3947 - accuracy: 0.8110\n",
      "Epoch 74/100\n",
      "305/305 [==============================] - 0s 421us/step - loss: 0.3927 - accuracy: 0.8106\n",
      "Epoch 75/100\n",
      "305/305 [==============================] - 0s 416us/step - loss: 0.3911 - accuracy: 0.8077\n",
      "Epoch 76/100\n",
      "305/305 [==============================] - 0s 417us/step - loss: 0.3901 - accuracy: 0.8118\n",
      "Epoch 77/100\n",
      "305/305 [==============================] - 0s 420us/step - loss: 0.3909 - accuracy: 0.8135\n",
      "Epoch 78/100\n",
      "305/305 [==============================] - 0s 421us/step - loss: 0.3882 - accuracy: 0.8110\n",
      "Epoch 79/100\n",
      "305/305 [==============================] - 0s 417us/step - loss: 0.3915 - accuracy: 0.8096\n",
      "Epoch 80/100\n",
      "305/305 [==============================] - 0s 415us/step - loss: 0.3922 - accuracy: 0.8090\n",
      "Epoch 81/100\n",
      "305/305 [==============================] - 0s 414us/step - loss: 0.3886 - accuracy: 0.8118\n",
      "Epoch 82/100\n",
      "305/305 [==============================] - 0s 416us/step - loss: 0.3930 - accuracy: 0.8081\n",
      "Epoch 83/100\n",
      "305/305 [==============================] - 0s 416us/step - loss: 0.3916 - accuracy: 0.8073\n",
      "Epoch 84/100\n",
      "305/305 [==============================] - 0s 440us/step - loss: 0.3889 - accuracy: 0.8088\n",
      "Epoch 85/100\n",
      "305/305 [==============================] - 0s 428us/step - loss: 0.3891 - accuracy: 0.8135\n",
      "Epoch 86/100\n",
      "305/305 [==============================] - 0s 421us/step - loss: 0.3892 - accuracy: 0.8118\n",
      "Epoch 87/100\n",
      "305/305 [==============================] - 0s 425us/step - loss: 0.3888 - accuracy: 0.8186\n",
      "Epoch 88/100\n",
      "305/305 [==============================] - 0s 420us/step - loss: 0.3893 - accuracy: 0.8108\n",
      "Epoch 89/100\n",
      "305/305 [==============================] - 0s 420us/step - loss: 0.3940 - accuracy: 0.8081\n",
      "Epoch 90/100\n",
      "305/305 [==============================] - 0s 431us/step - loss: 0.3876 - accuracy: 0.8104\n",
      "Epoch 91/100\n",
      "305/305 [==============================] - 0s 427us/step - loss: 0.3900 - accuracy: 0.8114\n",
      "Epoch 92/100\n",
      "305/305 [==============================] - 0s 425us/step - loss: 0.3867 - accuracy: 0.8094\n",
      "Epoch 93/100\n",
      "305/305 [==============================] - 0s 421us/step - loss: 0.3862 - accuracy: 0.8172\n",
      "Epoch 94/100\n",
      "305/305 [==============================] - 0s 422us/step - loss: 0.3874 - accuracy: 0.8122\n",
      "Epoch 95/100\n",
      "305/305 [==============================] - 0s 422us/step - loss: 0.3916 - accuracy: 0.8075\n",
      "Epoch 96/100\n",
      "305/305 [==============================] - 0s 432us/step - loss: 0.3908 - accuracy: 0.8149\n",
      "Epoch 97/100\n",
      "305/305 [==============================] - 0s 419us/step - loss: 0.3875 - accuracy: 0.8098\n",
      "Epoch 98/100\n",
      "305/305 [==============================] - 0s 425us/step - loss: 0.3889 - accuracy: 0.8106\n",
      "Epoch 99/100\n",
      "305/305 [==============================] - 0s 426us/step - loss: 0.3892 - accuracy: 0.8090\n",
      "Epoch 100/100\n",
      "305/305 [==============================] - 0s 422us/step - loss: 0.3883 - accuracy: 0.8164\n",
      "39/39 [==============================] - 0s 323us/step\n",
      "Epoch 1/100\n",
      "305/305 [==============================] - 0s 445us/step - loss: 0.5324 - accuracy: 0.7251\n",
      "Epoch 2/100\n",
      "305/305 [==============================] - 0s 450us/step - loss: 0.4379 - accuracy: 0.7925\n",
      "Epoch 3/100\n",
      "305/305 [==============================] - 0s 444us/step - loss: 0.4285 - accuracy: 0.7952\n",
      "Epoch 4/100\n",
      "305/305 [==============================] - 0s 442us/step - loss: 0.4220 - accuracy: 0.7954\n",
      "Epoch 5/100\n",
      "305/305 [==============================] - 0s 483us/step - loss: 0.4233 - accuracy: 0.7989\n",
      "Epoch 6/100\n",
      "305/305 [==============================] - 0s 458us/step - loss: 0.4203 - accuracy: 0.7997\n",
      "Epoch 7/100\n",
      "305/305 [==============================] - 0s 435us/step - loss: 0.4135 - accuracy: 0.7981\n",
      "Epoch 8/100\n",
      "305/305 [==============================] - 0s 418us/step - loss: 0.4153 - accuracy: 0.7985\n",
      "Epoch 9/100\n",
      "305/305 [==============================] - 0s 422us/step - loss: 0.4171 - accuracy: 0.7995\n",
      "Epoch 10/100\n",
      "305/305 [==============================] - 0s 422us/step - loss: 0.4154 - accuracy: 0.7995\n",
      "Epoch 11/100\n",
      "305/305 [==============================] - 0s 418us/step - loss: 0.4142 - accuracy: 0.7989\n",
      "Epoch 12/100\n",
      "305/305 [==============================] - 0s 431us/step - loss: 0.4158 - accuracy: 0.7977\n",
      "Epoch 13/100\n",
      "305/305 [==============================] - 0s 426us/step - loss: 0.4133 - accuracy: 0.8009\n",
      "Epoch 14/100\n",
      "305/305 [==============================] - 0s 427us/step - loss: 0.4116 - accuracy: 0.7983\n",
      "Epoch 15/100\n",
      "305/305 [==============================] - 0s 431us/step - loss: 0.4132 - accuracy: 0.8018\n",
      "Epoch 16/100\n",
      "305/305 [==============================] - 0s 426us/step - loss: 0.4082 - accuracy: 0.8067\n",
      "Epoch 17/100\n",
      "305/305 [==============================] - 0s 421us/step - loss: 0.4097 - accuracy: 0.8044\n",
      "Epoch 18/100\n",
      "305/305 [==============================] - 0s 418us/step - loss: 0.4069 - accuracy: 0.8071\n",
      "Epoch 19/100\n",
      "305/305 [==============================] - 0s 434us/step - loss: 0.4077 - accuracy: 0.8040\n",
      "Epoch 20/100\n",
      "305/305 [==============================] - 0s 423us/step - loss: 0.4094 - accuracy: 0.8059\n",
      "Epoch 21/100\n",
      "305/305 [==============================] - 0s 425us/step - loss: 0.4077 - accuracy: 0.8034\n",
      "Epoch 22/100\n",
      "305/305 [==============================] - 0s 430us/step - loss: 0.4070 - accuracy: 0.8032\n",
      "Epoch 23/100\n",
      "305/305 [==============================] - 0s 420us/step - loss: 0.4066 - accuracy: 0.8012\n",
      "Epoch 24/100\n",
      "305/305 [==============================] - 0s 433us/step - loss: 0.4085 - accuracy: 0.7993\n",
      "Epoch 25/100\n",
      "305/305 [==============================] - 0s 427us/step - loss: 0.4066 - accuracy: 0.8012\n",
      "Epoch 26/100\n",
      "305/305 [==============================] - 0s 486us/step - loss: 0.4043 - accuracy: 0.8014\n",
      "Epoch 27/100\n",
      "305/305 [==============================] - 0s 429us/step - loss: 0.4003 - accuracy: 0.8065\n",
      "Epoch 28/100\n",
      "305/305 [==============================] - 0s 446us/step - loss: 0.4002 - accuracy: 0.8022\n",
      "Epoch 29/100\n",
      "305/305 [==============================] - 0s 445us/step - loss: 0.4033 - accuracy: 0.7985\n",
      "Epoch 30/100\n",
      "305/305 [==============================] - 0s 424us/step - loss: 0.4002 - accuracy: 0.8100\n",
      "Epoch 31/100\n",
      "305/305 [==============================] - 0s 441us/step - loss: 0.4024 - accuracy: 0.8069\n",
      "Epoch 32/100\n",
      "305/305 [==============================] - 0s 431us/step - loss: 0.4037 - accuracy: 0.8048\n",
      "Epoch 33/100\n",
      "305/305 [==============================] - 0s 429us/step - loss: 0.3955 - accuracy: 0.8083\n",
      "Epoch 34/100\n",
      "305/305 [==============================] - 0s 427us/step - loss: 0.4013 - accuracy: 0.8059\n",
      "Epoch 35/100\n",
      "305/305 [==============================] - 0s 428us/step - loss: 0.4016 - accuracy: 0.7995\n",
      "Epoch 36/100\n",
      "305/305 [==============================] - 0s 473us/step - loss: 0.3971 - accuracy: 0.8083\n",
      "Epoch 37/100\n",
      "305/305 [==============================] - 0s 430us/step - loss: 0.4012 - accuracy: 0.8083\n",
      "Epoch 38/100\n",
      "305/305 [==============================] - 0s 430us/step - loss: 0.3958 - accuracy: 0.8102\n",
      "Epoch 39/100\n",
      "305/305 [==============================] - 0s 440us/step - loss: 0.3964 - accuracy: 0.8106\n",
      "Epoch 40/100\n",
      "305/305 [==============================] - 0s 432us/step - loss: 0.3981 - accuracy: 0.8020\n",
      "Epoch 41/100\n",
      "305/305 [==============================] - 0s 425us/step - loss: 0.3972 - accuracy: 0.8083\n",
      "Epoch 42/100\n",
      "305/305 [==============================] - 0s 440us/step - loss: 0.3882 - accuracy: 0.8090\n",
      "Epoch 43/100\n",
      "305/305 [==============================] - 0s 433us/step - loss: 0.3948 - accuracy: 0.8088\n",
      "Epoch 44/100\n",
      "305/305 [==============================] - 0s 419us/step - loss: 0.3960 - accuracy: 0.8112\n",
      "Epoch 45/100\n",
      "305/305 [==============================] - 0s 417us/step - loss: 0.3901 - accuracy: 0.8139\n",
      "Epoch 46/100\n",
      "305/305 [==============================] - 0s 430us/step - loss: 0.3930 - accuracy: 0.8077\n",
      "Epoch 47/100\n",
      "305/305 [==============================] - 0s 432us/step - loss: 0.3929 - accuracy: 0.8079\n",
      "Epoch 48/100\n",
      "305/305 [==============================] - 0s 420us/step - loss: 0.3912 - accuracy: 0.8036\n",
      "Epoch 49/100\n",
      "305/305 [==============================] - 0s 415us/step - loss: 0.3920 - accuracy: 0.8124\n",
      "Epoch 50/100\n",
      "305/305 [==============================] - 0s 430us/step - loss: 0.3913 - accuracy: 0.8085\n",
      "Epoch 51/100\n",
      "305/305 [==============================] - 0s 419us/step - loss: 0.3922 - accuracy: 0.8059\n",
      "Epoch 52/100\n",
      "305/305 [==============================] - 0s 435us/step - loss: 0.3864 - accuracy: 0.8135\n",
      "Epoch 53/100\n",
      "305/305 [==============================] - 0s 431us/step - loss: 0.3918 - accuracy: 0.8092\n",
      "Epoch 54/100\n",
      "305/305 [==============================] - 0s 427us/step - loss: 0.3905 - accuracy: 0.8055\n",
      "Epoch 55/100\n",
      "305/305 [==============================] - 0s 423us/step - loss: 0.3947 - accuracy: 0.8108\n",
      "Epoch 56/100\n",
      "305/305 [==============================] - 0s 791us/step - loss: 0.3959 - accuracy: 0.8075\n",
      "Epoch 57/100\n",
      "305/305 [==============================] - 0s 481us/step - loss: 0.3955 - accuracy: 0.8018\n",
      "Epoch 58/100\n",
      "305/305 [==============================] - 0s 433us/step - loss: 0.3885 - accuracy: 0.8085\n",
      "Epoch 59/100\n",
      "305/305 [==============================] - 0s 424us/step - loss: 0.3887 - accuracy: 0.8092\n",
      "Epoch 60/100\n",
      "305/305 [==============================] - 0s 423us/step - loss: 0.3873 - accuracy: 0.8044\n",
      "Epoch 61/100\n",
      "305/305 [==============================] - 0s 429us/step - loss: 0.3862 - accuracy: 0.8120\n",
      "Epoch 62/100\n",
      "305/305 [==============================] - 0s 425us/step - loss: 0.3862 - accuracy: 0.8065\n",
      "Epoch 63/100\n",
      "305/305 [==============================] - 0s 429us/step - loss: 0.3905 - accuracy: 0.8051\n",
      "Epoch 64/100\n",
      "305/305 [==============================] - 0s 421us/step - loss: 0.3890 - accuracy: 0.8065\n",
      "Epoch 65/100\n",
      "305/305 [==============================] - 0s 416us/step - loss: 0.3900 - accuracy: 0.8092\n",
      "Epoch 66/100\n",
      "305/305 [==============================] - 0s 452us/step - loss: 0.3892 - accuracy: 0.8106\n",
      "Epoch 67/100\n",
      "305/305 [==============================] - 0s 429us/step - loss: 0.3912 - accuracy: 0.8069\n",
      "Epoch 68/100\n",
      "305/305 [==============================] - 0s 440us/step - loss: 0.3888 - accuracy: 0.8020\n",
      "Epoch 69/100\n",
      "305/305 [==============================] - 0s 428us/step - loss: 0.3938 - accuracy: 0.8063\n",
      "Epoch 70/100\n",
      "305/305 [==============================] - 0s 428us/step - loss: 0.3892 - accuracy: 0.8155\n",
      "Epoch 71/100\n",
      "305/305 [==============================] - 0s 434us/step - loss: 0.3848 - accuracy: 0.8055\n",
      "Epoch 72/100\n",
      "305/305 [==============================] - 0s 434us/step - loss: 0.3885 - accuracy: 0.8073\n",
      "Epoch 73/100\n",
      "305/305 [==============================] - 0s 431us/step - loss: 0.3872 - accuracy: 0.8110\n",
      "Epoch 74/100\n",
      "305/305 [==============================] - 0s 427us/step - loss: 0.3867 - accuracy: 0.8042\n",
      "Epoch 75/100\n",
      "305/305 [==============================] - 0s 421us/step - loss: 0.3847 - accuracy: 0.8145\n",
      "Epoch 76/100\n",
      "305/305 [==============================] - 0s 418us/step - loss: 0.3882 - accuracy: 0.8063\n",
      "Epoch 77/100\n",
      "305/305 [==============================] - 0s 415us/step - loss: 0.3889 - accuracy: 0.8063\n",
      "Epoch 78/100\n",
      "305/305 [==============================] - 0s 421us/step - loss: 0.3854 - accuracy: 0.8073\n",
      "Epoch 79/100\n",
      "305/305 [==============================] - 0s 429us/step - loss: 0.3842 - accuracy: 0.8032\n",
      "Epoch 80/100\n",
      "305/305 [==============================] - 0s 414us/step - loss: 0.3864 - accuracy: 0.8022\n",
      "Epoch 81/100\n",
      "305/305 [==============================] - 0s 417us/step - loss: 0.3899 - accuracy: 0.8042\n",
      "Epoch 82/100\n",
      "305/305 [==============================] - 0s 420us/step - loss: 0.3858 - accuracy: 0.8112\n",
      "Epoch 83/100\n",
      "305/305 [==============================] - 0s 429us/step - loss: 0.3840 - accuracy: 0.8028\n",
      "Epoch 84/100\n",
      "305/305 [==============================] - 0s 467us/step - loss: 0.3846 - accuracy: 0.8067\n",
      "Epoch 85/100\n",
      "305/305 [==============================] - 0s 417us/step - loss: 0.3886 - accuracy: 0.8053\n",
      "Epoch 86/100\n",
      "305/305 [==============================] - 0s 424us/step - loss: 0.3901 - accuracy: 0.8053\n",
      "Epoch 87/100\n",
      "305/305 [==============================] - 0s 426us/step - loss: 0.3868 - accuracy: 0.8073\n",
      "Epoch 88/100\n",
      "305/305 [==============================] - 0s 420us/step - loss: 0.3812 - accuracy: 0.8129\n",
      "Epoch 89/100\n",
      "305/305 [==============================] - 0s 424us/step - loss: 0.3818 - accuracy: 0.8051\n",
      "Epoch 90/100\n",
      "305/305 [==============================] - 0s 425us/step - loss: 0.3853 - accuracy: 0.8145\n",
      "Epoch 91/100\n",
      "305/305 [==============================] - 0s 438us/step - loss: 0.3804 - accuracy: 0.8122\n",
      "Epoch 92/100\n",
      "305/305 [==============================] - 0s 436us/step - loss: 0.3827 - accuracy: 0.8120\n",
      "Epoch 93/100\n",
      "305/305 [==============================] - 0s 424us/step - loss: 0.3788 - accuracy: 0.8073\n",
      "Epoch 94/100\n",
      "305/305 [==============================] - 0s 427us/step - loss: 0.3876 - accuracy: 0.8079\n",
      "Epoch 95/100\n",
      "305/305 [==============================] - 0s 437us/step - loss: 0.3822 - accuracy: 0.8012\n",
      "Epoch 96/100\n",
      "305/305 [==============================] - 0s 429us/step - loss: 0.3872 - accuracy: 0.8048\n",
      "Epoch 97/100\n",
      "305/305 [==============================] - 0s 443us/step - loss: 0.3810 - accuracy: 0.8153\n",
      "Epoch 98/100\n",
      "305/305 [==============================] - 0s 424us/step - loss: 0.3871 - accuracy: 0.8083\n",
      "Epoch 99/100\n",
      "305/305 [==============================] - 0s 428us/step - loss: 0.3821 - accuracy: 0.8048\n",
      "Epoch 100/100\n",
      "305/305 [==============================] - 0s 422us/step - loss: 0.3859 - accuracy: 0.8061\n",
      "39/39 [==============================] - 0s 341us/step\n",
      "Epoch 1/100\n",
      "305/305 [==============================] - 1s 437us/step - loss: 0.5447 - accuracy: 0.7163\n",
      "Epoch 2/100\n",
      "305/305 [==============================] - 0s 431us/step - loss: 0.4367 - accuracy: 0.7894\n",
      "Epoch 3/100\n",
      "305/305 [==============================] - 0s 423us/step - loss: 0.4312 - accuracy: 0.7997\n",
      "Epoch 4/100\n",
      "305/305 [==============================] - 0s 414us/step - loss: 0.4269 - accuracy: 0.7983\n",
      "Epoch 5/100\n",
      "305/305 [==============================] - 0s 421us/step - loss: 0.4199 - accuracy: 0.8034\n",
      "Epoch 6/100\n",
      "305/305 [==============================] - 0s 423us/step - loss: 0.4245 - accuracy: 0.7983\n",
      "Epoch 7/100\n",
      "305/305 [==============================] - 0s 416us/step - loss: 0.4206 - accuracy: 0.8030\n",
      "Epoch 8/100\n",
      "305/305 [==============================] - 0s 415us/step - loss: 0.4190 - accuracy: 0.8003\n",
      "Epoch 9/100\n",
      "305/305 [==============================] - 0s 423us/step - loss: 0.4200 - accuracy: 0.7997\n",
      "Epoch 10/100\n",
      "305/305 [==============================] - 0s 421us/step - loss: 0.4178 - accuracy: 0.8034\n",
      "Epoch 11/100\n",
      "305/305 [==============================] - 0s 423us/step - loss: 0.4167 - accuracy: 0.8057\n",
      "Epoch 12/100\n",
      "305/305 [==============================] - 0s 423us/step - loss: 0.4179 - accuracy: 0.8034\n",
      "Epoch 13/100\n",
      "305/305 [==============================] - 0s 420us/step - loss: 0.4130 - accuracy: 0.8053\n",
      "Epoch 14/100\n",
      "305/305 [==============================] - 0s 433us/step - loss: 0.4113 - accuracy: 0.8059\n",
      "Epoch 15/100\n",
      "305/305 [==============================] - 0s 420us/step - loss: 0.4084 - accuracy: 0.8092\n",
      "Epoch 16/100\n",
      "305/305 [==============================] - 0s 413us/step - loss: 0.4118 - accuracy: 0.8044\n",
      "Epoch 17/100\n",
      "305/305 [==============================] - 0s 420us/step - loss: 0.4071 - accuracy: 0.8090\n",
      "Epoch 18/100\n",
      "305/305 [==============================] - 0s 425us/step - loss: 0.4125 - accuracy: 0.8022\n",
      "Epoch 19/100\n",
      "305/305 [==============================] - 0s 423us/step - loss: 0.4064 - accuracy: 0.8046\n",
      "Epoch 20/100\n",
      "305/305 [==============================] - 0s 423us/step - loss: 0.4123 - accuracy: 0.8028\n",
      "Epoch 21/100\n",
      "305/305 [==============================] - 0s 417us/step - loss: 0.4059 - accuracy: 0.8118\n",
      "Epoch 22/100\n",
      "305/305 [==============================] - 0s 421us/step - loss: 0.4109 - accuracy: 0.8073\n",
      "Epoch 23/100\n",
      "305/305 [==============================] - 0s 431us/step - loss: 0.4061 - accuracy: 0.8059\n",
      "Epoch 24/100\n",
      "305/305 [==============================] - 0s 422us/step - loss: 0.4102 - accuracy: 0.8016\n",
      "Epoch 25/100\n",
      "305/305 [==============================] - 0s 422us/step - loss: 0.4060 - accuracy: 0.8120\n",
      "Epoch 26/100\n",
      "305/305 [==============================] - 0s 419us/step - loss: 0.4097 - accuracy: 0.8081\n",
      "Epoch 27/100\n",
      "305/305 [==============================] - 0s 418us/step - loss: 0.4026 - accuracy: 0.8088\n",
      "Epoch 28/100\n",
      "305/305 [==============================] - 0s 421us/step - loss: 0.4020 - accuracy: 0.8108\n",
      "Epoch 29/100\n",
      "305/305 [==============================] - 0s 419us/step - loss: 0.4044 - accuracy: 0.8083\n",
      "Epoch 30/100\n",
      "305/305 [==============================] - 0s 418us/step - loss: 0.4010 - accuracy: 0.8108\n",
      "Epoch 31/100\n",
      "305/305 [==============================] - 0s 723us/step - loss: 0.4084 - accuracy: 0.8083\n",
      "Epoch 32/100\n",
      "305/305 [==============================] - 0s 449us/step - loss: 0.4049 - accuracy: 0.8088\n",
      "Epoch 33/100\n",
      "305/305 [==============================] - 0s 420us/step - loss: 0.4043 - accuracy: 0.8083\n",
      "Epoch 34/100\n",
      "305/305 [==============================] - 0s 417us/step - loss: 0.4038 - accuracy: 0.8088\n",
      "Epoch 35/100\n",
      "305/305 [==============================] - 0s 423us/step - loss: 0.4015 - accuracy: 0.8102\n",
      "Epoch 36/100\n",
      "305/305 [==============================] - 0s 437us/step - loss: 0.4042 - accuracy: 0.8067\n",
      "Epoch 37/100\n",
      "305/305 [==============================] - 0s 426us/step - loss: 0.4016 - accuracy: 0.8102\n",
      "Epoch 38/100\n",
      "305/305 [==============================] - 0s 419us/step - loss: 0.3995 - accuracy: 0.8106\n",
      "Epoch 39/100\n",
      "305/305 [==============================] - 0s 423us/step - loss: 0.3984 - accuracy: 0.8143\n",
      "Epoch 40/100\n",
      "305/305 [==============================] - 0s 428us/step - loss: 0.4024 - accuracy: 0.8092\n",
      "Epoch 41/100\n",
      "305/305 [==============================] - 0s 429us/step - loss: 0.3972 - accuracy: 0.8168\n",
      "Epoch 42/100\n",
      "305/305 [==============================] - 0s 419us/step - loss: 0.3991 - accuracy: 0.8083\n",
      "Epoch 43/100\n",
      "305/305 [==============================] - 0s 415us/step - loss: 0.3972 - accuracy: 0.8137\n",
      "Epoch 44/100\n",
      "305/305 [==============================] - 0s 420us/step - loss: 0.3971 - accuracy: 0.8127\n",
      "Epoch 45/100\n",
      "305/305 [==============================] - 0s 416us/step - loss: 0.3978 - accuracy: 0.8127\n",
      "Epoch 46/100\n",
      "305/305 [==============================] - 0s 420us/step - loss: 0.3994 - accuracy: 0.8129\n",
      "Epoch 47/100\n",
      "305/305 [==============================] - 0s 418us/step - loss: 0.3970 - accuracy: 0.8118\n",
      "Epoch 48/100\n",
      "305/305 [==============================] - 0s 431us/step - loss: 0.3973 - accuracy: 0.8114\n",
      "Epoch 49/100\n",
      "305/305 [==============================] - 0s 420us/step - loss: 0.3947 - accuracy: 0.8149\n",
      "Epoch 50/100\n",
      "305/305 [==============================] - 0s 418us/step - loss: 0.3933 - accuracy: 0.8112\n",
      "Epoch 51/100\n",
      "305/305 [==============================] - 0s 423us/step - loss: 0.3959 - accuracy: 0.8096\n",
      "Epoch 52/100\n",
      "305/305 [==============================] - 0s 422us/step - loss: 0.4012 - accuracy: 0.8106\n",
      "Epoch 53/100\n",
      "305/305 [==============================] - 0s 422us/step - loss: 0.3978 - accuracy: 0.8110\n",
      "Epoch 54/100\n",
      "305/305 [==============================] - 0s 439us/step - loss: 0.3962 - accuracy: 0.8108\n",
      "Epoch 55/100\n",
      "305/305 [==============================] - 0s 429us/step - loss: 0.3988 - accuracy: 0.8094\n",
      "Epoch 56/100\n",
      "305/305 [==============================] - 0s 415us/step - loss: 0.3961 - accuracy: 0.8141\n",
      "Epoch 57/100\n",
      "305/305 [==============================] - 0s 417us/step - loss: 0.3986 - accuracy: 0.8114\n",
      "Epoch 58/100\n",
      "305/305 [==============================] - 0s 420us/step - loss: 0.3913 - accuracy: 0.8149\n",
      "Epoch 59/100\n",
      "305/305 [==============================] - 0s 425us/step - loss: 0.3938 - accuracy: 0.8194\n",
      "Epoch 60/100\n",
      "305/305 [==============================] - 0s 452us/step - loss: 0.3979 - accuracy: 0.8083\n",
      "Epoch 61/100\n",
      "305/305 [==============================] - 0s 432us/step - loss: 0.3926 - accuracy: 0.8110\n",
      "Epoch 62/100\n",
      "305/305 [==============================] - 0s 433us/step - loss: 0.3968 - accuracy: 0.8081\n",
      "Epoch 63/100\n",
      "305/305 [==============================] - 0s 434us/step - loss: 0.3957 - accuracy: 0.8168\n",
      "Epoch 64/100\n",
      "305/305 [==============================] - 0s 428us/step - loss: 0.3968 - accuracy: 0.8129\n",
      "Epoch 65/100\n",
      "305/305 [==============================] - 0s 425us/step - loss: 0.3895 - accuracy: 0.8192\n",
      "Epoch 66/100\n",
      "305/305 [==============================] - 0s 427us/step - loss: 0.3955 - accuracy: 0.8094\n",
      "Epoch 67/100\n",
      "305/305 [==============================] - 0s 420us/step - loss: 0.3933 - accuracy: 0.8122\n",
      "Epoch 68/100\n",
      "305/305 [==============================] - 0s 422us/step - loss: 0.3933 - accuracy: 0.8161\n",
      "Epoch 69/100\n",
      "305/305 [==============================] - 0s 427us/step - loss: 0.3959 - accuracy: 0.8159\n",
      "Epoch 70/100\n",
      "305/305 [==============================] - 0s 420us/step - loss: 0.3908 - accuracy: 0.8129\n",
      "Epoch 71/100\n",
      "305/305 [==============================] - 0s 429us/step - loss: 0.3935 - accuracy: 0.8147\n",
      "Epoch 72/100\n",
      "305/305 [==============================] - 0s 420us/step - loss: 0.3955 - accuracy: 0.8098\n",
      "Epoch 73/100\n",
      "305/305 [==============================] - 0s 416us/step - loss: 0.3970 - accuracy: 0.8135\n",
      "Epoch 74/100\n",
      "305/305 [==============================] - 0s 421us/step - loss: 0.3932 - accuracy: 0.8127\n",
      "Epoch 75/100\n",
      "305/305 [==============================] - 0s 417us/step - loss: 0.3917 - accuracy: 0.8178\n",
      "Epoch 76/100\n",
      "305/305 [==============================] - 0s 421us/step - loss: 0.3925 - accuracy: 0.8161\n",
      "Epoch 77/100\n",
      "305/305 [==============================] - 0s 417us/step - loss: 0.3910 - accuracy: 0.8166\n",
      "Epoch 78/100\n",
      "305/305 [==============================] - 0s 716us/step - loss: 0.3917 - accuracy: 0.8166\n",
      "Epoch 79/100\n",
      "305/305 [==============================] - 0s 425us/step - loss: 0.3910 - accuracy: 0.8141\n",
      "Epoch 80/100\n",
      "305/305 [==============================] - 0s 415us/step - loss: 0.3934 - accuracy: 0.8164\n",
      "Epoch 81/100\n",
      "305/305 [==============================] - 0s 414us/step - loss: 0.3929 - accuracy: 0.8137\n",
      "Epoch 82/100\n",
      "305/305 [==============================] - 0s 425us/step - loss: 0.3928 - accuracy: 0.8159\n",
      "Epoch 83/100\n",
      "305/305 [==============================] - 0s 426us/step - loss: 0.3926 - accuracy: 0.8133\n",
      "Epoch 84/100\n",
      "305/305 [==============================] - 0s 428us/step - loss: 0.3897 - accuracy: 0.8159\n",
      "Epoch 85/100\n",
      "305/305 [==============================] - 0s 419us/step - loss: 0.3922 - accuracy: 0.8145\n",
      "Epoch 86/100\n",
      "305/305 [==============================] - 0s 422us/step - loss: 0.3917 - accuracy: 0.8161\n",
      "Epoch 87/100\n",
      "305/305 [==============================] - 0s 421us/step - loss: 0.3923 - accuracy: 0.8184\n",
      "Epoch 88/100\n",
      "305/305 [==============================] - 0s 419us/step - loss: 0.3908 - accuracy: 0.8139\n",
      "Epoch 89/100\n",
      "305/305 [==============================] - 0s 429us/step - loss: 0.3885 - accuracy: 0.8194\n",
      "Epoch 90/100\n",
      "305/305 [==============================] - 0s 417us/step - loss: 0.3864 - accuracy: 0.8180\n",
      "Epoch 91/100\n",
      "305/305 [==============================] - 0s 422us/step - loss: 0.3923 - accuracy: 0.8131\n",
      "Epoch 92/100\n",
      "305/305 [==============================] - 0s 426us/step - loss: 0.3921 - accuracy: 0.8166\n",
      "Epoch 93/100\n",
      "305/305 [==============================] - 0s 422us/step - loss: 0.3878 - accuracy: 0.8174\n",
      "Epoch 94/100\n",
      "305/305 [==============================] - 0s 435us/step - loss: 0.3908 - accuracy: 0.8127\n",
      "Epoch 95/100\n",
      "305/305 [==============================] - 0s 420us/step - loss: 0.3878 - accuracy: 0.8176\n",
      "Epoch 96/100\n",
      "305/305 [==============================] - 0s 416us/step - loss: 0.3947 - accuracy: 0.8110\n",
      "Epoch 97/100\n",
      "305/305 [==============================] - 0s 424us/step - loss: 0.3916 - accuracy: 0.8124\n",
      "Epoch 98/100\n",
      "305/305 [==============================] - 0s 416us/step - loss: 0.3921 - accuracy: 0.8110\n",
      "Epoch 99/100\n",
      "305/305 [==============================] - 0s 417us/step - loss: 0.3902 - accuracy: 0.8108\n",
      "Epoch 100/100\n",
      "305/305 [==============================] - 0s 610us/step - loss: 0.3877 - accuracy: 0.8198\n",
      "39/39 [==============================] - 0s 324us/step\n",
      "Epoch 1/100\n",
      "305/305 [==============================] - 0s 436us/step - loss: 0.5289 - accuracy: 0.7253\n",
      "Epoch 2/100\n",
      "305/305 [==============================] - 0s 445us/step - loss: 0.4411 - accuracy: 0.7880\n",
      "Epoch 3/100\n",
      "305/305 [==============================] - 0s 443us/step - loss: 0.4353 - accuracy: 0.7911\n",
      "Epoch 4/100\n",
      "305/305 [==============================] - 0s 429us/step - loss: 0.4278 - accuracy: 0.7925\n",
      "Epoch 5/100\n",
      "305/305 [==============================] - 0s 442us/step - loss: 0.4264 - accuracy: 0.7989\n",
      "Epoch 6/100\n",
      "305/305 [==============================] - 0s 445us/step - loss: 0.4231 - accuracy: 0.7987\n",
      "Epoch 7/100\n",
      "305/305 [==============================] - 0s 424us/step - loss: 0.4226 - accuracy: 0.7987\n",
      "Epoch 8/100\n",
      "305/305 [==============================] - 0s 417us/step - loss: 0.4166 - accuracy: 0.8048\n",
      "Epoch 9/100\n",
      "305/305 [==============================] - 0s 420us/step - loss: 0.4153 - accuracy: 0.8016\n",
      "Epoch 10/100\n",
      "305/305 [==============================] - 0s 424us/step - loss: 0.4186 - accuracy: 0.7983\n",
      "Epoch 11/100\n",
      "305/305 [==============================] - 0s 450us/step - loss: 0.4133 - accuracy: 0.8016\n",
      "Epoch 12/100\n",
      "305/305 [==============================] - 0s 443us/step - loss: 0.4181 - accuracy: 0.8038\n",
      "Epoch 13/100\n",
      "305/305 [==============================] - 0s 437us/step - loss: 0.4165 - accuracy: 0.7999\n",
      "Epoch 14/100\n",
      "305/305 [==============================] - 0s 428us/step - loss: 0.4123 - accuracy: 0.8048\n",
      "Epoch 15/100\n",
      "305/305 [==============================] - 0s 436us/step - loss: 0.4116 - accuracy: 0.8032\n",
      "Epoch 16/100\n",
      "305/305 [==============================] - 0s 429us/step - loss: 0.4110 - accuracy: 0.8007\n",
      "Epoch 17/100\n",
      "305/305 [==============================] - 0s 441us/step - loss: 0.4091 - accuracy: 0.8026\n",
      "Epoch 18/100\n",
      "305/305 [==============================] - 0s 432us/step - loss: 0.4100 - accuracy: 0.8028\n",
      "Epoch 19/100\n",
      "305/305 [==============================] - 0s 431us/step - loss: 0.4084 - accuracy: 0.8051\n",
      "Epoch 20/100\n",
      "305/305 [==============================] - 0s 432us/step - loss: 0.4097 - accuracy: 0.8034\n",
      "Epoch 21/100\n",
      "305/305 [==============================] - 0s 430us/step - loss: 0.4114 - accuracy: 0.7983\n",
      "Epoch 22/100\n",
      "305/305 [==============================] - 0s 433us/step - loss: 0.4081 - accuracy: 0.8024\n",
      "Epoch 23/100\n",
      "305/305 [==============================] - 0s 429us/step - loss: 0.4110 - accuracy: 0.8020\n",
      "Epoch 24/100\n",
      "305/305 [==============================] - 0s 442us/step - loss: 0.4057 - accuracy: 0.8046\n",
      "Epoch 25/100\n",
      "305/305 [==============================] - 0s 424us/step - loss: 0.4076 - accuracy: 0.8040\n",
      "Epoch 26/100\n",
      "305/305 [==============================] - 0s 778us/step - loss: 0.4009 - accuracy: 0.8100\n",
      "Epoch 27/100\n",
      "305/305 [==============================] - 0s 446us/step - loss: 0.4032 - accuracy: 0.8090\n",
      "Epoch 28/100\n",
      "305/305 [==============================] - 0s 459us/step - loss: 0.4083 - accuracy: 0.7979\n",
      "Epoch 29/100\n",
      "305/305 [==============================] - 0s 440us/step - loss: 0.4030 - accuracy: 0.8100\n",
      "Epoch 30/100\n",
      "305/305 [==============================] - 0s 466us/step - loss: 0.4068 - accuracy: 0.8083\n",
      "Epoch 31/100\n",
      "305/305 [==============================] - 0s 447us/step - loss: 0.4015 - accuracy: 0.8061\n",
      "Epoch 32/100\n",
      "305/305 [==============================] - 0s 428us/step - loss: 0.4017 - accuracy: 0.8069\n",
      "Epoch 33/100\n",
      "305/305 [==============================] - 0s 432us/step - loss: 0.4023 - accuracy: 0.8071\n",
      "Epoch 34/100\n",
      "305/305 [==============================] - 0s 443us/step - loss: 0.4004 - accuracy: 0.8094\n",
      "Epoch 35/100\n",
      "305/305 [==============================] - 0s 443us/step - loss: 0.3990 - accuracy: 0.8088\n",
      "Epoch 36/100\n",
      "305/305 [==============================] - 0s 430us/step - loss: 0.4073 - accuracy: 0.8026\n",
      "Epoch 37/100\n",
      "305/305 [==============================] - 0s 508us/step - loss: 0.3997 - accuracy: 0.8038\n",
      "Epoch 38/100\n",
      "305/305 [==============================] - 0s 451us/step - loss: 0.4059 - accuracy: 0.8007\n",
      "Epoch 39/100\n",
      "305/305 [==============================] - 0s 457us/step - loss: 0.4038 - accuracy: 0.8057\n",
      "Epoch 40/100\n",
      "305/305 [==============================] - 0s 476us/step - loss: 0.3987 - accuracy: 0.8042\n",
      "Epoch 41/100\n",
      "305/305 [==============================] - 0s 526us/step - loss: 0.4010 - accuracy: 0.8094\n",
      "Epoch 42/100\n",
      "305/305 [==============================] - 0s 428us/step - loss: 0.3975 - accuracy: 0.8077\n",
      "Epoch 43/100\n",
      "305/305 [==============================] - 0s 423us/step - loss: 0.4007 - accuracy: 0.8106\n",
      "Epoch 44/100\n",
      "305/305 [==============================] - 0s 434us/step - loss: 0.4010 - accuracy: 0.8038\n",
      "Epoch 45/100\n",
      "305/305 [==============================] - 0s 455us/step - loss: 0.3993 - accuracy: 0.8094\n",
      "Epoch 46/100\n",
      "305/305 [==============================] - 0s 451us/step - loss: 0.3979 - accuracy: 0.8051\n",
      "Epoch 47/100\n",
      "305/305 [==============================] - 0s 436us/step - loss: 0.3991 - accuracy: 0.8083\n",
      "Epoch 48/100\n",
      "305/305 [==============================] - 0s 430us/step - loss: 0.3970 - accuracy: 0.8034\n",
      "Epoch 49/100\n",
      "305/305 [==============================] - 0s 422us/step - loss: 0.3971 - accuracy: 0.8112\n",
      "Epoch 50/100\n",
      "305/305 [==============================] - 0s 424us/step - loss: 0.3995 - accuracy: 0.8036\n",
      "Epoch 51/100\n",
      "305/305 [==============================] - 0s 436us/step - loss: 0.3973 - accuracy: 0.8036\n",
      "Epoch 52/100\n",
      "305/305 [==============================] - 0s 424us/step - loss: 0.3999 - accuracy: 0.8012\n",
      "Epoch 53/100\n",
      "305/305 [==============================] - 0s 438us/step - loss: 0.3981 - accuracy: 0.8079\n",
      "Epoch 54/100\n",
      "305/305 [==============================] - 0s 436us/step - loss: 0.3991 - accuracy: 0.8079\n",
      "Epoch 55/100\n",
      "305/305 [==============================] - 0s 421us/step - loss: 0.3980 - accuracy: 0.8090\n",
      "Epoch 56/100\n",
      "305/305 [==============================] - 0s 426us/step - loss: 0.4005 - accuracy: 0.8075\n",
      "Epoch 57/100\n",
      "305/305 [==============================] - 0s 442us/step - loss: 0.3975 - accuracy: 0.8055\n",
      "Epoch 58/100\n",
      "305/305 [==============================] - 0s 427us/step - loss: 0.3954 - accuracy: 0.8069\n",
      "Epoch 59/100\n",
      "305/305 [==============================] - 0s 432us/step - loss: 0.4003 - accuracy: 0.8100\n",
      "Epoch 60/100\n",
      "305/305 [==============================] - 0s 448us/step - loss: 0.3946 - accuracy: 0.8090\n",
      "Epoch 61/100\n",
      "305/305 [==============================] - 0s 445us/step - loss: 0.3928 - accuracy: 0.8129\n",
      "Epoch 62/100\n",
      "305/305 [==============================] - 0s 423us/step - loss: 0.3993 - accuracy: 0.8061\n",
      "Epoch 63/100\n",
      "305/305 [==============================] - 0s 434us/step - loss: 0.3960 - accuracy: 0.8075\n",
      "Epoch 64/100\n",
      "305/305 [==============================] - 0s 442us/step - loss: 0.3930 - accuracy: 0.8180\n",
      "Epoch 65/100\n",
      "305/305 [==============================] - 0s 432us/step - loss: 0.3990 - accuracy: 0.8075\n",
      "Epoch 66/100\n",
      "305/305 [==============================] - 0s 426us/step - loss: 0.3964 - accuracy: 0.8096\n",
      "Epoch 67/100\n",
      "305/305 [==============================] - 0s 441us/step - loss: 0.3936 - accuracy: 0.8063\n",
      "Epoch 68/100\n",
      "305/305 [==============================] - 0s 496us/step - loss: 0.3871 - accuracy: 0.8116\n",
      "Epoch 69/100\n",
      "305/305 [==============================] - 0s 436us/step - loss: 0.3909 - accuracy: 0.8149\n",
      "Epoch 70/100\n",
      "305/305 [==============================] - 0s 739us/step - loss: 0.3953 - accuracy: 0.8040\n",
      "Epoch 71/100\n",
      "305/305 [==============================] - 0s 633us/step - loss: 0.3934 - accuracy: 0.8100\n",
      "Epoch 72/100\n",
      "305/305 [==============================] - 0s 480us/step - loss: 0.3889 - accuracy: 0.8116\n",
      "Epoch 73/100\n",
      "305/305 [==============================] - 0s 438us/step - loss: 0.3908 - accuracy: 0.8079\n",
      "Epoch 74/100\n",
      "305/305 [==============================] - 0s 457us/step - loss: 0.3945 - accuracy: 0.8069\n",
      "Epoch 75/100\n",
      "305/305 [==============================] - 0s 436us/step - loss: 0.3963 - accuracy: 0.8073\n",
      "Epoch 76/100\n",
      "305/305 [==============================] - 0s 434us/step - loss: 0.3931 - accuracy: 0.8129\n",
      "Epoch 77/100\n",
      "305/305 [==============================] - 0s 434us/step - loss: 0.3906 - accuracy: 0.8120\n",
      "Epoch 78/100\n",
      "305/305 [==============================] - 0s 431us/step - loss: 0.3897 - accuracy: 0.8122\n",
      "Epoch 79/100\n",
      "305/305 [==============================] - 0s 430us/step - loss: 0.3921 - accuracy: 0.8110\n",
      "Epoch 80/100\n",
      "305/305 [==============================] - 0s 434us/step - loss: 0.3948 - accuracy: 0.8069\n",
      "Epoch 81/100\n",
      "305/305 [==============================] - 0s 427us/step - loss: 0.3951 - accuracy: 0.8057\n",
      "Epoch 82/100\n",
      "305/305 [==============================] - 0s 429us/step - loss: 0.3928 - accuracy: 0.8065\n",
      "Epoch 83/100\n",
      "305/305 [==============================] - 0s 426us/step - loss: 0.3932 - accuracy: 0.8098\n",
      "Epoch 84/100\n",
      "305/305 [==============================] - 0s 435us/step - loss: 0.3932 - accuracy: 0.8100\n",
      "Epoch 85/100\n",
      "305/305 [==============================] - 0s 423us/step - loss: 0.3899 - accuracy: 0.8131\n",
      "Epoch 86/100\n",
      "305/305 [==============================] - 0s 430us/step - loss: 0.3906 - accuracy: 0.8129\n",
      "Epoch 87/100\n",
      "305/305 [==============================] - 0s 419us/step - loss: 0.3927 - accuracy: 0.8063\n",
      "Epoch 88/100\n",
      "305/305 [==============================] - 0s 420us/step - loss: 0.3918 - accuracy: 0.8092\n",
      "Epoch 89/100\n",
      "305/305 [==============================] - 0s 426us/step - loss: 0.3959 - accuracy: 0.8092\n",
      "Epoch 90/100\n",
      "305/305 [==============================] - 0s 424us/step - loss: 0.3884 - accuracy: 0.8151\n",
      "Epoch 91/100\n",
      "305/305 [==============================] - 0s 414us/step - loss: 0.3942 - accuracy: 0.8063\n",
      "Epoch 92/100\n",
      "305/305 [==============================] - 0s 430us/step - loss: 0.3923 - accuracy: 0.8106\n",
      "Epoch 93/100\n",
      "305/305 [==============================] - 0s 420us/step - loss: 0.3909 - accuracy: 0.8088\n",
      "Epoch 94/100\n",
      "305/305 [==============================] - 0s 417us/step - loss: 0.3874 - accuracy: 0.8106\n",
      "Epoch 95/100\n",
      "305/305 [==============================] - 0s 426us/step - loss: 0.3887 - accuracy: 0.8096\n",
      "Epoch 96/100\n",
      "305/305 [==============================] - 0s 440us/step - loss: 0.3911 - accuracy: 0.8104\n",
      "Epoch 97/100\n",
      "305/305 [==============================] - 0s 434us/step - loss: 0.3932 - accuracy: 0.8061\n",
      "Epoch 98/100\n",
      "305/305 [==============================] - 0s 453us/step - loss: 0.3914 - accuracy: 0.8108\n",
      "Epoch 99/100\n",
      "305/305 [==============================] - 0s 461us/step - loss: 0.3883 - accuracy: 0.8106\n",
      "Epoch 100/100\n",
      "305/305 [==============================] - 0s 474us/step - loss: 0.3912 - accuracy: 0.8055\n",
      "39/39 [==============================] - 0s 349us/step\n",
      "Epoch 1/100\n",
      "305/305 [==============================] - 0s 458us/step - loss: 0.5418 - accuracy: 0.7293\n",
      "Epoch 2/100\n",
      "305/305 [==============================] - 0s 465us/step - loss: 0.4527 - accuracy: 0.7765\n",
      "Epoch 3/100\n",
      "305/305 [==============================] - 0s 438us/step - loss: 0.4434 - accuracy: 0.7796\n",
      "Epoch 4/100\n",
      "305/305 [==============================] - 0s 436us/step - loss: 0.4413 - accuracy: 0.7839\n",
      "Epoch 5/100\n",
      "305/305 [==============================] - 0s 424us/step - loss: 0.4425 - accuracy: 0.7798\n",
      "Epoch 6/100\n",
      "305/305 [==============================] - 0s 420us/step - loss: 0.4359 - accuracy: 0.7882\n",
      "Epoch 7/100\n",
      "305/305 [==============================] - 0s 419us/step - loss: 0.4351 - accuracy: 0.7913\n",
      "Epoch 8/100\n",
      "305/305 [==============================] - 0s 429us/step - loss: 0.4323 - accuracy: 0.7896\n",
      "Epoch 9/100\n",
      "305/305 [==============================] - 0s 474us/step - loss: 0.4300 - accuracy: 0.7888\n",
      "Epoch 10/100\n",
      "305/305 [==============================] - 0s 435us/step - loss: 0.4298 - accuracy: 0.7857\n",
      "Epoch 11/100\n",
      "305/305 [==============================] - 0s 717us/step - loss: 0.4290 - accuracy: 0.7935\n",
      "Epoch 12/100\n",
      "305/305 [==============================] - 0s 457us/step - loss: 0.4240 - accuracy: 0.7970\n",
      "Epoch 13/100\n",
      "305/305 [==============================] - 0s 441us/step - loss: 0.4285 - accuracy: 0.7905\n",
      "Epoch 14/100\n",
      "305/305 [==============================] - 0s 430us/step - loss: 0.4241 - accuracy: 0.7975\n",
      "Epoch 15/100\n",
      "305/305 [==============================] - 0s 426us/step - loss: 0.4226 - accuracy: 0.7960\n",
      "Epoch 16/100\n",
      "305/305 [==============================] - 0s 423us/step - loss: 0.4197 - accuracy: 0.7983\n",
      "Epoch 17/100\n",
      "305/305 [==============================] - 0s 435us/step - loss: 0.4255 - accuracy: 0.7913\n",
      "Epoch 18/100\n",
      "305/305 [==============================] - 0s 435us/step - loss: 0.4250 - accuracy: 0.7950\n",
      "Epoch 19/100\n",
      "305/305 [==============================] - 0s 427us/step - loss: 0.4260 - accuracy: 0.7950\n",
      "Epoch 20/100\n",
      "305/305 [==============================] - 0s 432us/step - loss: 0.4187 - accuracy: 0.8001\n",
      "Epoch 21/100\n",
      "305/305 [==============================] - 0s 424us/step - loss: 0.4197 - accuracy: 0.7972\n",
      "Epoch 22/100\n",
      "305/305 [==============================] - 0s 429us/step - loss: 0.4196 - accuracy: 0.7989\n",
      "Epoch 23/100\n",
      "305/305 [==============================] - 0s 420us/step - loss: 0.4203 - accuracy: 0.7981\n",
      "Epoch 24/100\n",
      "305/305 [==============================] - 0s 429us/step - loss: 0.4203 - accuracy: 0.7958\n",
      "Epoch 25/100\n",
      "305/305 [==============================] - 0s 431us/step - loss: 0.4188 - accuracy: 0.7960\n",
      "Epoch 26/100\n",
      "305/305 [==============================] - 0s 427us/step - loss: 0.4214 - accuracy: 0.8016\n",
      "Epoch 27/100\n",
      "305/305 [==============================] - 0s 446us/step - loss: 0.4166 - accuracy: 0.7948\n",
      "Epoch 28/100\n",
      "305/305 [==============================] - 0s 447us/step - loss: 0.4172 - accuracy: 0.7970\n",
      "Epoch 29/100\n",
      "305/305 [==============================] - 0s 421us/step - loss: 0.4140 - accuracy: 0.7975\n",
      "Epoch 30/100\n",
      "305/305 [==============================] - 0s 439us/step - loss: 0.4125 - accuracy: 0.7915\n",
      "Epoch 31/100\n",
      "305/305 [==============================] - 0s 460us/step - loss: 0.4127 - accuracy: 0.7999\n",
      "Epoch 32/100\n",
      "305/305 [==============================] - 0s 428us/step - loss: 0.4161 - accuracy: 0.8001\n",
      "Epoch 33/100\n",
      "305/305 [==============================] - 0s 441us/step - loss: 0.4135 - accuracy: 0.7989\n",
      "Epoch 34/100\n",
      "305/305 [==============================] - 0s 435us/step - loss: 0.4126 - accuracy: 0.7991\n",
      "Epoch 35/100\n",
      "305/305 [==============================] - 0s 431us/step - loss: 0.4117 - accuracy: 0.7977\n",
      "Epoch 36/100\n",
      "305/305 [==============================] - 0s 431us/step - loss: 0.4129 - accuracy: 0.8059\n",
      "Epoch 37/100\n",
      "305/305 [==============================] - 0s 434us/step - loss: 0.4153 - accuracy: 0.7942\n",
      "Epoch 38/100\n",
      "305/305 [==============================] - 0s 427us/step - loss: 0.4106 - accuracy: 0.7993\n",
      "Epoch 39/100\n",
      "305/305 [==============================] - 0s 426us/step - loss: 0.4170 - accuracy: 0.7938\n",
      "Epoch 40/100\n",
      "305/305 [==============================] - 0s 429us/step - loss: 0.4114 - accuracy: 0.8053\n",
      "Epoch 41/100\n",
      "305/305 [==============================] - 0s 424us/step - loss: 0.4091 - accuracy: 0.8003\n",
      "Epoch 42/100\n",
      "305/305 [==============================] - 0s 428us/step - loss: 0.4080 - accuracy: 0.8007\n",
      "Epoch 43/100\n",
      "305/305 [==============================] - 0s 423us/step - loss: 0.4075 - accuracy: 0.8030\n",
      "Epoch 44/100\n",
      "305/305 [==============================] - 0s 419us/step - loss: 0.4093 - accuracy: 0.8020\n",
      "Epoch 45/100\n",
      "305/305 [==============================] - 0s 422us/step - loss: 0.4079 - accuracy: 0.8026\n",
      "Epoch 46/100\n",
      "305/305 [==============================] - 0s 423us/step - loss: 0.4163 - accuracy: 0.7972\n",
      "Epoch 47/100\n",
      "305/305 [==============================] - 0s 424us/step - loss: 0.4109 - accuracy: 0.8009\n",
      "Epoch 48/100\n",
      "305/305 [==============================] - 0s 784us/step - loss: 0.4080 - accuracy: 0.7989\n",
      "Epoch 49/100\n",
      "305/305 [==============================] - 0s 441us/step - loss: 0.4044 - accuracy: 0.8030\n",
      "Epoch 50/100\n",
      "305/305 [==============================] - 0s 420us/step - loss: 0.4076 - accuracy: 0.7977\n",
      "Epoch 51/100\n",
      "305/305 [==============================] - 0s 425us/step - loss: 0.4078 - accuracy: 0.8007\n",
      "Epoch 52/100\n",
      "305/305 [==============================] - 0s 419us/step - loss: 0.4099 - accuracy: 0.8051\n",
      "Epoch 53/100\n",
      "305/305 [==============================] - 0s 430us/step - loss: 0.4066 - accuracy: 0.8030\n",
      "Epoch 54/100\n",
      "305/305 [==============================] - 0s 424us/step - loss: 0.4091 - accuracy: 0.7962\n",
      "Epoch 55/100\n",
      "305/305 [==============================] - 0s 430us/step - loss: 0.4075 - accuracy: 0.8036\n",
      "Epoch 56/100\n",
      "305/305 [==============================] - 0s 423us/step - loss: 0.4050 - accuracy: 0.8022\n",
      "Epoch 57/100\n",
      "305/305 [==============================] - 0s 430us/step - loss: 0.4072 - accuracy: 0.7989\n",
      "Epoch 58/100\n",
      "305/305 [==============================] - 0s 425us/step - loss: 0.4026 - accuracy: 0.8022\n",
      "Epoch 59/100\n",
      "305/305 [==============================] - 0s 426us/step - loss: 0.4049 - accuracy: 0.8071\n",
      "Epoch 60/100\n",
      "305/305 [==============================] - 0s 430us/step - loss: 0.4071 - accuracy: 0.8022\n",
      "Epoch 61/100\n",
      "305/305 [==============================] - 0s 427us/step - loss: 0.4013 - accuracy: 0.8067\n",
      "Epoch 62/100\n",
      "305/305 [==============================] - 0s 433us/step - loss: 0.4068 - accuracy: 0.8018\n",
      "Epoch 63/100\n",
      "305/305 [==============================] - 0s 427us/step - loss: 0.4041 - accuracy: 0.7997\n",
      "Epoch 64/100\n",
      "305/305 [==============================] - 0s 438us/step - loss: 0.4051 - accuracy: 0.8057\n",
      "Epoch 65/100\n",
      "305/305 [==============================] - 0s 438us/step - loss: 0.4025 - accuracy: 0.7991\n",
      "Epoch 66/100\n",
      "305/305 [==============================] - 0s 432us/step - loss: 0.4028 - accuracy: 0.7991\n",
      "Epoch 67/100\n",
      "305/305 [==============================] - 0s 436us/step - loss: 0.4009 - accuracy: 0.8003\n",
      "Epoch 68/100\n",
      "305/305 [==============================] - 0s 426us/step - loss: 0.4073 - accuracy: 0.8040\n",
      "Epoch 69/100\n",
      "305/305 [==============================] - 0s 458us/step - loss: 0.3992 - accuracy: 0.8061\n",
      "Epoch 70/100\n",
      "305/305 [==============================] - 0s 464us/step - loss: 0.4027 - accuracy: 0.8001\n",
      "Epoch 71/100\n",
      "305/305 [==============================] - 0s 442us/step - loss: 0.4030 - accuracy: 0.8020\n",
      "Epoch 72/100\n",
      "305/305 [==============================] - 0s 433us/step - loss: 0.4037 - accuracy: 0.8018\n",
      "Epoch 73/100\n",
      "305/305 [==============================] - 0s 451us/step - loss: 0.4061 - accuracy: 0.7950\n",
      "Epoch 74/100\n",
      "305/305 [==============================] - 0s 440us/step - loss: 0.3985 - accuracy: 0.8055\n",
      "Epoch 75/100\n",
      "305/305 [==============================] - 0s 436us/step - loss: 0.4057 - accuracy: 0.7979\n",
      "Epoch 76/100\n",
      "305/305 [==============================] - 0s 427us/step - loss: 0.4004 - accuracy: 0.8026\n",
      "Epoch 77/100\n",
      "305/305 [==============================] - 0s 430us/step - loss: 0.3995 - accuracy: 0.8026\n",
      "Epoch 78/100\n",
      "305/305 [==============================] - 0s 430us/step - loss: 0.3969 - accuracy: 0.8042\n",
      "Epoch 79/100\n",
      "305/305 [==============================] - 0s 422us/step - loss: 0.4006 - accuracy: 0.8088\n",
      "Epoch 80/100\n",
      "305/305 [==============================] - 0s 431us/step - loss: 0.3999 - accuracy: 0.8003\n",
      "Epoch 81/100\n",
      "305/305 [==============================] - 0s 489us/step - loss: 0.3994 - accuracy: 0.8059\n",
      "Epoch 82/100\n",
      "305/305 [==============================] - 0s 676us/step - loss: 0.4004 - accuracy: 0.7985\n",
      "Epoch 83/100\n",
      "305/305 [==============================] - 0s 431us/step - loss: 0.3998 - accuracy: 0.8038\n",
      "Epoch 84/100\n",
      "305/305 [==============================] - 0s 440us/step - loss: 0.4047 - accuracy: 0.7964\n",
      "Epoch 85/100\n",
      "305/305 [==============================] - 0s 431us/step - loss: 0.3963 - accuracy: 0.8042\n",
      "Epoch 86/100\n",
      "305/305 [==============================] - 0s 448us/step - loss: 0.3995 - accuracy: 0.8077\n",
      "Epoch 87/100\n",
      "305/305 [==============================] - 0s 437us/step - loss: 0.4031 - accuracy: 0.7987\n",
      "Epoch 88/100\n",
      "305/305 [==============================] - 0s 424us/step - loss: 0.4022 - accuracy: 0.8007\n",
      "Epoch 89/100\n",
      "305/305 [==============================] - 0s 421us/step - loss: 0.3961 - accuracy: 0.8018\n",
      "Epoch 90/100\n",
      "305/305 [==============================] - 0s 436us/step - loss: 0.4029 - accuracy: 0.7999\n",
      "Epoch 91/100\n",
      "305/305 [==============================] - 0s 424us/step - loss: 0.3977 - accuracy: 0.8046\n",
      "Epoch 92/100\n",
      "305/305 [==============================] - 0s 431us/step - loss: 0.4039 - accuracy: 0.8016\n",
      "Epoch 93/100\n",
      "305/305 [==============================] - 0s 430us/step - loss: 0.3960 - accuracy: 0.8046\n",
      "Epoch 94/100\n",
      "305/305 [==============================] - 0s 436us/step - loss: 0.3998 - accuracy: 0.8003\n",
      "Epoch 95/100\n",
      "305/305 [==============================] - 0s 432us/step - loss: 0.3980 - accuracy: 0.8055\n",
      "Epoch 96/100\n",
      "305/305 [==============================] - 0s 491us/step - loss: 0.3965 - accuracy: 0.8088\n",
      "Epoch 97/100\n",
      "305/305 [==============================] - 0s 443us/step - loss: 0.3976 - accuracy: 0.8077\n",
      "Epoch 98/100\n",
      "305/305 [==============================] - 0s 448us/step - loss: 0.3980 - accuracy: 0.8073\n",
      "Epoch 99/100\n",
      "305/305 [==============================] - 0s 433us/step - loss: 0.3963 - accuracy: 0.8073\n",
      "Epoch 100/100\n",
      "305/305 [==============================] - 0s 433us/step - loss: 0.4002 - accuracy: 0.8022\n",
      "39/39 [==============================] - 0s 332us/step\n",
      "Epoch 1/200\n",
      "305/305 [==============================] - 0s 503us/step - loss: 0.5371 - accuracy: 0.7395\n",
      "Epoch 2/200\n",
      "305/305 [==============================] - 0s 426us/step - loss: 0.4440 - accuracy: 0.7862\n",
      "Epoch 3/200\n",
      "305/305 [==============================] - 0s 438us/step - loss: 0.4344 - accuracy: 0.7868\n",
      "Epoch 4/200\n",
      "305/305 [==============================] - 0s 435us/step - loss: 0.4275 - accuracy: 0.7966\n",
      "Epoch 5/200\n",
      "305/305 [==============================] - 0s 432us/step - loss: 0.4220 - accuracy: 0.8007\n",
      "Epoch 6/200\n",
      "305/305 [==============================] - 0s 446us/step - loss: 0.4221 - accuracy: 0.7972\n",
      "Epoch 7/200\n",
      "305/305 [==============================] - 0s 434us/step - loss: 0.4234 - accuracy: 0.7970\n",
      "Epoch 8/200\n",
      "305/305 [==============================] - 0s 424us/step - loss: 0.4157 - accuracy: 0.8003\n",
      "Epoch 9/200\n",
      "305/305 [==============================] - 0s 426us/step - loss: 0.4242 - accuracy: 0.7968\n",
      "Epoch 10/200\n",
      "305/305 [==============================] - 0s 421us/step - loss: 0.4130 - accuracy: 0.8048\n",
      "Epoch 11/200\n",
      "305/305 [==============================] - 0s 425us/step - loss: 0.4161 - accuracy: 0.8009\n",
      "Epoch 12/200\n",
      "305/305 [==============================] - 0s 424us/step - loss: 0.4155 - accuracy: 0.8028\n",
      "Epoch 13/200\n",
      "305/305 [==============================] - 0s 730us/step - loss: 0.4148 - accuracy: 0.8022\n",
      "Epoch 14/200\n",
      "305/305 [==============================] - 0s 448us/step - loss: 0.4120 - accuracy: 0.8034\n",
      "Epoch 15/200\n",
      "305/305 [==============================] - 0s 432us/step - loss: 0.4090 - accuracy: 0.8083\n",
      "Epoch 16/200\n",
      "305/305 [==============================] - 0s 435us/step - loss: 0.4106 - accuracy: 0.8057\n",
      "Epoch 17/200\n",
      "305/305 [==============================] - 0s 437us/step - loss: 0.4116 - accuracy: 0.8014\n",
      "Epoch 18/200\n",
      "305/305 [==============================] - 0s 425us/step - loss: 0.4079 - accuracy: 0.8042\n",
      "Epoch 19/200\n",
      "305/305 [==============================] - 0s 423us/step - loss: 0.4112 - accuracy: 0.8044\n",
      "Epoch 20/200\n",
      "305/305 [==============================] - 0s 418us/step - loss: 0.4087 - accuracy: 0.8057\n",
      "Epoch 21/200\n",
      "305/305 [==============================] - 0s 418us/step - loss: 0.4076 - accuracy: 0.8077\n",
      "Epoch 22/200\n",
      "305/305 [==============================] - 0s 419us/step - loss: 0.4052 - accuracy: 0.8114\n",
      "Epoch 23/200\n",
      "305/305 [==============================] - 0s 420us/step - loss: 0.4046 - accuracy: 0.8081\n",
      "Epoch 24/200\n",
      "305/305 [==============================] - 0s 420us/step - loss: 0.4072 - accuracy: 0.8034\n",
      "Epoch 25/200\n",
      "305/305 [==============================] - 0s 423us/step - loss: 0.4051 - accuracy: 0.8104\n",
      "Epoch 26/200\n",
      "305/305 [==============================] - 0s 429us/step - loss: 0.4037 - accuracy: 0.8129\n",
      "Epoch 27/200\n",
      "305/305 [==============================] - 0s 420us/step - loss: 0.4050 - accuracy: 0.8108\n",
      "Epoch 28/200\n",
      "305/305 [==============================] - 0s 430us/step - loss: 0.4063 - accuracy: 0.8018\n",
      "Epoch 29/200\n",
      "305/305 [==============================] - 0s 421us/step - loss: 0.4036 - accuracy: 0.8046\n",
      "Epoch 30/200\n",
      "305/305 [==============================] - 0s 427us/step - loss: 0.4028 - accuracy: 0.8104\n",
      "Epoch 31/200\n",
      "305/305 [==============================] - 0s 420us/step - loss: 0.4026 - accuracy: 0.8112\n",
      "Epoch 32/200\n",
      "305/305 [==============================] - 0s 426us/step - loss: 0.4014 - accuracy: 0.8104\n",
      "Epoch 33/200\n",
      "305/305 [==============================] - 0s 429us/step - loss: 0.3952 - accuracy: 0.8122\n",
      "Epoch 34/200\n",
      "305/305 [==============================] - 0s 431us/step - loss: 0.4003 - accuracy: 0.8083\n",
      "Epoch 35/200\n",
      "305/305 [==============================] - 0s 426us/step - loss: 0.4048 - accuracy: 0.8104\n",
      "Epoch 36/200\n",
      "305/305 [==============================] - 0s 419us/step - loss: 0.3993 - accuracy: 0.8090\n",
      "Epoch 37/200\n",
      "305/305 [==============================] - 0s 422us/step - loss: 0.4000 - accuracy: 0.8118\n",
      "Epoch 38/200\n",
      "305/305 [==============================] - 0s 427us/step - loss: 0.3958 - accuracy: 0.8116\n",
      "Epoch 39/200\n",
      "305/305 [==============================] - 0s 429us/step - loss: 0.4014 - accuracy: 0.8118\n",
      "Epoch 40/200\n",
      "305/305 [==============================] - 0s 438us/step - loss: 0.4003 - accuracy: 0.8114\n",
      "Epoch 41/200\n",
      "305/305 [==============================] - 0s 420us/step - loss: 0.3997 - accuracy: 0.8079\n",
      "Epoch 42/200\n",
      "305/305 [==============================] - 0s 552us/step - loss: 0.4031 - accuracy: 0.8094\n",
      "Epoch 43/200\n",
      "305/305 [==============================] - 0s 461us/step - loss: 0.3997 - accuracy: 0.8127\n",
      "Epoch 44/200\n",
      "305/305 [==============================] - 0s 431us/step - loss: 0.4009 - accuracy: 0.8116\n",
      "Epoch 45/200\n",
      "305/305 [==============================] - 0s 432us/step - loss: 0.4031 - accuracy: 0.8048\n",
      "Epoch 46/200\n",
      "305/305 [==============================] - 0s 426us/step - loss: 0.3946 - accuracy: 0.8118\n",
      "Epoch 47/200\n",
      "305/305 [==============================] - 0s 441us/step - loss: 0.3990 - accuracy: 0.8090\n",
      "Epoch 48/200\n",
      "305/305 [==============================] - 0s 425us/step - loss: 0.3953 - accuracy: 0.8096\n",
      "Epoch 49/200\n",
      "305/305 [==============================] - 0s 426us/step - loss: 0.3975 - accuracy: 0.8108\n",
      "Epoch 50/200\n",
      "305/305 [==============================] - 0s 436us/step - loss: 0.3921 - accuracy: 0.8170\n",
      "Epoch 51/200\n",
      "305/305 [==============================] - 0s 438us/step - loss: 0.3954 - accuracy: 0.8155\n",
      "Epoch 52/200\n",
      "305/305 [==============================] - 0s 431us/step - loss: 0.3991 - accuracy: 0.8092\n",
      "Epoch 53/200\n",
      "305/305 [==============================] - 0s 429us/step - loss: 0.3952 - accuracy: 0.8098\n",
      "Epoch 54/200\n",
      "305/305 [==============================] - 0s 460us/step - loss: 0.3983 - accuracy: 0.8102\n",
      "Epoch 55/200\n",
      "305/305 [==============================] - 0s 457us/step - loss: 0.4011 - accuracy: 0.8083\n",
      "Epoch 56/200\n",
      "305/305 [==============================] - 0s 450us/step - loss: 0.3996 - accuracy: 0.8075\n",
      "Epoch 57/200\n",
      "305/305 [==============================] - 0s 446us/step - loss: 0.3912 - accuracy: 0.8161\n",
      "Epoch 58/200\n",
      "305/305 [==============================] - 0s 434us/step - loss: 0.3999 - accuracy: 0.8063\n",
      "Epoch 59/200\n",
      "305/305 [==============================] - 0s 425us/step - loss: 0.3928 - accuracy: 0.8116\n",
      "Epoch 60/200\n",
      "305/305 [==============================] - 0s 438us/step - loss: 0.3994 - accuracy: 0.8133\n",
      "Epoch 61/200\n",
      "305/305 [==============================] - 0s 417us/step - loss: 0.3965 - accuracy: 0.8110\n",
      "Epoch 62/200\n",
      "305/305 [==============================] - 0s 442us/step - loss: 0.3937 - accuracy: 0.8174\n",
      "Epoch 63/200\n",
      "305/305 [==============================] - 0s 451us/step - loss: 0.3937 - accuracy: 0.8153\n",
      "Epoch 64/200\n",
      "305/305 [==============================] - 0s 423us/step - loss: 0.3925 - accuracy: 0.8145\n",
      "Epoch 65/200\n",
      "305/305 [==============================] - 0s 427us/step - loss: 0.3899 - accuracy: 0.8141\n",
      "Epoch 66/200\n",
      "305/305 [==============================] - 0s 416us/step - loss: 0.3882 - accuracy: 0.8133\n",
      "Epoch 67/200\n",
      "305/305 [==============================] - 0s 421us/step - loss: 0.3898 - accuracy: 0.8141\n",
      "Epoch 68/200\n",
      "305/305 [==============================] - 0s 413us/step - loss: 0.3955 - accuracy: 0.8129\n",
      "Epoch 69/200\n",
      "305/305 [==============================] - 0s 425us/step - loss: 0.3908 - accuracy: 0.8135\n",
      "Epoch 70/200\n",
      "305/305 [==============================] - 0s 453us/step - loss: 0.3886 - accuracy: 0.8147\n",
      "Epoch 71/200\n",
      "305/305 [==============================] - 0s 795us/step - loss: 0.3904 - accuracy: 0.8110\n",
      "Epoch 72/200\n",
      "305/305 [==============================] - 0s 519us/step - loss: 0.3928 - accuracy: 0.8114\n",
      "Epoch 73/200\n",
      "305/305 [==============================] - 0s 481us/step - loss: 0.3906 - accuracy: 0.8168\n",
      "Epoch 74/200\n",
      "305/305 [==============================] - 0s 432us/step - loss: 0.3894 - accuracy: 0.8153\n",
      "Epoch 75/200\n",
      "305/305 [==============================] - 0s 442us/step - loss: 0.3886 - accuracy: 0.8166\n",
      "Epoch 76/200\n",
      "305/305 [==============================] - 0s 456us/step - loss: 0.3942 - accuracy: 0.8096\n",
      "Epoch 77/200\n",
      "305/305 [==============================] - 0s 429us/step - loss: 0.3901 - accuracy: 0.8120\n",
      "Epoch 78/200\n",
      "305/305 [==============================] - 0s 453us/step - loss: 0.3887 - accuracy: 0.8149\n",
      "Epoch 79/200\n",
      "305/305 [==============================] - 0s 440us/step - loss: 0.3913 - accuracy: 0.8153\n",
      "Epoch 80/200\n",
      "305/305 [==============================] - 0s 443us/step - loss: 0.3878 - accuracy: 0.8168\n",
      "Epoch 81/200\n",
      "305/305 [==============================] - 0s 428us/step - loss: 0.3921 - accuracy: 0.8112\n",
      "Epoch 82/200\n",
      "305/305 [==============================] - 0s 425us/step - loss: 0.3895 - accuracy: 0.8094\n",
      "Epoch 83/200\n",
      "305/305 [==============================] - 0s 436us/step - loss: 0.3945 - accuracy: 0.8051\n",
      "Epoch 84/200\n",
      "305/305 [==============================] - 0s 437us/step - loss: 0.3848 - accuracy: 0.8139\n",
      "Epoch 85/200\n",
      "305/305 [==============================] - 0s 436us/step - loss: 0.3869 - accuracy: 0.8147\n",
      "Epoch 86/200\n",
      "305/305 [==============================] - 0s 421us/step - loss: 0.3923 - accuracy: 0.8081\n",
      "Epoch 87/200\n",
      "305/305 [==============================] - 0s 418us/step - loss: 0.3863 - accuracy: 0.8194\n",
      "Epoch 88/200\n",
      "305/305 [==============================] - 0s 412us/step - loss: 0.3868 - accuracy: 0.8155\n",
      "Epoch 89/200\n",
      "305/305 [==============================] - 0s 419us/step - loss: 0.3940 - accuracy: 0.8106\n",
      "Epoch 90/200\n",
      "305/305 [==============================] - 0s 422us/step - loss: 0.3915 - accuracy: 0.8131\n",
      "Epoch 91/200\n",
      "305/305 [==============================] - 0s 429us/step - loss: 0.3865 - accuracy: 0.8151\n",
      "Epoch 92/200\n",
      "305/305 [==============================] - 0s 416us/step - loss: 0.3886 - accuracy: 0.8147\n",
      "Epoch 93/200\n",
      "305/305 [==============================] - 0s 419us/step - loss: 0.3942 - accuracy: 0.8071\n",
      "Epoch 94/200\n",
      "305/305 [==============================] - 0s 416us/step - loss: 0.3866 - accuracy: 0.8182\n",
      "Epoch 95/200\n",
      "305/305 [==============================] - 0s 418us/step - loss: 0.3872 - accuracy: 0.8203\n",
      "Epoch 96/200\n",
      "305/305 [==============================] - 0s 419us/step - loss: 0.3868 - accuracy: 0.8129\n",
      "Epoch 97/200\n",
      "305/305 [==============================] - 0s 411us/step - loss: 0.3882 - accuracy: 0.8124\n",
      "Epoch 98/200\n",
      "305/305 [==============================] - 0s 705us/step - loss: 0.3868 - accuracy: 0.8137\n",
      "Epoch 99/200\n",
      "305/305 [==============================] - 0s 444us/step - loss: 0.3917 - accuracy: 0.8153\n",
      "Epoch 100/200\n",
      "305/305 [==============================] - 0s 439us/step - loss: 0.3872 - accuracy: 0.8139\n",
      "Epoch 101/200\n",
      "305/305 [==============================] - 0s 419us/step - loss: 0.3843 - accuracy: 0.8153\n",
      "Epoch 102/200\n",
      "305/305 [==============================] - 0s 416us/step - loss: 0.3932 - accuracy: 0.8133\n",
      "Epoch 103/200\n",
      "305/305 [==============================] - 0s 427us/step - loss: 0.3894 - accuracy: 0.8108\n",
      "Epoch 104/200\n",
      "305/305 [==============================] - 0s 423us/step - loss: 0.3934 - accuracy: 0.8131\n",
      "Epoch 105/200\n",
      "305/305 [==============================] - 0s 420us/step - loss: 0.3885 - accuracy: 0.8145\n",
      "Epoch 106/200\n",
      "305/305 [==============================] - 0s 417us/step - loss: 0.3857 - accuracy: 0.8168\n",
      "Epoch 107/200\n",
      "305/305 [==============================] - 0s 416us/step - loss: 0.3929 - accuracy: 0.8151\n",
      "Epoch 108/200\n",
      "305/305 [==============================] - 0s 428us/step - loss: 0.3847 - accuracy: 0.8168\n",
      "Epoch 109/200\n",
      "305/305 [==============================] - 0s 413us/step - loss: 0.3879 - accuracy: 0.8135\n",
      "Epoch 110/200\n",
      "305/305 [==============================] - 0s 415us/step - loss: 0.3854 - accuracy: 0.8120\n",
      "Epoch 111/200\n",
      "305/305 [==============================] - 0s 420us/step - loss: 0.3918 - accuracy: 0.8170\n",
      "Epoch 112/200\n",
      "305/305 [==============================] - 0s 419us/step - loss: 0.3920 - accuracy: 0.8129\n",
      "Epoch 113/200\n",
      "305/305 [==============================] - 0s 417us/step - loss: 0.3893 - accuracy: 0.8120\n",
      "Epoch 114/200\n",
      "305/305 [==============================] - 0s 418us/step - loss: 0.3872 - accuracy: 0.8141\n",
      "Epoch 115/200\n",
      "305/305 [==============================] - 0s 418us/step - loss: 0.3843 - accuracy: 0.8131\n",
      "Epoch 116/200\n",
      "305/305 [==============================] - 0s 413us/step - loss: 0.3883 - accuracy: 0.8153\n",
      "Epoch 117/200\n",
      "305/305 [==============================] - 0s 430us/step - loss: 0.3883 - accuracy: 0.8137\n",
      "Epoch 118/200\n",
      "305/305 [==============================] - 0s 426us/step - loss: 0.3836 - accuracy: 0.8161\n",
      "Epoch 119/200\n",
      "305/305 [==============================] - 0s 427us/step - loss: 0.3827 - accuracy: 0.8118\n",
      "Epoch 120/200\n",
      "305/305 [==============================] - 0s 429us/step - loss: 0.3871 - accuracy: 0.8188\n",
      "Epoch 121/200\n",
      "305/305 [==============================] - 0s 437us/step - loss: 0.3853 - accuracy: 0.8190\n",
      "Epoch 122/200\n",
      "305/305 [==============================] - 0s 430us/step - loss: 0.3848 - accuracy: 0.8178\n",
      "Epoch 123/200\n",
      "305/305 [==============================] - 0s 425us/step - loss: 0.3874 - accuracy: 0.8122\n",
      "Epoch 124/200\n",
      "305/305 [==============================] - 0s 433us/step - loss: 0.3891 - accuracy: 0.8149\n",
      "Epoch 125/200\n",
      "305/305 [==============================] - 0s 428us/step - loss: 0.3891 - accuracy: 0.8145\n",
      "Epoch 126/200\n",
      "305/305 [==============================] - 0s 537us/step - loss: 0.3860 - accuracy: 0.8166\n",
      "Epoch 127/200\n",
      "305/305 [==============================] - 0s 490us/step - loss: 0.3886 - accuracy: 0.8114\n",
      "Epoch 128/200\n",
      "305/305 [==============================] - 0s 444us/step - loss: 0.3824 - accuracy: 0.8188\n",
      "Epoch 129/200\n",
      "305/305 [==============================] - 0s 430us/step - loss: 0.3853 - accuracy: 0.8170\n",
      "Epoch 130/200\n",
      "305/305 [==============================] - 0s 425us/step - loss: 0.3828 - accuracy: 0.8176\n",
      "Epoch 131/200\n",
      "305/305 [==============================] - 0s 422us/step - loss: 0.3748 - accuracy: 0.8215\n",
      "Epoch 132/200\n",
      "305/305 [==============================] - 0s 427us/step - loss: 0.3876 - accuracy: 0.8157\n",
      "Epoch 133/200\n",
      "305/305 [==============================] - 0s 425us/step - loss: 0.3844 - accuracy: 0.8141\n",
      "Epoch 134/200\n",
      "305/305 [==============================] - 0s 430us/step - loss: 0.3862 - accuracy: 0.8116\n",
      "Epoch 135/200\n",
      "305/305 [==============================] - 0s 420us/step - loss: 0.3916 - accuracy: 0.8133\n",
      "Epoch 136/200\n",
      "305/305 [==============================] - 0s 445us/step - loss: 0.3859 - accuracy: 0.8131\n",
      "Epoch 137/200\n",
      "305/305 [==============================] - 0s 468us/step - loss: 0.3801 - accuracy: 0.8153\n",
      "Epoch 138/200\n",
      "305/305 [==============================] - 0s 434us/step - loss: 0.3819 - accuracy: 0.8131\n",
      "Epoch 139/200\n",
      "305/305 [==============================] - 0s 428us/step - loss: 0.3856 - accuracy: 0.8149\n",
      "Epoch 140/200\n",
      "305/305 [==============================] - 0s 427us/step - loss: 0.3837 - accuracy: 0.8135\n",
      "Epoch 141/200\n",
      "305/305 [==============================] - 0s 420us/step - loss: 0.3830 - accuracy: 0.8141\n",
      "Epoch 142/200\n",
      "305/305 [==============================] - 0s 420us/step - loss: 0.3843 - accuracy: 0.8166\n",
      "Epoch 143/200\n",
      "305/305 [==============================] - 0s 435us/step - loss: 0.3933 - accuracy: 0.8137\n",
      "Epoch 144/200\n",
      "305/305 [==============================] - 0s 420us/step - loss: 0.3821 - accuracy: 0.8159\n",
      "Epoch 145/200\n",
      "305/305 [==============================] - 0s 428us/step - loss: 0.3836 - accuracy: 0.8161\n",
      "Epoch 146/200\n",
      "305/305 [==============================] - 0s 414us/step - loss: 0.3812 - accuracy: 0.8114\n",
      "Epoch 147/200\n",
      "305/305 [==============================] - 0s 416us/step - loss: 0.3868 - accuracy: 0.8127\n",
      "Epoch 148/200\n",
      "305/305 [==============================] - 0s 418us/step - loss: 0.3860 - accuracy: 0.8110\n",
      "Epoch 149/200\n",
      "305/305 [==============================] - 0s 410us/step - loss: 0.3840 - accuracy: 0.8112\n",
      "Epoch 150/200\n",
      "305/305 [==============================] - 0s 435us/step - loss: 0.3847 - accuracy: 0.8198\n",
      "Epoch 151/200\n",
      "305/305 [==============================] - 0s 449us/step - loss: 0.3874 - accuracy: 0.8124\n",
      "Epoch 152/200\n",
      "305/305 [==============================] - 0s 445us/step - loss: 0.3842 - accuracy: 0.8174\n",
      "Epoch 153/200\n",
      "305/305 [==============================] - 0s 435us/step - loss: 0.3873 - accuracy: 0.8088\n",
      "Epoch 154/200\n",
      "305/305 [==============================] - 0s 433us/step - loss: 0.3850 - accuracy: 0.8104\n",
      "Epoch 155/200\n",
      "305/305 [==============================] - 0s 776us/step - loss: 0.3833 - accuracy: 0.8108\n",
      "Epoch 156/200\n",
      "305/305 [==============================] - 0s 488us/step - loss: 0.3838 - accuracy: 0.8153\n",
      "Epoch 157/200\n",
      "305/305 [==============================] - 0s 959us/step - loss: 0.3827 - accuracy: 0.8153\n",
      "Epoch 158/200\n",
      "305/305 [==============================] - 0s 597us/step - loss: 0.3825 - accuracy: 0.8188\n",
      "Epoch 159/200\n",
      "305/305 [==============================] - 0s 424us/step - loss: 0.3826 - accuracy: 0.8141\n",
      "Epoch 160/200\n",
      "305/305 [==============================] - 0s 442us/step - loss: 0.3852 - accuracy: 0.8166\n",
      "Epoch 161/200\n",
      "305/305 [==============================] - 0s 428us/step - loss: 0.3806 - accuracy: 0.8141\n",
      "Epoch 162/200\n",
      "305/305 [==============================] - 0s 479us/step - loss: 0.3784 - accuracy: 0.8242\n",
      "Epoch 163/200\n",
      "305/305 [==============================] - 0s 418us/step - loss: 0.3836 - accuracy: 0.8143\n",
      "Epoch 164/200\n",
      "305/305 [==============================] - 0s 422us/step - loss: 0.3823 - accuracy: 0.8122\n",
      "Epoch 165/200\n",
      "305/305 [==============================] - 0s 430us/step - loss: 0.3783 - accuracy: 0.8129\n",
      "Epoch 166/200\n",
      "305/305 [==============================] - 0s 430us/step - loss: 0.3782 - accuracy: 0.8124\n",
      "Epoch 167/200\n",
      "305/305 [==============================] - 0s 421us/step - loss: 0.3849 - accuracy: 0.8131\n",
      "Epoch 168/200\n",
      "305/305 [==============================] - 0s 427us/step - loss: 0.3869 - accuracy: 0.8151\n",
      "Epoch 169/200\n",
      "305/305 [==============================] - 0s 421us/step - loss: 0.3834 - accuracy: 0.8188\n",
      "Epoch 170/200\n",
      "305/305 [==============================] - 0s 424us/step - loss: 0.3821 - accuracy: 0.8110\n",
      "Epoch 171/200\n",
      "305/305 [==============================] - 0s 443us/step - loss: 0.3760 - accuracy: 0.8178\n",
      "Epoch 172/200\n",
      "305/305 [==============================] - 0s 423us/step - loss: 0.3792 - accuracy: 0.8174\n",
      "Epoch 173/200\n",
      "305/305 [==============================] - 0s 430us/step - loss: 0.3823 - accuracy: 0.8151\n",
      "Epoch 174/200\n",
      "305/305 [==============================] - 0s 419us/step - loss: 0.3882 - accuracy: 0.8133\n",
      "Epoch 175/200\n",
      "305/305 [==============================] - 0s 428us/step - loss: 0.3829 - accuracy: 0.8102\n",
      "Epoch 176/200\n",
      "305/305 [==============================] - 0s 430us/step - loss: 0.3798 - accuracy: 0.8176\n",
      "Epoch 177/200\n",
      "305/305 [==============================] - 0s 475us/step - loss: 0.3806 - accuracy: 0.8174\n",
      "Epoch 178/200\n",
      "305/305 [==============================] - 0s 456us/step - loss: 0.3815 - accuracy: 0.8159\n",
      "Epoch 179/200\n",
      "305/305 [==============================] - 0s 638us/step - loss: 0.3841 - accuracy: 0.8127\n",
      "Epoch 180/200\n",
      "305/305 [==============================] - 0s 514us/step - loss: 0.3797 - accuracy: 0.8188\n",
      "Epoch 181/200\n",
      "305/305 [==============================] - 0s 438us/step - loss: 0.3766 - accuracy: 0.8198\n",
      "Epoch 182/200\n",
      "305/305 [==============================] - 0s 446us/step - loss: 0.3820 - accuracy: 0.8159\n",
      "Epoch 183/200\n",
      "305/305 [==============================] - 0s 431us/step - loss: 0.3842 - accuracy: 0.8188\n",
      "Epoch 184/200\n",
      "305/305 [==============================] - 0s 419us/step - loss: 0.3786 - accuracy: 0.8149\n",
      "Epoch 185/200\n",
      "305/305 [==============================] - 0s 435us/step - loss: 0.3824 - accuracy: 0.8209\n",
      "Epoch 186/200\n",
      "305/305 [==============================] - 0s 423us/step - loss: 0.3821 - accuracy: 0.8106\n",
      "Epoch 187/200\n",
      "305/305 [==============================] - 0s 423us/step - loss: 0.3789 - accuracy: 0.8149\n",
      "Epoch 188/200\n",
      "305/305 [==============================] - 0s 422us/step - loss: 0.3773 - accuracy: 0.8151\n",
      "Epoch 189/200\n",
      "305/305 [==============================] - 0s 410us/step - loss: 0.3779 - accuracy: 0.8139\n",
      "Epoch 190/200\n",
      "305/305 [==============================] - 0s 419us/step - loss: 0.3763 - accuracy: 0.8180\n",
      "Epoch 191/200\n",
      "305/305 [==============================] - 0s 425us/step - loss: 0.3871 - accuracy: 0.8127\n",
      "Epoch 192/200\n",
      "305/305 [==============================] - 0s 459us/step - loss: 0.3860 - accuracy: 0.8116\n",
      "Epoch 193/200\n",
      "305/305 [==============================] - 0s 462us/step - loss: 0.3783 - accuracy: 0.8188\n",
      "Epoch 194/200\n",
      "305/305 [==============================] - 0s 508us/step - loss: 0.3779 - accuracy: 0.8168\n",
      "Epoch 195/200\n",
      "305/305 [==============================] - 0s 444us/step - loss: 0.3791 - accuracy: 0.8180\n",
      "Epoch 196/200\n",
      "305/305 [==============================] - 0s 429us/step - loss: 0.3793 - accuracy: 0.8213\n",
      "Epoch 197/200\n",
      "305/305 [==============================] - 0s 426us/step - loss: 0.3786 - accuracy: 0.8170\n",
      "Epoch 198/200\n",
      "305/305 [==============================] - 0s 426us/step - loss: 0.3807 - accuracy: 0.8178\n",
      "Epoch 199/200\n",
      "305/305 [==============================] - 0s 451us/step - loss: 0.3822 - accuracy: 0.8153\n",
      "Epoch 200/200\n",
      "305/305 [==============================] - 0s 466us/step - loss: 0.3837 - accuracy: 0.8131\n",
      "39/39 [==============================] - 0s 357us/step\n",
      "Epoch 1/200\n",
      "305/305 [==============================] - 0s 441us/step - loss: 0.5433 - accuracy: 0.7048\n",
      "Epoch 2/200\n",
      "305/305 [==============================] - 0s 436us/step - loss: 0.4411 - accuracy: 0.7806\n",
      "Epoch 3/200\n",
      "305/305 [==============================] - 0s 428us/step - loss: 0.4302 - accuracy: 0.7903\n",
      "Epoch 4/200\n",
      "305/305 [==============================] - 0s 749us/step - loss: 0.4341 - accuracy: 0.7915\n",
      "Epoch 5/200\n",
      "305/305 [==============================] - 0s 435us/step - loss: 0.4282 - accuracy: 0.7890\n",
      "Epoch 6/200\n",
      "305/305 [==============================] - 0s 449us/step - loss: 0.4260 - accuracy: 0.7890\n",
      "Epoch 7/200\n",
      "305/305 [==============================] - 0s 439us/step - loss: 0.4219 - accuracy: 0.7952\n",
      "Epoch 8/200\n",
      "305/305 [==============================] - 0s 428us/step - loss: 0.4218 - accuracy: 0.7962\n",
      "Epoch 9/200\n",
      "305/305 [==============================] - 0s 426us/step - loss: 0.4224 - accuracy: 0.7960\n",
      "Epoch 10/200\n",
      "305/305 [==============================] - 0s 422us/step - loss: 0.4137 - accuracy: 0.7972\n",
      "Epoch 11/200\n",
      "305/305 [==============================] - 0s 423us/step - loss: 0.4139 - accuracy: 0.7940\n",
      "Epoch 12/200\n",
      "305/305 [==============================] - 0s 433us/step - loss: 0.4090 - accuracy: 0.7979\n",
      "Epoch 13/200\n",
      "305/305 [==============================] - 0s 435us/step - loss: 0.4161 - accuracy: 0.7993\n",
      "Epoch 14/200\n",
      "305/305 [==============================] - 0s 482us/step - loss: 0.4163 - accuracy: 0.7964\n",
      "Epoch 15/200\n",
      "305/305 [==============================] - 0s 443us/step - loss: 0.4101 - accuracy: 0.8020\n",
      "Epoch 16/200\n",
      "305/305 [==============================] - 0s 459us/step - loss: 0.4153 - accuracy: 0.7999\n",
      "Epoch 17/200\n",
      "305/305 [==============================] - 0s 457us/step - loss: 0.4130 - accuracy: 0.7972\n",
      "Epoch 18/200\n",
      "305/305 [==============================] - 0s 486us/step - loss: 0.4098 - accuracy: 0.8026\n",
      "Epoch 19/200\n",
      "305/305 [==============================] - 0s 446us/step - loss: 0.4053 - accuracy: 0.8001\n",
      "Epoch 20/200\n",
      "305/305 [==============================] - 0s 461us/step - loss: 0.4088 - accuracy: 0.8001\n",
      "Epoch 21/200\n",
      "305/305 [==============================] - 0s 444us/step - loss: 0.4027 - accuracy: 0.8046\n",
      "Epoch 22/200\n",
      "305/305 [==============================] - 0s 532us/step - loss: 0.4036 - accuracy: 0.8059\n",
      "Epoch 23/200\n",
      "305/305 [==============================] - 0s 462us/step - loss: 0.4093 - accuracy: 0.8005\n",
      "Epoch 24/200\n",
      "305/305 [==============================] - 0s 428us/step - loss: 0.4070 - accuracy: 0.8020\n",
      "Epoch 25/200\n",
      "305/305 [==============================] - 0s 427us/step - loss: 0.4041 - accuracy: 0.8001\n",
      "Epoch 26/200\n",
      "305/305 [==============================] - 0s 426us/step - loss: 0.4029 - accuracy: 0.8057\n",
      "Epoch 27/200\n",
      "305/305 [==============================] - 0s 425us/step - loss: 0.4054 - accuracy: 0.8030\n",
      "Epoch 28/200\n",
      "305/305 [==============================] - 0s 431us/step - loss: 0.3984 - accuracy: 0.8079\n",
      "Epoch 29/200\n",
      "305/305 [==============================] - 0s 472us/step - loss: 0.3996 - accuracy: 0.8079\n",
      "Epoch 30/200\n",
      "305/305 [==============================] - 0s 741us/step - loss: 0.4062 - accuracy: 0.7966\n",
      "Epoch 31/200\n",
      "305/305 [==============================] - 0s 484us/step - loss: 0.4022 - accuracy: 0.8100\n",
      "Epoch 32/200\n",
      "305/305 [==============================] - 0s 460us/step - loss: 0.3994 - accuracy: 0.8063\n",
      "Epoch 33/200\n",
      "305/305 [==============================] - 0s 451us/step - loss: 0.4033 - accuracy: 0.8046\n",
      "Epoch 34/200\n",
      "305/305 [==============================] - 0s 438us/step - loss: 0.4026 - accuracy: 0.8057\n",
      "Epoch 35/200\n",
      "305/305 [==============================] - 0s 433us/step - loss: 0.3994 - accuracy: 0.8046\n",
      "Epoch 36/200\n",
      "305/305 [==============================] - 0s 431us/step - loss: 0.3996 - accuracy: 0.8069\n",
      "Epoch 37/200\n",
      "305/305 [==============================] - 0s 427us/step - loss: 0.3977 - accuracy: 0.8069\n",
      "Epoch 38/200\n",
      "305/305 [==============================] - 0s 421us/step - loss: 0.3918 - accuracy: 0.8135\n",
      "Epoch 39/200\n",
      "305/305 [==============================] - 0s 425us/step - loss: 0.3999 - accuracy: 0.8083\n",
      "Epoch 40/200\n",
      "305/305 [==============================] - 0s 423us/step - loss: 0.3980 - accuracy: 0.8040\n",
      "Epoch 41/200\n",
      "305/305 [==============================] - 0s 418us/step - loss: 0.3994 - accuracy: 0.8081\n",
      "Epoch 42/200\n",
      "305/305 [==============================] - 0s 433us/step - loss: 0.3988 - accuracy: 0.8102\n",
      "Epoch 43/200\n",
      "305/305 [==============================] - 0s 422us/step - loss: 0.3952 - accuracy: 0.8079\n",
      "Epoch 44/200\n",
      "305/305 [==============================] - 0s 428us/step - loss: 0.3959 - accuracy: 0.8036\n",
      "Epoch 45/200\n",
      "305/305 [==============================] - 0s 434us/step - loss: 0.3942 - accuracy: 0.8100\n",
      "Epoch 46/200\n",
      "305/305 [==============================] - 0s 423us/step - loss: 0.3960 - accuracy: 0.8094\n",
      "Epoch 47/200\n",
      "305/305 [==============================] - 0s 431us/step - loss: 0.3944 - accuracy: 0.8055\n",
      "Epoch 48/200\n",
      "305/305 [==============================] - 0s 421us/step - loss: 0.3929 - accuracy: 0.8096\n",
      "Epoch 49/200\n",
      "305/305 [==============================] - 0s 422us/step - loss: 0.4003 - accuracy: 0.8034\n",
      "Epoch 50/200\n",
      "305/305 [==============================] - 0s 456us/step - loss: 0.3960 - accuracy: 0.8137\n",
      "Epoch 51/200\n",
      "305/305 [==============================] - 0s 429us/step - loss: 0.3932 - accuracy: 0.8090\n",
      "Epoch 52/200\n",
      "305/305 [==============================] - 0s 420us/step - loss: 0.3949 - accuracy: 0.8153\n",
      "Epoch 53/200\n",
      "305/305 [==============================] - 0s 605us/step - loss: 0.3904 - accuracy: 0.8114\n",
      "Epoch 54/200\n",
      "305/305 [==============================] - 0s 429us/step - loss: 0.3967 - accuracy: 0.8088\n",
      "Epoch 55/200\n",
      "305/305 [==============================] - 0s 443us/step - loss: 0.3904 - accuracy: 0.8108\n",
      "Epoch 56/200\n",
      "305/305 [==============================] - 0s 436us/step - loss: 0.3918 - accuracy: 0.8166\n",
      "Epoch 57/200\n",
      "305/305 [==============================] - 0s 426us/step - loss: 0.3978 - accuracy: 0.8106\n",
      "Epoch 58/200\n",
      "305/305 [==============================] - 0s 440us/step - loss: 0.3967 - accuracy: 0.8067\n",
      "Epoch 59/200\n",
      "305/305 [==============================] - 0s 429us/step - loss: 0.3885 - accuracy: 0.8129\n",
      "Epoch 60/200\n",
      "305/305 [==============================] - 0s 428us/step - loss: 0.3901 - accuracy: 0.8106\n",
      "Epoch 61/200\n",
      "305/305 [==============================] - 0s 421us/step - loss: 0.3921 - accuracy: 0.8110\n",
      "Epoch 62/200\n",
      "305/305 [==============================] - 0s 430us/step - loss: 0.3918 - accuracy: 0.8133\n",
      "Epoch 63/200\n",
      "305/305 [==============================] - 0s 430us/step - loss: 0.3921 - accuracy: 0.8161\n",
      "Epoch 64/200\n",
      "305/305 [==============================] - 0s 428us/step - loss: 0.3908 - accuracy: 0.8151\n",
      "Epoch 65/200\n",
      "305/305 [==============================] - 0s 458us/step - loss: 0.3877 - accuracy: 0.8139\n",
      "Epoch 66/200\n",
      "305/305 [==============================] - 0s 472us/step - loss: 0.3955 - accuracy: 0.8075\n",
      "Epoch 67/200\n",
      "305/305 [==============================] - 0s 449us/step - loss: 0.3932 - accuracy: 0.8081\n",
      "Epoch 68/200\n",
      "305/305 [==============================] - 0s 420us/step - loss: 0.3883 - accuracy: 0.8153\n",
      "Epoch 69/200\n",
      "305/305 [==============================] - 0s 427us/step - loss: 0.3917 - accuracy: 0.8114\n",
      "Epoch 70/200\n",
      "305/305 [==============================] - 0s 443us/step - loss: 0.3925 - accuracy: 0.8067\n",
      "Epoch 71/200\n",
      "305/305 [==============================] - 0s 496us/step - loss: 0.3930 - accuracy: 0.8077\n",
      "Epoch 72/200\n",
      "305/305 [==============================] - 0s 451us/step - loss: 0.3903 - accuracy: 0.8112\n",
      "Epoch 73/200\n",
      "305/305 [==============================] - 0s 458us/step - loss: 0.3923 - accuracy: 0.8108\n",
      "Epoch 74/200\n",
      "305/305 [==============================] - 0s 461us/step - loss: 0.3889 - accuracy: 0.8157\n",
      "Epoch 75/200\n",
      "305/305 [==============================] - 0s 572us/step - loss: 0.3879 - accuracy: 0.8098\n",
      "Epoch 76/200\n",
      "305/305 [==============================] - 0s 521us/step - loss: 0.3886 - accuracy: 0.8083\n",
      "Epoch 77/200\n",
      "305/305 [==============================] - 0s 529us/step - loss: 0.3935 - accuracy: 0.8120\n",
      "Epoch 78/200\n",
      "305/305 [==============================] - 0s 466us/step - loss: 0.3892 - accuracy: 0.8083\n",
      "Epoch 79/200\n",
      "305/305 [==============================] - 0s 447us/step - loss: 0.3903 - accuracy: 0.8088\n",
      "Epoch 80/200\n",
      "305/305 [==============================] - 0s 445us/step - loss: 0.3885 - accuracy: 0.8151\n",
      "Epoch 81/200\n",
      "305/305 [==============================] - 0s 429us/step - loss: 0.3904 - accuracy: 0.8085\n",
      "Epoch 82/200\n",
      "305/305 [==============================] - 0s 446us/step - loss: 0.3883 - accuracy: 0.8112\n",
      "Epoch 83/200\n",
      "305/305 [==============================] - 0s 430us/step - loss: 0.3936 - accuracy: 0.8073\n",
      "Epoch 84/200\n",
      "305/305 [==============================] - 0s 428us/step - loss: 0.3864 - accuracy: 0.8139\n",
      "Epoch 85/200\n",
      "305/305 [==============================] - 0s 436us/step - loss: 0.3917 - accuracy: 0.8120\n",
      "Epoch 86/200\n",
      "305/305 [==============================] - 0s 437us/step - loss: 0.3893 - accuracy: 0.8172\n",
      "Epoch 87/200\n",
      "305/305 [==============================] - 0s 424us/step - loss: 0.3904 - accuracy: 0.8114\n",
      "Epoch 88/200\n",
      "305/305 [==============================] - 0s 458us/step - loss: 0.3880 - accuracy: 0.8112\n",
      "Epoch 89/200\n",
      "305/305 [==============================] - 0s 448us/step - loss: 0.3876 - accuracy: 0.8133\n",
      "Epoch 90/200\n",
      "305/305 [==============================] - 0s 731us/step - loss: 0.3900 - accuracy: 0.8088\n",
      "Epoch 91/200\n",
      "305/305 [==============================] - 0s 574us/step - loss: 0.3914 - accuracy: 0.8135\n",
      "Epoch 92/200\n",
      "305/305 [==============================] - 0s 483us/step - loss: 0.3863 - accuracy: 0.8110\n",
      "Epoch 93/200\n",
      "305/305 [==============================] - 0s 461us/step - loss: 0.3898 - accuracy: 0.8112\n",
      "Epoch 94/200\n",
      "305/305 [==============================] - 0s 471us/step - loss: 0.3876 - accuracy: 0.8094\n",
      "Epoch 95/200\n",
      "305/305 [==============================] - 0s 462us/step - loss: 0.3846 - accuracy: 0.8164\n",
      "Epoch 96/200\n",
      "305/305 [==============================] - 0s 451us/step - loss: 0.3873 - accuracy: 0.8106\n",
      "Epoch 97/200\n",
      "305/305 [==============================] - 0s 439us/step - loss: 0.3888 - accuracy: 0.8143\n",
      "Epoch 98/200\n",
      "305/305 [==============================] - 0s 774us/step - loss: 0.3857 - accuracy: 0.8063\n",
      "Epoch 99/200\n",
      "305/305 [==============================] - 0s 536us/step - loss: 0.3865 - accuracy: 0.8131\n",
      "Epoch 100/200\n",
      "305/305 [==============================] - 0s 458us/step - loss: 0.3875 - accuracy: 0.8108\n",
      "Epoch 101/200\n",
      "305/305 [==============================] - 0s 443us/step - loss: 0.3872 - accuracy: 0.8085\n",
      "Epoch 102/200\n",
      "305/305 [==============================] - 0s 448us/step - loss: 0.3868 - accuracy: 0.8141\n",
      "Epoch 103/200\n",
      "305/305 [==============================] - 0s 447us/step - loss: 0.3898 - accuracy: 0.8108\n",
      "Epoch 104/200\n",
      "305/305 [==============================] - 0s 476us/step - loss: 0.3860 - accuracy: 0.8102\n",
      "Epoch 105/200\n",
      "305/305 [==============================] - 0s 435us/step - loss: 0.3845 - accuracy: 0.8153\n",
      "Epoch 106/200\n",
      "305/305 [==============================] - 0s 442us/step - loss: 0.3865 - accuracy: 0.8135\n",
      "Epoch 107/200\n",
      "305/305 [==============================] - 0s 437us/step - loss: 0.3853 - accuracy: 0.8145\n",
      "Epoch 108/200\n",
      "305/305 [==============================] - 0s 478us/step - loss: 0.3871 - accuracy: 0.8092\n",
      "Epoch 109/200\n",
      "305/305 [==============================] - 0s 457us/step - loss: 0.3822 - accuracy: 0.8172\n",
      "Epoch 110/200\n",
      "305/305 [==============================] - 0s 445us/step - loss: 0.3843 - accuracy: 0.8112\n",
      "Epoch 111/200\n",
      "305/305 [==============================] - 0s 443us/step - loss: 0.3794 - accuracy: 0.8198\n",
      "Epoch 112/200\n",
      "305/305 [==============================] - 0s 443us/step - loss: 0.3852 - accuracy: 0.8168\n",
      "Epoch 113/200\n",
      "305/305 [==============================] - 0s 461us/step - loss: 0.3893 - accuracy: 0.8124\n",
      "Epoch 114/200\n",
      "305/305 [==============================] - 0s 441us/step - loss: 0.3841 - accuracy: 0.8198\n",
      "Epoch 115/200\n",
      "305/305 [==============================] - 0s 448us/step - loss: 0.3800 - accuracy: 0.8188\n",
      "Epoch 116/200\n",
      "305/305 [==============================] - 0s 441us/step - loss: 0.3821 - accuracy: 0.8161\n",
      "Epoch 117/200\n",
      "305/305 [==============================] - 0s 435us/step - loss: 0.3874 - accuracy: 0.8135\n",
      "Epoch 118/200\n",
      "305/305 [==============================] - 0s 425us/step - loss: 0.3792 - accuracy: 0.8207\n",
      "Epoch 119/200\n",
      "305/305 [==============================] - 0s 704us/step - loss: 0.3814 - accuracy: 0.8135\n",
      "Epoch 120/200\n",
      "305/305 [==============================] - 0s 431us/step - loss: 0.3727 - accuracy: 0.8205\n",
      "Epoch 121/200\n",
      "305/305 [==============================] - 0s 507us/step - loss: 0.3837 - accuracy: 0.8151\n",
      "Epoch 122/200\n",
      "305/305 [==============================] - 0s 447us/step - loss: 0.3830 - accuracy: 0.8166\n",
      "Epoch 123/200\n",
      "305/305 [==============================] - 0s 476us/step - loss: 0.3849 - accuracy: 0.8168\n",
      "Epoch 124/200\n",
      "305/305 [==============================] - 0s 432us/step - loss: 0.3747 - accuracy: 0.8207\n",
      "Epoch 125/200\n",
      "305/305 [==============================] - 0s 469us/step - loss: 0.3790 - accuracy: 0.8153\n",
      "Epoch 126/200\n",
      "305/305 [==============================] - 0s 485us/step - loss: 0.3783 - accuracy: 0.8133\n",
      "Epoch 127/200\n",
      "305/305 [==============================] - 0s 450us/step - loss: 0.3776 - accuracy: 0.8192\n",
      "Epoch 128/200\n",
      "305/305 [==============================] - 0s 441us/step - loss: 0.3861 - accuracy: 0.8112\n",
      "Epoch 129/200\n",
      "305/305 [==============================] - 0s 446us/step - loss: 0.3800 - accuracy: 0.8159\n",
      "Epoch 130/200\n",
      "305/305 [==============================] - 0s 426us/step - loss: 0.3797 - accuracy: 0.8110\n",
      "Epoch 131/200\n",
      "305/305 [==============================] - 0s 431us/step - loss: 0.3796 - accuracy: 0.8112\n",
      "Epoch 132/200\n",
      "305/305 [==============================] - 0s 462us/step - loss: 0.3856 - accuracy: 0.8114\n",
      "Epoch 133/200\n",
      "305/305 [==============================] - 0s 503us/step - loss: 0.3843 - accuracy: 0.8118\n",
      "Epoch 134/200\n",
      "305/305 [==============================] - 0s 451us/step - loss: 0.3748 - accuracy: 0.8200\n",
      "Epoch 135/200\n",
      "305/305 [==============================] - 0s 441us/step - loss: 0.3795 - accuracy: 0.8153\n",
      "Epoch 136/200\n",
      "305/305 [==============================] - 0s 512us/step - loss: 0.3817 - accuracy: 0.8106\n",
      "Epoch 137/200\n",
      "305/305 [==============================] - 0s 445us/step - loss: 0.3803 - accuracy: 0.8159\n",
      "Epoch 138/200\n",
      "305/305 [==============================] - 0s 472us/step - loss: 0.3790 - accuracy: 0.8190\n",
      "Epoch 139/200\n",
      "305/305 [==============================] - 0s 442us/step - loss: 0.3799 - accuracy: 0.8166\n",
      "Epoch 140/200\n",
      "305/305 [==============================] - 0s 459us/step - loss: 0.3780 - accuracy: 0.8178\n",
      "Epoch 141/200\n",
      "305/305 [==============================] - 0s 828us/step - loss: 0.3826 - accuracy: 0.8166\n",
      "Epoch 142/200\n",
      "305/305 [==============================] - 0s 499us/step - loss: 0.3823 - accuracy: 0.8155\n",
      "Epoch 143/200\n",
      "305/305 [==============================] - 0s 436us/step - loss: 0.3787 - accuracy: 0.8153\n",
      "Epoch 144/200\n",
      "305/305 [==============================] - 0s 440us/step - loss: 0.3817 - accuracy: 0.8120\n",
      "Epoch 145/200\n",
      "305/305 [==============================] - 0s 439us/step - loss: 0.3792 - accuracy: 0.8155\n",
      "Epoch 146/200\n",
      "305/305 [==============================] - 0s 448us/step - loss: 0.3809 - accuracy: 0.8124\n",
      "Epoch 147/200\n",
      "305/305 [==============================] - 0s 434us/step - loss: 0.3800 - accuracy: 0.8120\n",
      "Epoch 148/200\n",
      "305/305 [==============================] - 0s 428us/step - loss: 0.3774 - accuracy: 0.8137\n",
      "Epoch 149/200\n",
      "305/305 [==============================] - 0s 434us/step - loss: 0.3757 - accuracy: 0.8182\n",
      "Epoch 150/200\n",
      "305/305 [==============================] - 0s 455us/step - loss: 0.3758 - accuracy: 0.8174\n",
      "Epoch 151/200\n",
      "305/305 [==============================] - 0s 427us/step - loss: 0.3775 - accuracy: 0.8180\n",
      "Epoch 152/200\n",
      "305/305 [==============================] - 0s 437us/step - loss: 0.3743 - accuracy: 0.8246\n",
      "Epoch 153/200\n",
      "305/305 [==============================] - 0s 451us/step - loss: 0.3768 - accuracy: 0.8198\n",
      "Epoch 154/200\n",
      "305/305 [==============================] - 0s 438us/step - loss: 0.3854 - accuracy: 0.8073\n",
      "Epoch 155/200\n",
      "305/305 [==============================] - 0s 443us/step - loss: 0.3807 - accuracy: 0.8151\n",
      "Epoch 156/200\n",
      "305/305 [==============================] - 0s 441us/step - loss: 0.3826 - accuracy: 0.8145\n",
      "Epoch 157/200\n",
      "305/305 [==============================] - 0s 427us/step - loss: 0.3785 - accuracy: 0.8161\n",
      "Epoch 158/200\n",
      "305/305 [==============================] - 0s 427us/step - loss: 0.3750 - accuracy: 0.8139\n",
      "Epoch 159/200\n",
      "305/305 [==============================] - 0s 624us/step - loss: 0.3756 - accuracy: 0.8166\n",
      "Epoch 160/200\n",
      "305/305 [==============================] - 0s 435us/step - loss: 0.3767 - accuracy: 0.8161\n",
      "Epoch 161/200\n",
      "305/305 [==============================] - 0s 466us/step - loss: 0.3797 - accuracy: 0.8151\n",
      "Epoch 162/200\n",
      "305/305 [==============================] - 0s 455us/step - loss: 0.3764 - accuracy: 0.8203\n",
      "Epoch 163/200\n",
      "305/305 [==============================] - 0s 435us/step - loss: 0.3797 - accuracy: 0.8192\n",
      "Epoch 164/200\n",
      "305/305 [==============================] - 0s 437us/step - loss: 0.3746 - accuracy: 0.8176\n",
      "Epoch 165/200\n",
      "305/305 [==============================] - 0s 426us/step - loss: 0.3759 - accuracy: 0.8159\n",
      "Epoch 166/200\n",
      "305/305 [==============================] - 0s 419us/step - loss: 0.3770 - accuracy: 0.8170\n",
      "Epoch 167/200\n",
      "305/305 [==============================] - 0s 443us/step - loss: 0.3770 - accuracy: 0.8170\n",
      "Epoch 168/200\n",
      "305/305 [==============================] - 0s 433us/step - loss: 0.3769 - accuracy: 0.8161\n",
      "Epoch 169/200\n",
      "305/305 [==============================] - 0s 454us/step - loss: 0.3790 - accuracy: 0.8164\n",
      "Epoch 170/200\n",
      "305/305 [==============================] - 0s 434us/step - loss: 0.3740 - accuracy: 0.8170\n",
      "Epoch 171/200\n",
      "305/305 [==============================] - 0s 445us/step - loss: 0.3725 - accuracy: 0.8196\n",
      "Epoch 172/200\n",
      "305/305 [==============================] - 0s 443us/step - loss: 0.3774 - accuracy: 0.8137\n",
      "Epoch 173/200\n",
      "305/305 [==============================] - 0s 431us/step - loss: 0.3758 - accuracy: 0.8198\n",
      "Epoch 174/200\n",
      "305/305 [==============================] - 0s 426us/step - loss: 0.3722 - accuracy: 0.8217\n",
      "Epoch 175/200\n",
      "305/305 [==============================] - 0s 455us/step - loss: 0.3814 - accuracy: 0.8178\n",
      "Epoch 176/200\n",
      "305/305 [==============================] - 0s 443us/step - loss: 0.3771 - accuracy: 0.8188\n",
      "Epoch 177/200\n",
      "305/305 [==============================] - 0s 441us/step - loss: 0.3765 - accuracy: 0.8127\n",
      "Epoch 178/200\n",
      "305/305 [==============================] - 0s 700us/step - loss: 0.3722 - accuracy: 0.8192\n",
      "Epoch 179/200\n",
      "305/305 [==============================] - 0s 461us/step - loss: 0.3742 - accuracy: 0.8207\n",
      "Epoch 180/200\n",
      "305/305 [==============================] - 0s 466us/step - loss: 0.3750 - accuracy: 0.8192\n",
      "Epoch 181/200\n",
      "305/305 [==============================] - 0s 449us/step - loss: 0.3752 - accuracy: 0.8180\n",
      "Epoch 182/200\n",
      "305/305 [==============================] - 0s 479us/step - loss: 0.3769 - accuracy: 0.8157\n",
      "Epoch 183/200\n",
      "305/305 [==============================] - 0s 454us/step - loss: 0.3712 - accuracy: 0.8200\n",
      "Epoch 184/200\n",
      "305/305 [==============================] - 0s 445us/step - loss: 0.3758 - accuracy: 0.8190\n",
      "Epoch 185/200\n",
      "305/305 [==============================] - 0s 438us/step - loss: 0.3785 - accuracy: 0.8180\n",
      "Epoch 186/200\n",
      "305/305 [==============================] - 0s 443us/step - loss: 0.3753 - accuracy: 0.8145\n",
      "Epoch 187/200\n",
      "305/305 [==============================] - 0s 440us/step - loss: 0.3748 - accuracy: 0.8205\n",
      "Epoch 188/200\n",
      "305/305 [==============================] - 0s 435us/step - loss: 0.3717 - accuracy: 0.8227\n",
      "Epoch 189/200\n",
      "305/305 [==============================] - 0s 438us/step - loss: 0.3753 - accuracy: 0.8157\n",
      "Epoch 190/200\n",
      "305/305 [==============================] - 0s 507us/step - loss: 0.3729 - accuracy: 0.8207\n",
      "Epoch 191/200\n",
      "305/305 [==============================] - 0s 449us/step - loss: 0.3764 - accuracy: 0.8131\n",
      "Epoch 192/200\n",
      "305/305 [==============================] - 0s 442us/step - loss: 0.3772 - accuracy: 0.8143\n",
      "Epoch 193/200\n",
      "305/305 [==============================] - 0s 448us/step - loss: 0.3754 - accuracy: 0.8205\n",
      "Epoch 194/200\n",
      "305/305 [==============================] - 0s 437us/step - loss: 0.3691 - accuracy: 0.8190\n",
      "Epoch 195/200\n",
      "305/305 [==============================] - 0s 443us/step - loss: 0.3766 - accuracy: 0.8149\n",
      "Epoch 196/200\n",
      "305/305 [==============================] - 0s 438us/step - loss: 0.3695 - accuracy: 0.8182\n",
      "Epoch 197/200\n",
      "305/305 [==============================] - 0s 690us/step - loss: 0.3689 - accuracy: 0.8200\n",
      "Epoch 198/200\n",
      "305/305 [==============================] - 0s 441us/step - loss: 0.3766 - accuracy: 0.8223\n",
      "Epoch 199/200\n",
      "305/305 [==============================] - 0s 441us/step - loss: 0.3765 - accuracy: 0.8211\n",
      "Epoch 200/200\n",
      "305/305 [==============================] - 0s 440us/step - loss: 0.3724 - accuracy: 0.8233\n",
      "39/39 [==============================] - 0s 339us/step\n",
      "Epoch 1/200\n",
      "305/305 [==============================] - 0s 470us/step - loss: 0.5321 - accuracy: 0.7284\n",
      "Epoch 2/200\n",
      "305/305 [==============================] - 0s 441us/step - loss: 0.4405 - accuracy: 0.7868\n",
      "Epoch 3/200\n",
      "305/305 [==============================] - 0s 456us/step - loss: 0.4308 - accuracy: 0.7948\n",
      "Epoch 4/200\n",
      "305/305 [==============================] - 0s 436us/step - loss: 0.4272 - accuracy: 0.7929\n",
      "Epoch 5/200\n",
      "305/305 [==============================] - 0s 439us/step - loss: 0.4262 - accuracy: 0.7938\n",
      "Epoch 6/200\n",
      "305/305 [==============================] - 0s 463us/step - loss: 0.4219 - accuracy: 0.7997\n",
      "Epoch 7/200\n",
      "305/305 [==============================] - 0s 448us/step - loss: 0.4225 - accuracy: 0.7977\n",
      "Epoch 8/200\n",
      "305/305 [==============================] - 0s 457us/step - loss: 0.4200 - accuracy: 0.7987\n",
      "Epoch 9/200\n",
      "305/305 [==============================] - 0s 435us/step - loss: 0.4151 - accuracy: 0.8022\n",
      "Epoch 10/200\n",
      "305/305 [==============================] - 0s 428us/step - loss: 0.4162 - accuracy: 0.8024\n",
      "Epoch 11/200\n",
      "305/305 [==============================] - 0s 435us/step - loss: 0.4125 - accuracy: 0.7993\n",
      "Epoch 12/200\n",
      "305/305 [==============================] - 0s 440us/step - loss: 0.4141 - accuracy: 0.8022\n",
      "Epoch 13/200\n",
      "305/305 [==============================] - 0s 430us/step - loss: 0.4120 - accuracy: 0.8059\n",
      "Epoch 14/200\n",
      "305/305 [==============================] - 0s 436us/step - loss: 0.4144 - accuracy: 0.8022\n",
      "Epoch 15/200\n",
      "305/305 [==============================] - 0s 553us/step - loss: 0.4108 - accuracy: 0.8061\n",
      "Epoch 16/200\n",
      "305/305 [==============================] - 0s 483us/step - loss: 0.4113 - accuracy: 0.8028\n",
      "Epoch 17/200\n",
      "305/305 [==============================] - 0s 463us/step - loss: 0.4112 - accuracy: 0.8048\n",
      "Epoch 18/200\n",
      "305/305 [==============================] - 0s 447us/step - loss: 0.4077 - accuracy: 0.8077\n",
      "Epoch 19/200\n",
      "305/305 [==============================] - 0s 441us/step - loss: 0.4128 - accuracy: 0.8018\n",
      "Epoch 20/200\n",
      "305/305 [==============================] - 0s 431us/step - loss: 0.4115 - accuracy: 0.8073\n",
      "Epoch 21/200\n",
      "305/305 [==============================] - 0s 435us/step - loss: 0.4070 - accuracy: 0.8055\n",
      "Epoch 22/200\n",
      "305/305 [==============================] - 0s 460us/step - loss: 0.4079 - accuracy: 0.8071\n",
      "Epoch 23/200\n",
      "305/305 [==============================] - 0s 438us/step - loss: 0.4063 - accuracy: 0.8071\n",
      "Epoch 24/200\n",
      "305/305 [==============================] - 0s 441us/step - loss: 0.4083 - accuracy: 0.8061\n",
      "Epoch 25/200\n",
      "305/305 [==============================] - 0s 431us/step - loss: 0.4050 - accuracy: 0.8127\n",
      "Epoch 26/200\n",
      "305/305 [==============================] - 0s 429us/step - loss: 0.4051 - accuracy: 0.8081\n",
      "Epoch 27/200\n",
      "305/305 [==============================] - 0s 434us/step - loss: 0.4101 - accuracy: 0.8048\n",
      "Epoch 28/200\n",
      "305/305 [==============================] - 0s 440us/step - loss: 0.4047 - accuracy: 0.8108\n",
      "Epoch 29/200\n",
      "305/305 [==============================] - 0s 446us/step - loss: 0.4011 - accuracy: 0.8104\n",
      "Epoch 30/200\n",
      "305/305 [==============================] - 0s 438us/step - loss: 0.4066 - accuracy: 0.8036\n",
      "Epoch 31/200\n",
      "305/305 [==============================] - 0s 460us/step - loss: 0.3997 - accuracy: 0.8118\n",
      "Epoch 32/200\n",
      "305/305 [==============================] - 0s 452us/step - loss: 0.4016 - accuracy: 0.8090\n",
      "Epoch 33/200\n",
      "305/305 [==============================] - 0s 508us/step - loss: 0.4029 - accuracy: 0.8116\n",
      "Epoch 34/200\n",
      "305/305 [==============================] - 0s 433us/step - loss: 0.4052 - accuracy: 0.8131\n",
      "Epoch 35/200\n",
      "305/305 [==============================] - 0s 431us/step - loss: 0.4011 - accuracy: 0.8108\n",
      "Epoch 36/200\n",
      "305/305 [==============================] - 0s 433us/step - loss: 0.4011 - accuracy: 0.8124\n",
      "Epoch 37/200\n",
      "305/305 [==============================] - 0s 438us/step - loss: 0.3989 - accuracy: 0.8108\n",
      "Epoch 38/200\n",
      "305/305 [==============================] - 0s 445us/step - loss: 0.4002 - accuracy: 0.8131\n",
      "Epoch 39/200\n",
      "305/305 [==============================] - 0s 437us/step - loss: 0.4013 - accuracy: 0.8096\n",
      "Epoch 40/200\n",
      "305/305 [==============================] - 0s 430us/step - loss: 0.3992 - accuracy: 0.8110\n",
      "Epoch 41/200\n",
      "305/305 [==============================] - 0s 437us/step - loss: 0.3975 - accuracy: 0.8164\n",
      "Epoch 42/200\n",
      "305/305 [==============================] - 0s 439us/step - loss: 0.4002 - accuracy: 0.8139\n",
      "Epoch 43/200\n",
      "305/305 [==============================] - 0s 454us/step - loss: 0.4028 - accuracy: 0.8120\n",
      "Epoch 44/200\n",
      "305/305 [==============================] - 0s 452us/step - loss: 0.4013 - accuracy: 0.8127\n",
      "Epoch 45/200\n",
      "305/305 [==============================] - 0s 442us/step - loss: 0.3983 - accuracy: 0.8164\n",
      "Epoch 46/200\n",
      "305/305 [==============================] - 0s 433us/step - loss: 0.4001 - accuracy: 0.8118\n",
      "Epoch 47/200\n",
      "305/305 [==============================] - 0s 431us/step - loss: 0.3971 - accuracy: 0.8127\n",
      "Epoch 48/200\n",
      "305/305 [==============================] - 0s 435us/step - loss: 0.3978 - accuracy: 0.8096\n",
      "Epoch 49/200\n",
      "305/305 [==============================] - 0s 431us/step - loss: 0.3933 - accuracy: 0.8184\n",
      "Epoch 50/200\n",
      "305/305 [==============================] - 0s 579us/step - loss: 0.3946 - accuracy: 0.8131\n",
      "Epoch 51/200\n",
      "305/305 [==============================] - 0s 489us/step - loss: 0.3962 - accuracy: 0.8178\n",
      "Epoch 52/200\n",
      "305/305 [==============================] - 0s 435us/step - loss: 0.3987 - accuracy: 0.8096\n",
      "Epoch 53/200\n",
      "305/305 [==============================] - 0s 435us/step - loss: 0.3959 - accuracy: 0.8131\n",
      "Epoch 54/200\n",
      "305/305 [==============================] - 0s 437us/step - loss: 0.3959 - accuracy: 0.8114\n",
      "Epoch 55/200\n",
      "305/305 [==============================] - 0s 440us/step - loss: 0.3963 - accuracy: 0.8137\n",
      "Epoch 56/200\n",
      "305/305 [==============================] - 0s 443us/step - loss: 0.3987 - accuracy: 0.8073\n",
      "Epoch 57/200\n",
      "305/305 [==============================] - 0s 439us/step - loss: 0.3944 - accuracy: 0.8129\n",
      "Epoch 58/200\n",
      "305/305 [==============================] - 0s 433us/step - loss: 0.3952 - accuracy: 0.8159\n",
      "Epoch 59/200\n",
      "305/305 [==============================] - 0s 439us/step - loss: 0.3981 - accuracy: 0.8157\n",
      "Epoch 60/200\n",
      "305/305 [==============================] - 0s 435us/step - loss: 0.3938 - accuracy: 0.8178\n",
      "Epoch 61/200\n",
      "305/305 [==============================] - 0s 435us/step - loss: 0.3899 - accuracy: 0.8182\n",
      "Epoch 62/200\n",
      "305/305 [==============================] - 0s 448us/step - loss: 0.3950 - accuracy: 0.8129\n",
      "Epoch 63/200\n",
      "305/305 [==============================] - 0s 436us/step - loss: 0.3963 - accuracy: 0.8151\n",
      "Epoch 64/200\n",
      "305/305 [==============================] - 0s 435us/step - loss: 0.3960 - accuracy: 0.8139\n",
      "Epoch 65/200\n",
      "305/305 [==============================] - 0s 430us/step - loss: 0.3945 - accuracy: 0.8157\n",
      "Epoch 66/200\n",
      "305/305 [==============================] - 0s 446us/step - loss: 0.3924 - accuracy: 0.8166\n",
      "Epoch 67/200\n",
      "305/305 [==============================] - 0s 588us/step - loss: 0.3951 - accuracy: 0.8190\n",
      "Epoch 68/200\n",
      "305/305 [==============================] - 0s 489us/step - loss: 0.3998 - accuracy: 0.8137\n",
      "Epoch 69/200\n",
      "305/305 [==============================] - 0s 434us/step - loss: 0.3895 - accuracy: 0.8161\n",
      "Epoch 70/200\n",
      "305/305 [==============================] - 0s 433us/step - loss: 0.3935 - accuracy: 0.8143\n",
      "Epoch 71/200\n",
      "305/305 [==============================] - 0s 438us/step - loss: 0.3947 - accuracy: 0.8127\n",
      "Epoch 72/200\n",
      "305/305 [==============================] - 0s 437us/step - loss: 0.3928 - accuracy: 0.8133\n",
      "Epoch 73/200\n",
      "305/305 [==============================] - 0s 438us/step - loss: 0.3938 - accuracy: 0.8129\n",
      "Epoch 74/200\n",
      "305/305 [==============================] - 0s 444us/step - loss: 0.3897 - accuracy: 0.8168\n",
      "Epoch 75/200\n",
      "305/305 [==============================] - 0s 472us/step - loss: 0.3901 - accuracy: 0.8203\n",
      "Epoch 76/200\n",
      "305/305 [==============================] - 0s 534us/step - loss: 0.3920 - accuracy: 0.8155\n",
      "Epoch 77/200\n",
      "305/305 [==============================] - 0s 479us/step - loss: 0.3931 - accuracy: 0.8164\n",
      "Epoch 78/200\n",
      "305/305 [==============================] - 0s 476us/step - loss: 0.3927 - accuracy: 0.8135\n",
      "Epoch 79/200\n",
      "305/305 [==============================] - 0s 455us/step - loss: 0.3940 - accuracy: 0.8151\n",
      "Epoch 80/200\n",
      "305/305 [==============================] - 0s 448us/step - loss: 0.3897 - accuracy: 0.8172\n",
      "Epoch 81/200\n",
      "305/305 [==============================] - 0s 450us/step - loss: 0.3844 - accuracy: 0.8231\n",
      "Epoch 82/200\n",
      "305/305 [==============================] - 0s 444us/step - loss: 0.3921 - accuracy: 0.8168\n",
      "Epoch 83/200\n",
      "305/305 [==============================] - 0s 440us/step - loss: 0.3897 - accuracy: 0.8207\n",
      "Epoch 84/200\n",
      "305/305 [==============================] - 0s 630us/step - loss: 0.3956 - accuracy: 0.8116\n",
      "Epoch 85/200\n",
      "305/305 [==============================] - 0s 474us/step - loss: 0.3930 - accuracy: 0.8168\n",
      "Epoch 86/200\n",
      "305/305 [==============================] - 0s 493us/step - loss: 0.3896 - accuracy: 0.8186\n",
      "Epoch 87/200\n",
      "305/305 [==============================] - 0s 464us/step - loss: 0.3896 - accuracy: 0.8141\n",
      "Epoch 88/200\n",
      "305/305 [==============================] - 0s 456us/step - loss: 0.3915 - accuracy: 0.8161\n",
      "Epoch 89/200\n",
      "305/305 [==============================] - 0s 439us/step - loss: 0.3875 - accuracy: 0.8186\n",
      "Epoch 90/200\n",
      "305/305 [==============================] - 0s 449us/step - loss: 0.3895 - accuracy: 0.8217\n",
      "Epoch 91/200\n",
      "305/305 [==============================] - 0s 439us/step - loss: 0.3927 - accuracy: 0.8155\n",
      "Epoch 92/200\n",
      "305/305 [==============================] - 0s 447us/step - loss: 0.3891 - accuracy: 0.8166\n",
      "Epoch 93/200\n",
      "305/305 [==============================] - 0s 444us/step - loss: 0.3882 - accuracy: 0.8186\n",
      "Epoch 94/200\n",
      "305/305 [==============================] - 0s 467us/step - loss: 0.3960 - accuracy: 0.8172\n",
      "Epoch 95/200\n",
      "305/305 [==============================] - 0s 460us/step - loss: 0.3914 - accuracy: 0.8153\n",
      "Epoch 96/200\n",
      "305/305 [==============================] - 0s 441us/step - loss: 0.3887 - accuracy: 0.8186\n",
      "Epoch 97/200\n",
      "305/305 [==============================] - 0s 449us/step - loss: 0.3890 - accuracy: 0.8205\n",
      "Epoch 98/200\n",
      "305/305 [==============================] - 0s 450us/step - loss: 0.3953 - accuracy: 0.8137\n",
      "Epoch 99/200\n",
      "305/305 [==============================] - 0s 454us/step - loss: 0.3907 - accuracy: 0.8147\n",
      "Epoch 100/200\n",
      "305/305 [==============================] - 0s 452us/step - loss: 0.3888 - accuracy: 0.8182\n",
      "Epoch 101/200\n",
      "305/305 [==============================] - 0s 436us/step - loss: 0.3904 - accuracy: 0.8176\n",
      "Epoch 102/200\n",
      "305/305 [==============================] - 0s 694us/step - loss: 0.3933 - accuracy: 0.8129\n",
      "Epoch 103/200\n",
      "305/305 [==============================] - 0s 448us/step - loss: 0.3875 - accuracy: 0.8192\n",
      "Epoch 104/200\n",
      "305/305 [==============================] - 0s 494us/step - loss: 0.3900 - accuracy: 0.8159\n",
      "Epoch 105/200\n",
      "305/305 [==============================] - 0s 444us/step - loss: 0.3883 - accuracy: 0.8153\n",
      "Epoch 106/200\n",
      "305/305 [==============================] - 0s 437us/step - loss: 0.3877 - accuracy: 0.8192\n",
      "Epoch 107/200\n",
      "305/305 [==============================] - 0s 434us/step - loss: 0.3884 - accuracy: 0.8219\n",
      "Epoch 108/200\n",
      "305/305 [==============================] - 0s 477us/step - loss: 0.3882 - accuracy: 0.8139\n",
      "Epoch 109/200\n",
      "305/305 [==============================] - 0s 443us/step - loss: 0.3875 - accuracy: 0.8151\n",
      "Epoch 110/200\n",
      "305/305 [==============================] - 0s 434us/step - loss: 0.3890 - accuracy: 0.8104\n",
      "Epoch 111/200\n",
      "305/305 [==============================] - 0s 449us/step - loss: 0.3870 - accuracy: 0.8186\n",
      "Epoch 112/200\n",
      "305/305 [==============================] - 0s 448us/step - loss: 0.3889 - accuracy: 0.8127\n",
      "Epoch 113/200\n",
      "305/305 [==============================] - 0s 438us/step - loss: 0.3906 - accuracy: 0.8133\n",
      "Epoch 114/200\n",
      "305/305 [==============================] - 0s 440us/step - loss: 0.3882 - accuracy: 0.8182\n",
      "Epoch 115/200\n",
      "305/305 [==============================] - 0s 445us/step - loss: 0.3854 - accuracy: 0.8147\n",
      "Epoch 116/200\n",
      "305/305 [==============================] - 0s 451us/step - loss: 0.3884 - accuracy: 0.8164\n",
      "Epoch 117/200\n",
      "305/305 [==============================] - 0s 431us/step - loss: 0.3899 - accuracy: 0.8141\n",
      "Epoch 118/200\n",
      "305/305 [==============================] - 0s 433us/step - loss: 0.3905 - accuracy: 0.8180\n",
      "Epoch 119/200\n",
      "305/305 [==============================] - 0s 608us/step - loss: 0.3909 - accuracy: 0.8164\n",
      "Epoch 120/200\n",
      "305/305 [==============================] - 0s 439us/step - loss: 0.3886 - accuracy: 0.8164\n",
      "Epoch 121/200\n",
      "305/305 [==============================] - 0s 484us/step - loss: 0.3850 - accuracy: 0.8190\n",
      "Epoch 122/200\n",
      "305/305 [==============================] - 0s 434us/step - loss: 0.3896 - accuracy: 0.8149\n",
      "Epoch 123/200\n",
      "305/305 [==============================] - 0s 436us/step - loss: 0.3898 - accuracy: 0.8135\n",
      "Epoch 124/200\n",
      "305/305 [==============================] - 0s 427us/step - loss: 0.3878 - accuracy: 0.8200\n",
      "Epoch 125/200\n",
      "305/305 [==============================] - 0s 438us/step - loss: 0.3870 - accuracy: 0.8166\n",
      "Epoch 126/200\n",
      "305/305 [==============================] - 0s 433us/step - loss: 0.3873 - accuracy: 0.8215\n",
      "Epoch 127/200\n",
      "305/305 [==============================] - 0s 428us/step - loss: 0.3903 - accuracy: 0.8194\n",
      "Epoch 128/200\n",
      "305/305 [==============================] - 0s 427us/step - loss: 0.3882 - accuracy: 0.8149\n",
      "Epoch 129/200\n",
      "305/305 [==============================] - 0s 438us/step - loss: 0.3851 - accuracy: 0.8209\n",
      "Epoch 130/200\n",
      "305/305 [==============================] - 0s 433us/step - loss: 0.3829 - accuracy: 0.8207\n",
      "Epoch 131/200\n",
      "305/305 [==============================] - 0s 741us/step - loss: 0.3843 - accuracy: 0.8233\n",
      "Epoch 132/200\n",
      "305/305 [==============================] - 0s 2ms/step - loss: 0.3919 - accuracy: 0.8196\n",
      "Epoch 133/200\n",
      "305/305 [==============================] - 0s 516us/step - loss: 0.3831 - accuracy: 0.8244\n",
      "Epoch 134/200\n",
      "305/305 [==============================] - 0s 456us/step - loss: 0.3866 - accuracy: 0.8213\n",
      "Epoch 135/200\n",
      "305/305 [==============================] - 0s 741us/step - loss: 0.3865 - accuracy: 0.8209\n",
      "Epoch 136/200\n",
      "305/305 [==============================] - 0s 464us/step - loss: 0.3883 - accuracy: 0.8172\n",
      "Epoch 137/200\n",
      "305/305 [==============================] - 0s 432us/step - loss: 0.3824 - accuracy: 0.8205\n",
      "Epoch 138/200\n",
      "305/305 [==============================] - 0s 409us/step - loss: 0.3875 - accuracy: 0.8229\n",
      "Epoch 139/200\n",
      "305/305 [==============================] - 0s 412us/step - loss: 0.3880 - accuracy: 0.8178\n",
      "Epoch 140/200\n",
      "305/305 [==============================] - 0s 415us/step - loss: 0.3831 - accuracy: 0.8227\n",
      "Epoch 141/200\n",
      "305/305 [==============================] - 0s 412us/step - loss: 0.3870 - accuracy: 0.8172\n",
      "Epoch 142/200\n",
      "305/305 [==============================] - 0s 417us/step - loss: 0.3873 - accuracy: 0.8229\n",
      "Epoch 143/200\n",
      "305/305 [==============================] - 0s 411us/step - loss: 0.3862 - accuracy: 0.8200\n",
      "Epoch 144/200\n",
      "305/305 [==============================] - 0s 406us/step - loss: 0.3868 - accuracy: 0.8203\n",
      "Epoch 145/200\n",
      "305/305 [==============================] - 0s 413us/step - loss: 0.3915 - accuracy: 0.8110\n",
      "Epoch 146/200\n",
      "305/305 [==============================] - 0s 416us/step - loss: 0.3853 - accuracy: 0.8186\n",
      "Epoch 147/200\n",
      "305/305 [==============================] - 0s 408us/step - loss: 0.3851 - accuracy: 0.8254\n",
      "Epoch 148/200\n",
      "305/305 [==============================] - 0s 413us/step - loss: 0.3851 - accuracy: 0.8225\n",
      "Epoch 149/200\n",
      "305/305 [==============================] - 0s 406us/step - loss: 0.3837 - accuracy: 0.8215\n",
      "Epoch 150/200\n",
      "305/305 [==============================] - 0s 408us/step - loss: 0.3855 - accuracy: 0.8211\n",
      "Epoch 151/200\n",
      "305/305 [==============================] - 0s 409us/step - loss: 0.3838 - accuracy: 0.8211\n",
      "Epoch 152/200\n",
      "305/305 [==============================] - 0s 415us/step - loss: 0.3886 - accuracy: 0.8164\n",
      "Epoch 153/200\n",
      "305/305 [==============================] - 0s 406us/step - loss: 0.3820 - accuracy: 0.8246\n",
      "Epoch 154/200\n",
      "305/305 [==============================] - 0s 409us/step - loss: 0.3857 - accuracy: 0.8209\n",
      "Epoch 155/200\n",
      "305/305 [==============================] - 0s 410us/step - loss: 0.3872 - accuracy: 0.8161\n",
      "Epoch 156/200\n",
      "305/305 [==============================] - 0s 587us/step - loss: 0.3860 - accuracy: 0.8198\n",
      "Epoch 157/200\n",
      "305/305 [==============================] - 0s 407us/step - loss: 0.3842 - accuracy: 0.8223\n",
      "Epoch 158/200\n",
      "305/305 [==============================] - 0s 407us/step - loss: 0.3843 - accuracy: 0.8200\n",
      "Epoch 159/200\n",
      "305/305 [==============================] - 0s 436us/step - loss: 0.3872 - accuracy: 0.8190\n",
      "Epoch 160/200\n",
      "305/305 [==============================] - 0s 466us/step - loss: 0.3837 - accuracy: 0.8248\n",
      "Epoch 161/200\n",
      "305/305 [==============================] - 0s 407us/step - loss: 0.3838 - accuracy: 0.8217\n",
      "Epoch 162/200\n",
      "305/305 [==============================] - 0s 403us/step - loss: 0.3890 - accuracy: 0.8194\n",
      "Epoch 163/200\n",
      "305/305 [==============================] - 0s 401us/step - loss: 0.3907 - accuracy: 0.8184\n",
      "Epoch 164/200\n",
      "305/305 [==============================] - 0s 403us/step - loss: 0.3854 - accuracy: 0.8219\n",
      "Epoch 165/200\n",
      "305/305 [==============================] - 0s 407us/step - loss: 0.3840 - accuracy: 0.8215\n",
      "Epoch 166/200\n",
      "305/305 [==============================] - 0s 406us/step - loss: 0.3867 - accuracy: 0.8184\n",
      "Epoch 167/200\n",
      "305/305 [==============================] - 0s 403us/step - loss: 0.3840 - accuracy: 0.8235\n",
      "Epoch 168/200\n",
      "305/305 [==============================] - 0s 412us/step - loss: 0.3838 - accuracy: 0.8237\n",
      "Epoch 169/200\n",
      "305/305 [==============================] - 0s 409us/step - loss: 0.3885 - accuracy: 0.8166\n",
      "Epoch 170/200\n",
      "305/305 [==============================] - 0s 587us/step - loss: 0.3870 - accuracy: 0.8174\n",
      "Epoch 171/200\n",
      "305/305 [==============================] - 0s 412us/step - loss: 0.3844 - accuracy: 0.8178\n",
      "Epoch 172/200\n",
      "305/305 [==============================] - 0s 416us/step - loss: 0.3779 - accuracy: 0.8237\n",
      "Epoch 173/200\n",
      "305/305 [==============================] - 0s 405us/step - loss: 0.3809 - accuracy: 0.8258\n",
      "Epoch 174/200\n",
      "305/305 [==============================] - 0s 408us/step - loss: 0.3884 - accuracy: 0.8153\n",
      "Epoch 175/200\n",
      "305/305 [==============================] - 0s 408us/step - loss: 0.3861 - accuracy: 0.8211\n",
      "Epoch 176/200\n",
      "305/305 [==============================] - 0s 406us/step - loss: 0.3885 - accuracy: 0.8180\n",
      "Epoch 177/200\n",
      "305/305 [==============================] - 0s 407us/step - loss: 0.3877 - accuracy: 0.8170\n",
      "Epoch 178/200\n",
      "305/305 [==============================] - 0s 406us/step - loss: 0.3818 - accuracy: 0.8205\n",
      "Epoch 179/200\n",
      "305/305 [==============================] - 0s 397us/step - loss: 0.3812 - accuracy: 0.8252\n",
      "Epoch 180/200\n",
      "305/305 [==============================] - 0s 406us/step - loss: 0.3844 - accuracy: 0.8147\n",
      "Epoch 181/200\n",
      "305/305 [==============================] - 0s 409us/step - loss: 0.3854 - accuracy: 0.8211\n",
      "Epoch 182/200\n",
      "305/305 [==============================] - 0s 407us/step - loss: 0.3792 - accuracy: 0.8233\n",
      "Epoch 183/200\n",
      "305/305 [==============================] - 0s 412us/step - loss: 0.3905 - accuracy: 0.8209\n",
      "Epoch 184/200\n",
      "305/305 [==============================] - 0s 581us/step - loss: 0.3828 - accuracy: 0.8215\n",
      "Epoch 185/200\n",
      "305/305 [==============================] - 0s 419us/step - loss: 0.3811 - accuracy: 0.8235\n",
      "Epoch 186/200\n",
      "305/305 [==============================] - 0s 1ms/step - loss: 0.3824 - accuracy: 0.8240\n",
      "Epoch 187/200\n",
      "305/305 [==============================] - 0s 817us/step - loss: 0.3853 - accuracy: 0.8155\n",
      "Epoch 188/200\n",
      "305/305 [==============================] - 0s 617us/step - loss: 0.3824 - accuracy: 0.8207\n",
      "Epoch 189/200\n",
      "305/305 [==============================] - 0s 466us/step - loss: 0.3843 - accuracy: 0.8203\n",
      "Epoch 190/200\n",
      "305/305 [==============================] - 0s 453us/step - loss: 0.3818 - accuracy: 0.8268\n",
      "Epoch 191/200\n",
      "305/305 [==============================] - 0s 472us/step - loss: 0.3827 - accuracy: 0.8211\n",
      "Epoch 192/200\n",
      "305/305 [==============================] - 0s 439us/step - loss: 0.3837 - accuracy: 0.8211\n",
      "Epoch 193/200\n",
      "305/305 [==============================] - 0s 447us/step - loss: 0.3859 - accuracy: 0.8225\n",
      "Epoch 194/200\n",
      "305/305 [==============================] - 0s 697us/step - loss: 0.3817 - accuracy: 0.8215\n",
      "Epoch 195/200\n",
      "305/305 [==============================] - 0s 460us/step - loss: 0.3867 - accuracy: 0.8151\n",
      "Epoch 196/200\n",
      "305/305 [==============================] - 0s 494us/step - loss: 0.3839 - accuracy: 0.8198\n",
      "Epoch 197/200\n",
      "305/305 [==============================] - 0s 438us/step - loss: 0.3785 - accuracy: 0.8233\n",
      "Epoch 198/200\n",
      "305/305 [==============================] - 0s 450us/step - loss: 0.3796 - accuracy: 0.8264\n",
      "Epoch 199/200\n",
      "305/305 [==============================] - 0s 436us/step - loss: 0.3839 - accuracy: 0.8229\n",
      "Epoch 200/200\n",
      "305/305 [==============================] - 0s 435us/step - loss: 0.3864 - accuracy: 0.8182\n",
      "39/39 [==============================] - 0s 394us/step\n",
      "Epoch 1/200\n",
      "305/305 [==============================] - 1s 441us/step - loss: 0.5336 - accuracy: 0.7352\n",
      "Epoch 2/200\n",
      "305/305 [==============================] - 0s 443us/step - loss: 0.4399 - accuracy: 0.7894\n",
      "Epoch 3/200\n",
      "305/305 [==============================] - 0s 446us/step - loss: 0.4373 - accuracy: 0.7911\n",
      "Epoch 4/200\n",
      "305/305 [==============================] - 0s 447us/step - loss: 0.4297 - accuracy: 0.7925\n",
      "Epoch 5/200\n",
      "305/305 [==============================] - 0s 439us/step - loss: 0.4298 - accuracy: 0.7948\n",
      "Epoch 6/200\n",
      "305/305 [==============================] - 0s 514us/step - loss: 0.4241 - accuracy: 0.7970\n",
      "Epoch 7/200\n",
      "305/305 [==============================] - 0s 563us/step - loss: 0.4198 - accuracy: 0.7964\n",
      "Epoch 8/200\n",
      "305/305 [==============================] - 0s 452us/step - loss: 0.4222 - accuracy: 0.7931\n",
      "Epoch 9/200\n",
      "305/305 [==============================] - 0s 442us/step - loss: 0.4216 - accuracy: 0.7983\n",
      "Epoch 10/200\n",
      "305/305 [==============================] - 0s 445us/step - loss: 0.4174 - accuracy: 0.8034\n",
      "Epoch 11/200\n",
      "305/305 [==============================] - 0s 454us/step - loss: 0.4176 - accuracy: 0.8009\n",
      "Epoch 12/200\n",
      "305/305 [==============================] - 0s 471us/step - loss: 0.4187 - accuracy: 0.7997\n",
      "Epoch 13/200\n",
      "305/305 [==============================] - 0s 426us/step - loss: 0.4163 - accuracy: 0.8036\n",
      "Epoch 14/200\n",
      "305/305 [==============================] - 0s 434us/step - loss: 0.4149 - accuracy: 0.7975\n",
      "Epoch 15/200\n",
      "305/305 [==============================] - 0s 441us/step - loss: 0.4161 - accuracy: 0.7993\n",
      "Epoch 16/200\n",
      "305/305 [==============================] - 0s 434us/step - loss: 0.4102 - accuracy: 0.8067\n",
      "Epoch 17/200\n",
      "305/305 [==============================] - 0s 429us/step - loss: 0.4124 - accuracy: 0.8057\n",
      "Epoch 18/200\n",
      "305/305 [==============================] - 0s 437us/step - loss: 0.4122 - accuracy: 0.7993\n",
      "Epoch 19/200\n",
      "305/305 [==============================] - 0s 456us/step - loss: 0.4117 - accuracy: 0.8036\n",
      "Epoch 20/200\n",
      "305/305 [==============================] - 0s 433us/step - loss: 0.4061 - accuracy: 0.8038\n",
      "Epoch 21/200\n",
      "305/305 [==============================] - 0s 717us/step - loss: 0.4080 - accuracy: 0.8022\n",
      "Epoch 22/200\n",
      "305/305 [==============================] - 0s 468us/step - loss: 0.4081 - accuracy: 0.8034\n",
      "Epoch 23/200\n",
      "305/305 [==============================] - 0s 452us/step - loss: 0.4068 - accuracy: 0.8020\n",
      "Epoch 24/200\n",
      "305/305 [==============================] - 0s 438us/step - loss: 0.4081 - accuracy: 0.8059\n",
      "Epoch 25/200\n",
      "305/305 [==============================] - 0s 438us/step - loss: 0.4042 - accuracy: 0.8051\n",
      "Epoch 26/200\n",
      "305/305 [==============================] - 0s 441us/step - loss: 0.4100 - accuracy: 0.7997\n",
      "Epoch 27/200\n",
      "305/305 [==============================] - 0s 435us/step - loss: 0.4076 - accuracy: 0.8003\n",
      "Epoch 28/200\n",
      "305/305 [==============================] - 0s 430us/step - loss: 0.4077 - accuracy: 0.8040\n",
      "Epoch 29/200\n",
      "305/305 [==============================] - 0s 439us/step - loss: 0.4051 - accuracy: 0.8046\n",
      "Epoch 30/200\n",
      "305/305 [==============================] - 0s 431us/step - loss: 0.4045 - accuracy: 0.8065\n",
      "Epoch 31/200\n",
      "305/305 [==============================] - 0s 433us/step - loss: 0.4047 - accuracy: 0.8083\n",
      "Epoch 32/200\n",
      "305/305 [==============================] - 0s 429us/step - loss: 0.4051 - accuracy: 0.8036\n",
      "Epoch 33/200\n",
      "305/305 [==============================] - 0s 437us/step - loss: 0.4021 - accuracy: 0.8067\n",
      "Epoch 34/200\n",
      "305/305 [==============================] - 0s 429us/step - loss: 0.4059 - accuracy: 0.8020\n",
      "Epoch 35/200\n",
      "305/305 [==============================] - 0s 435us/step - loss: 0.4018 - accuracy: 0.8085\n",
      "Epoch 36/200\n",
      "305/305 [==============================] - 0s 428us/step - loss: 0.3991 - accuracy: 0.8149\n",
      "Epoch 37/200\n",
      "305/305 [==============================] - 0s 429us/step - loss: 0.3943 - accuracy: 0.8141\n",
      "Epoch 38/200\n",
      "305/305 [==============================] - 0s 428us/step - loss: 0.4032 - accuracy: 0.8075\n",
      "Epoch 39/200\n",
      "305/305 [==============================] - 0s 425us/step - loss: 0.3982 - accuracy: 0.8112\n",
      "Epoch 40/200\n",
      "305/305 [==============================] - 0s 441us/step - loss: 0.4015 - accuracy: 0.8061\n",
      "Epoch 41/200\n",
      "305/305 [==============================] - 0s 563us/step - loss: 0.3984 - accuracy: 0.8065\n",
      "Epoch 42/200\n",
      "305/305 [==============================] - 0s 494us/step - loss: 0.4009 - accuracy: 0.8075\n",
      "Epoch 43/200\n",
      "305/305 [==============================] - 0s 428us/step - loss: 0.3950 - accuracy: 0.8159\n",
      "Epoch 44/200\n",
      "305/305 [==============================] - 0s 428us/step - loss: 0.3978 - accuracy: 0.8141\n",
      "Epoch 45/200\n",
      "305/305 [==============================] - 0s 421us/step - loss: 0.3992 - accuracy: 0.8059\n",
      "Epoch 46/200\n",
      "305/305 [==============================] - 0s 423us/step - loss: 0.3973 - accuracy: 0.8098\n",
      "Epoch 47/200\n",
      "305/305 [==============================] - 0s 431us/step - loss: 0.3980 - accuracy: 0.8092\n",
      "Epoch 48/200\n",
      "305/305 [==============================] - 0s 436us/step - loss: 0.3987 - accuracy: 0.8090\n",
      "Epoch 49/200\n",
      "305/305 [==============================] - 0s 428us/step - loss: 0.3940 - accuracy: 0.8141\n",
      "Epoch 50/200\n",
      "305/305 [==============================] - 0s 433us/step - loss: 0.3956 - accuracy: 0.8085\n",
      "Epoch 51/200\n",
      "305/305 [==============================] - 0s 435us/step - loss: 0.3953 - accuracy: 0.8122\n",
      "Epoch 52/200\n",
      "305/305 [==============================] - 0s 430us/step - loss: 0.3979 - accuracy: 0.8137\n",
      "Epoch 53/200\n",
      "305/305 [==============================] - 0s 433us/step - loss: 0.3918 - accuracy: 0.8143\n",
      "Epoch 54/200\n",
      "305/305 [==============================] - 0s 428us/step - loss: 0.3927 - accuracy: 0.8137\n",
      "Epoch 55/200\n",
      "305/305 [==============================] - 0s 427us/step - loss: 0.3995 - accuracy: 0.8057\n",
      "Epoch 56/200\n",
      "305/305 [==============================] - 0s 573us/step - loss: 0.3945 - accuracy: 0.8141\n",
      "Epoch 57/200\n",
      "305/305 [==============================] - 0s 488us/step - loss: 0.3962 - accuracy: 0.8112\n",
      "Epoch 58/200\n",
      "305/305 [==============================] - 0s 439us/step - loss: 0.3969 - accuracy: 0.8061\n",
      "Epoch 59/200\n",
      "305/305 [==============================] - 0s 435us/step - loss: 0.3942 - accuracy: 0.8018\n",
      "Epoch 60/200\n",
      "305/305 [==============================] - 0s 431us/step - loss: 0.3946 - accuracy: 0.8122\n",
      "Epoch 61/200\n",
      "305/305 [==============================] - 0s 436us/step - loss: 0.3896 - accuracy: 0.8151\n",
      "Epoch 62/200\n",
      "305/305 [==============================] - 0s 450us/step - loss: 0.3927 - accuracy: 0.8198\n",
      "Epoch 63/200\n",
      "305/305 [==============================] - 0s 433us/step - loss: 0.3973 - accuracy: 0.8141\n",
      "Epoch 64/200\n",
      "305/305 [==============================] - 0s 446us/step - loss: 0.3952 - accuracy: 0.8096\n",
      "Epoch 65/200\n",
      "305/305 [==============================] - 0s 436us/step - loss: 0.3951 - accuracy: 0.8075\n",
      "Epoch 66/200\n",
      "305/305 [==============================] - 0s 438us/step - loss: 0.3938 - accuracy: 0.8094\n",
      "Epoch 67/200\n",
      "305/305 [==============================] - 0s 435us/step - loss: 0.3963 - accuracy: 0.8090\n",
      "Epoch 68/200\n",
      "305/305 [==============================] - 0s 429us/step - loss: 0.3922 - accuracy: 0.8079\n",
      "Epoch 69/200\n",
      "305/305 [==============================] - 0s 438us/step - loss: 0.3952 - accuracy: 0.8090\n",
      "Epoch 70/200\n",
      "305/305 [==============================] - 0s 451us/step - loss: 0.3886 - accuracy: 0.8172\n",
      "Epoch 71/200\n",
      "305/305 [==============================] - 0s 434us/step - loss: 0.3968 - accuracy: 0.8044\n",
      "Epoch 72/200\n",
      "305/305 [==============================] - 0s 588us/step - loss: 0.3928 - accuracy: 0.8135\n",
      "Epoch 73/200\n",
      "305/305 [==============================] - 0s 463us/step - loss: 0.3957 - accuracy: 0.8102\n",
      "Epoch 74/200\n",
      "305/305 [==============================] - 0s 480us/step - loss: 0.3944 - accuracy: 0.8110\n",
      "Epoch 75/200\n",
      "305/305 [==============================] - 0s 425us/step - loss: 0.3924 - accuracy: 0.8143\n",
      "Epoch 76/200\n",
      "305/305 [==============================] - 0s 421us/step - loss: 0.3924 - accuracy: 0.8141\n",
      "Epoch 77/200\n",
      "305/305 [==============================] - 0s 427us/step - loss: 0.3941 - accuracy: 0.8073\n",
      "Epoch 78/200\n",
      "305/305 [==============================] - 0s 433us/step - loss: 0.3917 - accuracy: 0.8157\n",
      "Epoch 79/200\n",
      "305/305 [==============================] - 0s 429us/step - loss: 0.3938 - accuracy: 0.8092\n",
      "Epoch 80/200\n",
      "305/305 [==============================] - 0s 426us/step - loss: 0.3952 - accuracy: 0.8094\n",
      "Epoch 81/200\n",
      "305/305 [==============================] - 0s 440us/step - loss: 0.3931 - accuracy: 0.8112\n",
      "Epoch 82/200\n",
      "305/305 [==============================] - 0s 439us/step - loss: 0.3901 - accuracy: 0.8159\n",
      "Epoch 83/200\n",
      "305/305 [==============================] - 0s 439us/step - loss: 0.3920 - accuracy: 0.8149\n",
      "Epoch 84/200\n",
      "305/305 [==============================] - 0s 446us/step - loss: 0.3894 - accuracy: 0.8157\n",
      "Epoch 85/200\n",
      "305/305 [==============================] - 0s 443us/step - loss: 0.3883 - accuracy: 0.8149\n",
      "Epoch 86/200\n",
      "305/305 [==============================] - 0s 438us/step - loss: 0.3905 - accuracy: 0.8159\n",
      "Epoch 87/200\n",
      "305/305 [==============================] - 0s 569us/step - loss: 0.3906 - accuracy: 0.8143\n",
      "Epoch 88/200\n",
      "305/305 [==============================] - 0s 460us/step - loss: 0.3919 - accuracy: 0.8129\n",
      "Epoch 89/200\n",
      "305/305 [==============================] - 0s 437us/step - loss: 0.3900 - accuracy: 0.8118\n",
      "Epoch 90/200\n",
      "305/305 [==============================] - 0s 485us/step - loss: 0.3863 - accuracy: 0.8155\n",
      "Epoch 91/200\n",
      "305/305 [==============================] - 0s 430us/step - loss: 0.3853 - accuracy: 0.8151\n",
      "Epoch 92/200\n",
      "305/305 [==============================] - 0s 427us/step - loss: 0.3928 - accuracy: 0.8137\n",
      "Epoch 93/200\n",
      "305/305 [==============================] - 0s 424us/step - loss: 0.3860 - accuracy: 0.8174\n",
      "Epoch 94/200\n",
      "305/305 [==============================] - 0s 434us/step - loss: 0.3918 - accuracy: 0.8188\n",
      "Epoch 95/200\n",
      "305/305 [==============================] - 0s 442us/step - loss: 0.3872 - accuracy: 0.8131\n",
      "Epoch 96/200\n",
      "305/305 [==============================] - 0s 440us/step - loss: 0.3879 - accuracy: 0.8168\n",
      "Epoch 97/200\n",
      "305/305 [==============================] - 0s 436us/step - loss: 0.3850 - accuracy: 0.8209\n",
      "Epoch 98/200\n",
      "305/305 [==============================] - 0s 441us/step - loss: 0.3887 - accuracy: 0.8155\n",
      "Epoch 99/200\n",
      "305/305 [==============================] - 0s 443us/step - loss: 0.3917 - accuracy: 0.8164\n",
      "Epoch 100/200\n",
      "305/305 [==============================] - 0s 433us/step - loss: 0.3929 - accuracy: 0.8092\n",
      "Epoch 101/200\n",
      "305/305 [==============================] - 0s 424us/step - loss: 0.3899 - accuracy: 0.8131\n",
      "Epoch 102/200\n",
      "305/305 [==============================] - 0s 558us/step - loss: 0.3925 - accuracy: 0.8100\n",
      "Epoch 103/200\n",
      "305/305 [==============================] - 0s 436us/step - loss: 0.3946 - accuracy: 0.8046\n",
      "Epoch 104/200\n",
      "305/305 [==============================] - 0s 486us/step - loss: 0.3915 - accuracy: 0.8137\n",
      "Epoch 105/200\n",
      "305/305 [==============================] - 0s 458us/step - loss: 0.3890 - accuracy: 0.8139\n",
      "Epoch 106/200\n",
      "305/305 [==============================] - 0s 466us/step - loss: 0.3914 - accuracy: 0.8135\n",
      "Epoch 107/200\n",
      "305/305 [==============================] - 0s 438us/step - loss: 0.3899 - accuracy: 0.8147\n",
      "Epoch 108/200\n",
      "305/305 [==============================] - 0s 440us/step - loss: 0.3928 - accuracy: 0.8135\n",
      "Epoch 109/200\n",
      "305/305 [==============================] - 0s 437us/step - loss: 0.3823 - accuracy: 0.8231\n",
      "Epoch 110/200\n",
      "305/305 [==============================] - 0s 431us/step - loss: 0.3885 - accuracy: 0.8147\n",
      "Epoch 111/200\n",
      "305/305 [==============================] - 0s 429us/step - loss: 0.3875 - accuracy: 0.8112\n",
      "Epoch 112/200\n",
      "305/305 [==============================] - 0s 433us/step - loss: 0.3827 - accuracy: 0.8174\n",
      "Epoch 113/200\n",
      "305/305 [==============================] - 0s 433us/step - loss: 0.3870 - accuracy: 0.8131\n",
      "Epoch 114/200\n",
      "305/305 [==============================] - 0s 438us/step - loss: 0.3875 - accuracy: 0.8120\n",
      "Epoch 115/200\n",
      "305/305 [==============================] - 0s 432us/step - loss: 0.3849 - accuracy: 0.8184\n",
      "Epoch 116/200\n",
      "305/305 [==============================] - 0s 434us/step - loss: 0.3866 - accuracy: 0.8135\n",
      "Epoch 117/200\n",
      "305/305 [==============================] - 0s 581us/step - loss: 0.3913 - accuracy: 0.8147\n",
      "Epoch 118/200\n",
      "305/305 [==============================] - 0s 441us/step - loss: 0.3907 - accuracy: 0.8090\n",
      "Epoch 119/200\n",
      "305/305 [==============================] - 0s 478us/step - loss: 0.3832 - accuracy: 0.8192\n",
      "Epoch 120/200\n",
      "305/305 [==============================] - 0s 430us/step - loss: 0.3853 - accuracy: 0.8157\n",
      "Epoch 121/200\n",
      "305/305 [==============================] - 0s 430us/step - loss: 0.3878 - accuracy: 0.8155\n",
      "Epoch 122/200\n",
      "305/305 [==============================] - 0s 426us/step - loss: 0.3901 - accuracy: 0.8120\n",
      "Epoch 123/200\n",
      "305/305 [==============================] - 0s 430us/step - loss: 0.3889 - accuracy: 0.8063\n",
      "Epoch 124/200\n",
      "305/305 [==============================] - 0s 428us/step - loss: 0.3828 - accuracy: 0.8200\n",
      "Epoch 125/200\n",
      "305/305 [==============================] - 0s 431us/step - loss: 0.3894 - accuracy: 0.8155\n",
      "Epoch 126/200\n",
      "305/305 [==============================] - 0s 435us/step - loss: 0.3834 - accuracy: 0.8223\n",
      "Epoch 127/200\n",
      "305/305 [==============================] - 0s 438us/step - loss: 0.3832 - accuracy: 0.8209\n",
      "Epoch 128/200\n",
      "305/305 [==============================] - 0s 444us/step - loss: 0.3916 - accuracy: 0.8151\n",
      "Epoch 129/200\n",
      "305/305 [==============================] - 0s 552us/step - loss: 0.3887 - accuracy: 0.8114\n",
      "Epoch 130/200\n",
      "305/305 [==============================] - 0s 593us/step - loss: 0.3844 - accuracy: 0.8135\n",
      "Epoch 131/200\n",
      "305/305 [==============================] - 0s 455us/step - loss: 0.3902 - accuracy: 0.8159\n",
      "Epoch 132/200\n",
      "305/305 [==============================] - 0s 492us/step - loss: 0.3865 - accuracy: 0.8168\n",
      "Epoch 133/200\n",
      "305/305 [==============================] - 0s 437us/step - loss: 0.3871 - accuracy: 0.8176\n",
      "Epoch 134/200\n",
      "305/305 [==============================] - 0s 431us/step - loss: 0.3840 - accuracy: 0.8192\n",
      "Epoch 135/200\n",
      "305/305 [==============================] - 0s 438us/step - loss: 0.3901 - accuracy: 0.8122\n",
      "Epoch 136/200\n",
      "305/305 [==============================] - 0s 441us/step - loss: 0.3823 - accuracy: 0.8153\n",
      "Epoch 137/200\n",
      "305/305 [==============================] - 0s 439us/step - loss: 0.3885 - accuracy: 0.8135\n",
      "Epoch 138/200\n",
      "305/305 [==============================] - 0s 452us/step - loss: 0.3825 - accuracy: 0.8151\n",
      "Epoch 139/200\n",
      "305/305 [==============================] - 0s 442us/step - loss: 0.3853 - accuracy: 0.8161\n",
      "Epoch 140/200\n",
      "305/305 [==============================] - 0s 433us/step - loss: 0.3807 - accuracy: 0.8215\n",
      "Epoch 141/200\n",
      "305/305 [==============================] - 0s 442us/step - loss: 0.3865 - accuracy: 0.8129\n",
      "Epoch 142/200\n",
      "305/305 [==============================] - 0s 437us/step - loss: 0.3833 - accuracy: 0.8225\n",
      "Epoch 143/200\n",
      "305/305 [==============================] - 0s 432us/step - loss: 0.3864 - accuracy: 0.8131\n",
      "Epoch 144/200\n",
      "305/305 [==============================] - 0s 433us/step - loss: 0.3856 - accuracy: 0.8180\n",
      "Epoch 145/200\n",
      "305/305 [==============================] - 0s 565us/step - loss: 0.3865 - accuracy: 0.8157\n",
      "Epoch 146/200\n",
      "305/305 [==============================] - 0s 434us/step - loss: 0.3889 - accuracy: 0.8147\n",
      "Epoch 147/200\n",
      "305/305 [==============================] - 0s 482us/step - loss: 0.3833 - accuracy: 0.8186\n",
      "Epoch 148/200\n",
      "305/305 [==============================] - 0s 435us/step - loss: 0.3839 - accuracy: 0.8180\n",
      "Epoch 149/200\n",
      "305/305 [==============================] - 0s 433us/step - loss: 0.3820 - accuracy: 0.8168\n",
      "Epoch 150/200\n",
      "305/305 [==============================] - 0s 432us/step - loss: 0.3893 - accuracy: 0.8157\n",
      "Epoch 151/200\n",
      "305/305 [==============================] - 0s 431us/step - loss: 0.3839 - accuracy: 0.8159\n",
      "Epoch 152/200\n",
      "305/305 [==============================] - 0s 432us/step - loss: 0.3865 - accuracy: 0.8161\n",
      "Epoch 153/200\n",
      "305/305 [==============================] - 0s 433us/step - loss: 0.3860 - accuracy: 0.8153\n",
      "Epoch 154/200\n",
      "305/305 [==============================] - 0s 425us/step - loss: 0.3831 - accuracy: 0.8184\n",
      "Epoch 155/200\n",
      "305/305 [==============================] - 0s 433us/step - loss: 0.3859 - accuracy: 0.8151\n",
      "Epoch 156/200\n",
      "305/305 [==============================] - 0s 437us/step - loss: 0.3851 - accuracy: 0.8180\n",
      "Epoch 157/200\n",
      "305/305 [==============================] - 0s 445us/step - loss: 0.3852 - accuracy: 0.8098\n",
      "Epoch 158/200\n",
      "305/305 [==============================] - 0s 561us/step - loss: 0.3885 - accuracy: 0.8114\n",
      "Epoch 159/200\n",
      "305/305 [==============================] - 0s 457us/step - loss: 0.3849 - accuracy: 0.8184\n",
      "Epoch 160/200\n",
      "305/305 [==============================] - 0s 516us/step - loss: 0.3897 - accuracy: 0.8159\n",
      "Epoch 161/200\n",
      "305/305 [==============================] - 0s 431us/step - loss: 0.3895 - accuracy: 0.8143\n",
      "Epoch 162/200\n",
      "305/305 [==============================] - 0s 445us/step - loss: 0.3837 - accuracy: 0.8178\n",
      "Epoch 163/200\n",
      "305/305 [==============================] - 0s 437us/step - loss: 0.3795 - accuracy: 0.8166\n",
      "Epoch 164/200\n",
      "305/305 [==============================] - 0s 442us/step - loss: 0.3865 - accuracy: 0.8145\n",
      "Epoch 165/200\n",
      "305/305 [==============================] - 0s 435us/step - loss: 0.3848 - accuracy: 0.8139\n",
      "Epoch 166/200\n",
      "305/305 [==============================] - 0s 436us/step - loss: 0.3919 - accuracy: 0.8090\n",
      "Epoch 167/200\n",
      "305/305 [==============================] - 0s 445us/step - loss: 0.3846 - accuracy: 0.8168\n",
      "Epoch 168/200\n",
      "305/305 [==============================] - 0s 441us/step - loss: 0.3880 - accuracy: 0.8174\n",
      "Epoch 169/200\n",
      "305/305 [==============================] - 0s 430us/step - loss: 0.3823 - accuracy: 0.8196\n",
      "Epoch 170/200\n",
      "305/305 [==============================] - 0s 434us/step - loss: 0.3785 - accuracy: 0.8198\n",
      "Epoch 171/200\n",
      "305/305 [==============================] - 0s 441us/step - loss: 0.3830 - accuracy: 0.8211\n",
      "Epoch 172/200\n",
      "305/305 [==============================] - 0s 583us/step - loss: 0.3809 - accuracy: 0.8207\n",
      "Epoch 173/200\n",
      "305/305 [==============================] - 0s 453us/step - loss: 0.3852 - accuracy: 0.8153\n",
      "Epoch 174/200\n",
      "305/305 [==============================] - 0s 502us/step - loss: 0.3834 - accuracy: 0.8164\n",
      "Epoch 175/200\n",
      "305/305 [==============================] - 0s 432us/step - loss: 0.3862 - accuracy: 0.8155\n",
      "Epoch 176/200\n",
      "305/305 [==============================] - 0s 570us/step - loss: 0.3823 - accuracy: 0.8194\n",
      "Epoch 177/200\n",
      "305/305 [==============================] - 0s 470us/step - loss: 0.3858 - accuracy: 0.8141\n",
      "Epoch 178/200\n",
      "305/305 [==============================] - 0s 432us/step - loss: 0.3799 - accuracy: 0.8155\n",
      "Epoch 179/200\n",
      "305/305 [==============================] - 0s 429us/step - loss: 0.3822 - accuracy: 0.8223\n",
      "Epoch 180/200\n",
      "305/305 [==============================] - 0s 425us/step - loss: 0.3774 - accuracy: 0.8168\n",
      "Epoch 181/200\n",
      "305/305 [==============================] - 0s 445us/step - loss: 0.3810 - accuracy: 0.8194\n",
      "Epoch 182/200\n",
      "305/305 [==============================] - 0s 440us/step - loss: 0.3852 - accuracy: 0.8207\n",
      "Epoch 183/200\n",
      "305/305 [==============================] - 0s 435us/step - loss: 0.3822 - accuracy: 0.8149\n",
      "Epoch 184/200\n",
      "305/305 [==============================] - 0s 438us/step - loss: 0.3839 - accuracy: 0.8188\n",
      "Epoch 185/200\n",
      "305/305 [==============================] - 0s 438us/step - loss: 0.3822 - accuracy: 0.8153\n",
      "Epoch 186/200\n",
      "305/305 [==============================] - 0s 443us/step - loss: 0.3837 - accuracy: 0.8170\n",
      "Epoch 187/200\n",
      "305/305 [==============================] - 0s 433us/step - loss: 0.3836 - accuracy: 0.8159\n",
      "Epoch 188/200\n",
      "305/305 [==============================] - 0s 432us/step - loss: 0.3835 - accuracy: 0.8137\n",
      "Epoch 189/200\n",
      "305/305 [==============================] - 0s 436us/step - loss: 0.3856 - accuracy: 0.8155\n",
      "Epoch 190/200\n",
      "305/305 [==============================] - 0s 433us/step - loss: 0.3851 - accuracy: 0.8166\n",
      "Epoch 191/200\n",
      "305/305 [==============================] - 0s 634us/step - loss: 0.3817 - accuracy: 0.8170\n",
      "Epoch 192/200\n",
      "305/305 [==============================] - 0s 462us/step - loss: 0.3811 - accuracy: 0.8203\n",
      "Epoch 193/200\n",
      "305/305 [==============================] - 0s 492us/step - loss: 0.3805 - accuracy: 0.8161\n",
      "Epoch 194/200\n",
      "305/305 [==============================] - 0s 431us/step - loss: 0.3850 - accuracy: 0.8151\n",
      "Epoch 195/200\n",
      "305/305 [==============================] - 0s 431us/step - loss: 0.3828 - accuracy: 0.8153\n",
      "Epoch 196/200\n",
      "305/305 [==============================] - 0s 426us/step - loss: 0.3816 - accuracy: 0.8196\n",
      "Epoch 197/200\n",
      "305/305 [==============================] - 0s 430us/step - loss: 0.3801 - accuracy: 0.8219\n",
      "Epoch 198/200\n",
      "305/305 [==============================] - 0s 431us/step - loss: 0.3864 - accuracy: 0.8151\n",
      "Epoch 199/200\n",
      "305/305 [==============================] - 0s 435us/step - loss: 0.3790 - accuracy: 0.8217\n",
      "Epoch 200/200\n",
      "305/305 [==============================] - 0s 436us/step - loss: 0.3865 - accuracy: 0.8137\n",
      "39/39 [==============================] - 0s 335us/step\n",
      "Epoch 1/200\n",
      "305/305 [==============================] - 0s 452us/step - loss: 0.5440 - accuracy: 0.7198\n",
      "Epoch 2/200\n",
      "305/305 [==============================] - 0s 439us/step - loss: 0.4533 - accuracy: 0.7747\n",
      "Epoch 3/200\n",
      "305/305 [==============================] - 0s 437us/step - loss: 0.4440 - accuracy: 0.7843\n",
      "Epoch 4/200\n",
      "305/305 [==============================] - 0s 432us/step - loss: 0.4410 - accuracy: 0.7884\n",
      "Epoch 5/200\n",
      "305/305 [==============================] - 0s 430us/step - loss: 0.4332 - accuracy: 0.7890\n",
      "Epoch 6/200\n",
      "305/305 [==============================] - 0s 560us/step - loss: 0.4344 - accuracy: 0.7892\n",
      "Epoch 7/200\n",
      "305/305 [==============================] - 0s 444us/step - loss: 0.4319 - accuracy: 0.7929\n",
      "Epoch 8/200\n",
      "305/305 [==============================] - 0s 485us/step - loss: 0.4321 - accuracy: 0.7944\n",
      "Epoch 9/200\n",
      "305/305 [==============================] - 0s 448us/step - loss: 0.4278 - accuracy: 0.7925\n",
      "Epoch 10/200\n",
      "305/305 [==============================] - 0s 430us/step - loss: 0.4289 - accuracy: 0.7923\n",
      "Epoch 11/200\n",
      "305/305 [==============================] - 0s 436us/step - loss: 0.4307 - accuracy: 0.7950\n",
      "Epoch 12/200\n",
      "305/305 [==============================] - 0s 437us/step - loss: 0.4230 - accuracy: 0.7964\n",
      "Epoch 13/200\n",
      "305/305 [==============================] - 0s 436us/step - loss: 0.4263 - accuracy: 0.7956\n",
      "Epoch 14/200\n",
      "305/305 [==============================] - 0s 427us/step - loss: 0.4291 - accuracy: 0.7901\n",
      "Epoch 15/200\n",
      "305/305 [==============================] - 0s 438us/step - loss: 0.4234 - accuracy: 0.7954\n",
      "Epoch 16/200\n",
      "305/305 [==============================] - 0s 432us/step - loss: 0.4216 - accuracy: 0.7997\n",
      "Epoch 17/200\n",
      "305/305 [==============================] - 0s 428us/step - loss: 0.4222 - accuracy: 0.7985\n",
      "Epoch 18/200\n",
      "305/305 [==============================] - 0s 429us/step - loss: 0.4226 - accuracy: 0.7962\n",
      "Epoch 19/200\n",
      "305/305 [==============================] - 0s 429us/step - loss: 0.4202 - accuracy: 0.7966\n",
      "Epoch 20/200\n",
      "305/305 [==============================] - 0s 427us/step - loss: 0.4212 - accuracy: 0.8007\n",
      "Epoch 21/200\n",
      "305/305 [==============================] - 0s 557us/step - loss: 0.4172 - accuracy: 0.8014\n",
      "Epoch 22/200\n",
      "305/305 [==============================] - 0s 456us/step - loss: 0.4199 - accuracy: 0.7935\n",
      "Epoch 23/200\n",
      "305/305 [==============================] - 0s 446us/step - loss: 0.4157 - accuracy: 0.8024\n",
      "Epoch 24/200\n",
      "305/305 [==============================] - 0s 486us/step - loss: 0.4174 - accuracy: 0.7977\n",
      "Epoch 25/200\n",
      "305/305 [==============================] - 0s 438us/step - loss: 0.4148 - accuracy: 0.8009\n",
      "Epoch 26/200\n",
      "305/305 [==============================] - 0s 439us/step - loss: 0.4157 - accuracy: 0.8020\n",
      "Epoch 27/200\n",
      "305/305 [==============================] - 0s 445us/step - loss: 0.4162 - accuracy: 0.7964\n",
      "Epoch 28/200\n",
      "305/305 [==============================] - 0s 443us/step - loss: 0.4141 - accuracy: 0.7987\n",
      "Epoch 29/200\n",
      "305/305 [==============================] - 0s 428us/step - loss: 0.4166 - accuracy: 0.8003\n",
      "Epoch 30/200\n",
      "305/305 [==============================] - 0s 426us/step - loss: 0.4115 - accuracy: 0.8036\n",
      "Epoch 31/200\n",
      "305/305 [==============================] - 0s 432us/step - loss: 0.4166 - accuracy: 0.7977\n",
      "Epoch 32/200\n",
      "305/305 [==============================] - 0s 427us/step - loss: 0.4141 - accuracy: 0.7981\n",
      "Epoch 33/200\n",
      "305/305 [==============================] - 0s 465us/step - loss: 0.4125 - accuracy: 0.8016\n",
      "Epoch 34/200\n",
      "305/305 [==============================] - 0s 429us/step - loss: 0.4099 - accuracy: 0.8055\n",
      "Epoch 35/200\n",
      "305/305 [==============================] - 0s 430us/step - loss: 0.4110 - accuracy: 0.8020\n",
      "Epoch 36/200\n",
      "305/305 [==============================] - 0s 429us/step - loss: 0.4091 - accuracy: 0.8009\n",
      "Epoch 37/200\n",
      "305/305 [==============================] - 0s 550us/step - loss: 0.4151 - accuracy: 0.8034\n",
      "Epoch 38/200\n",
      "305/305 [==============================] - 0s 436us/step - loss: 0.4103 - accuracy: 0.8048\n",
      "Epoch 39/200\n",
      "305/305 [==============================] - 0s 502us/step - loss: 0.4133 - accuracy: 0.8057\n",
      "Epoch 40/200\n",
      "305/305 [==============================] - 0s 429us/step - loss: 0.4113 - accuracy: 0.8071\n",
      "Epoch 41/200\n",
      "305/305 [==============================] - 0s 432us/step - loss: 0.4099 - accuracy: 0.8051\n",
      "Epoch 42/200\n",
      "305/305 [==============================] - 0s 428us/step - loss: 0.4115 - accuracy: 0.8057\n",
      "Epoch 43/200\n",
      "305/305 [==============================] - 0s 422us/step - loss: 0.4096 - accuracy: 0.8040\n",
      "Epoch 44/200\n",
      "305/305 [==============================] - 0s 433us/step - loss: 0.4073 - accuracy: 0.8026\n",
      "Epoch 45/200\n",
      "305/305 [==============================] - 0s 435us/step - loss: 0.4096 - accuracy: 0.8065\n",
      "Epoch 46/200\n",
      "305/305 [==============================] - 0s 433us/step - loss: 0.4119 - accuracy: 0.8042\n",
      "Epoch 47/200\n",
      "305/305 [==============================] - 0s 423us/step - loss: 0.4082 - accuracy: 0.8046\n",
      "Epoch 48/200\n",
      "305/305 [==============================] - 0s 430us/step - loss: 0.4116 - accuracy: 0.7993\n",
      "Epoch 49/200\n",
      "305/305 [==============================] - 0s 433us/step - loss: 0.4056 - accuracy: 0.8040\n",
      "Epoch 50/200\n",
      "305/305 [==============================] - 0s 431us/step - loss: 0.4101 - accuracy: 0.8057\n",
      "Epoch 51/200\n",
      "305/305 [==============================] - 0s 432us/step - loss: 0.4019 - accuracy: 0.8079\n",
      "Epoch 52/200\n",
      "305/305 [==============================] - 0s 581us/step - loss: 0.4052 - accuracy: 0.8110\n",
      "Epoch 53/200\n",
      "305/305 [==============================] - 0s 448us/step - loss: 0.4107 - accuracy: 0.7999\n",
      "Epoch 54/200\n",
      "305/305 [==============================] - 0s 498us/step - loss: 0.4037 - accuracy: 0.8083\n",
      "Epoch 55/200\n",
      "305/305 [==============================] - 0s 451us/step - loss: 0.4043 - accuracy: 0.8090\n",
      "Epoch 56/200\n",
      "305/305 [==============================] - 0s 435us/step - loss: 0.4085 - accuracy: 0.8040\n",
      "Epoch 57/200\n",
      "305/305 [==============================] - 0s 439us/step - loss: 0.4072 - accuracy: 0.8044\n",
      "Epoch 58/200\n",
      "305/305 [==============================] - 0s 415us/step - loss: 0.4090 - accuracy: 0.8059\n",
      "Epoch 59/200\n",
      "305/305 [==============================] - 0s 429us/step - loss: 0.4052 - accuracy: 0.8059\n",
      "Epoch 60/200\n",
      "305/305 [==============================] - 0s 457us/step - loss: 0.4035 - accuracy: 0.8071\n",
      "Epoch 61/200\n",
      "305/305 [==============================] - 0s 476us/step - loss: 0.4017 - accuracy: 0.8071\n",
      "Epoch 62/200\n",
      "305/305 [==============================] - 0s 430us/step - loss: 0.4038 - accuracy: 0.8102\n",
      "Epoch 63/200\n",
      "305/305 [==============================] - 0s 431us/step - loss: 0.4062 - accuracy: 0.8092\n",
      "Epoch 64/200\n",
      "305/305 [==============================] - 0s 426us/step - loss: 0.4047 - accuracy: 0.8075\n",
      "Epoch 65/200\n",
      "305/305 [==============================] - 0s 441us/step - loss: 0.4026 - accuracy: 0.8073\n",
      "Epoch 66/200\n",
      "305/305 [==============================] - 0s 442us/step - loss: 0.4027 - accuracy: 0.8092\n",
      "Epoch 67/200\n",
      "305/305 [==============================] - 0s 442us/step - loss: 0.4047 - accuracy: 0.8065\n",
      "Epoch 68/200\n",
      "305/305 [==============================] - 0s 446us/step - loss: 0.4030 - accuracy: 0.8069\n",
      "Epoch 69/200\n",
      "305/305 [==============================] - 0s 459us/step - loss: 0.4006 - accuracy: 0.8098\n",
      "Epoch 70/200\n",
      "305/305 [==============================] - 0s 442us/step - loss: 0.4052 - accuracy: 0.7995\n",
      "Epoch 71/200\n",
      "305/305 [==============================] - 0s 472us/step - loss: 0.4107 - accuracy: 0.8069\n",
      "Epoch 72/200\n",
      "305/305 [==============================] - 0s 440us/step - loss: 0.4043 - accuracy: 0.8090\n",
      "Epoch 73/200\n",
      "305/305 [==============================] - 0s 450us/step - loss: 0.4009 - accuracy: 0.8051\n",
      "Epoch 74/200\n",
      "305/305 [==============================] - 0s 559us/step - loss: 0.3965 - accuracy: 0.8124\n",
      "Epoch 75/200\n",
      "305/305 [==============================] - 0s 454us/step - loss: 0.4051 - accuracy: 0.8063\n",
      "Epoch 76/200\n",
      "305/305 [==============================] - 0s 468us/step - loss: 0.4049 - accuracy: 0.8055\n",
      "Epoch 77/200\n",
      "305/305 [==============================] - 0s 512us/step - loss: 0.3985 - accuracy: 0.8118\n",
      "Epoch 78/200\n",
      "305/305 [==============================] - 0s 441us/step - loss: 0.3993 - accuracy: 0.8063\n",
      "Epoch 79/200\n",
      "305/305 [==============================] - 0s 438us/step - loss: 0.3985 - accuracy: 0.8092\n",
      "Epoch 80/200\n",
      "305/305 [==============================] - 0s 439us/step - loss: 0.4009 - accuracy: 0.8100\n",
      "Epoch 81/200\n",
      "305/305 [==============================] - 0s 445us/step - loss: 0.3965 - accuracy: 0.8135\n",
      "Epoch 82/200\n",
      "305/305 [==============================] - 0s 455us/step - loss: 0.4010 - accuracy: 0.8085\n",
      "Epoch 83/200\n",
      "305/305 [==============================] - 0s 466us/step - loss: 0.4063 - accuracy: 0.8075\n",
      "Epoch 84/200\n",
      "305/305 [==============================] - 0s 442us/step - loss: 0.4009 - accuracy: 0.8116\n",
      "Epoch 85/200\n",
      "305/305 [==============================] - 0s 434us/step - loss: 0.4032 - accuracy: 0.8071\n",
      "Epoch 86/200\n",
      "305/305 [==============================] - 0s 443us/step - loss: 0.4032 - accuracy: 0.8083\n",
      "Epoch 87/200\n",
      "305/305 [==============================] - 0s 452us/step - loss: 0.4019 - accuracy: 0.8102\n",
      "Epoch 88/200\n",
      "305/305 [==============================] - 0s 591us/step - loss: 0.3989 - accuracy: 0.8102\n",
      "Epoch 89/200\n",
      "305/305 [==============================] - 0s 456us/step - loss: 0.4031 - accuracy: 0.8075\n",
      "Epoch 90/200\n",
      "305/305 [==============================] - 0s 506us/step - loss: 0.3991 - accuracy: 0.8104\n",
      "Epoch 91/200\n",
      "305/305 [==============================] - 0s 442us/step - loss: 0.4002 - accuracy: 0.8104\n",
      "Epoch 92/200\n",
      "305/305 [==============================] - 0s 447us/step - loss: 0.3984 - accuracy: 0.8083\n",
      "Epoch 93/200\n",
      "305/305 [==============================] - 0s 440us/step - loss: 0.3991 - accuracy: 0.8090\n",
      "Epoch 94/200\n",
      "305/305 [==============================] - 0s 445us/step - loss: 0.4029 - accuracy: 0.8032\n",
      "Epoch 95/200\n",
      "305/305 [==============================] - 0s 440us/step - loss: 0.3970 - accuracy: 0.8106\n",
      "Epoch 96/200\n",
      "305/305 [==============================] - 0s 447us/step - loss: 0.4053 - accuracy: 0.8065\n",
      "Epoch 97/200\n",
      "305/305 [==============================] - 0s 436us/step - loss: 0.3957 - accuracy: 0.8172\n",
      "Epoch 98/200\n",
      "305/305 [==============================] - 0s 456us/step - loss: 0.4008 - accuracy: 0.8135\n",
      "Epoch 99/200\n",
      "305/305 [==============================] - 0s 457us/step - loss: 0.3992 - accuracy: 0.8083\n",
      "Epoch 100/200\n",
      "305/305 [==============================] - 0s 448us/step - loss: 0.4023 - accuracy: 0.8077\n",
      "Epoch 101/200\n",
      "305/305 [==============================] - 0s 439us/step - loss: 0.4022 - accuracy: 0.8077\n",
      "Epoch 102/200\n",
      "305/305 [==============================] - 0s 449us/step - loss: 0.3991 - accuracy: 0.8131\n",
      "Epoch 103/200\n",
      "305/305 [==============================] - 0s 594us/step - loss: 0.4050 - accuracy: 0.8012\n",
      "Epoch 104/200\n",
      "305/305 [==============================] - 0s 450us/step - loss: 0.3989 - accuracy: 0.8164\n",
      "Epoch 105/200\n",
      "305/305 [==============================] - 0s 510us/step - loss: 0.4027 - accuracy: 0.8088\n",
      "Epoch 106/200\n",
      "305/305 [==============================] - 0s 454us/step - loss: 0.3968 - accuracy: 0.8139\n",
      "Epoch 107/200\n",
      "305/305 [==============================] - 0s 441us/step - loss: 0.4007 - accuracy: 0.8118\n",
      "Epoch 108/200\n",
      "305/305 [==============================] - 0s 482us/step - loss: 0.3964 - accuracy: 0.8118\n",
      "Epoch 109/200\n",
      "305/305 [==============================] - 0s 548us/step - loss: 0.3986 - accuracy: 0.8118\n",
      "Epoch 110/200\n",
      "305/305 [==============================] - 0s 465us/step - loss: 0.3977 - accuracy: 0.8100\n",
      "Epoch 111/200\n",
      "305/305 [==============================] - 0s 450us/step - loss: 0.3990 - accuracy: 0.8081\n",
      "Epoch 112/200\n",
      "305/305 [==============================] - 0s 439us/step - loss: 0.3970 - accuracy: 0.8094\n",
      "Epoch 113/200\n",
      "305/305 [==============================] - 0s 445us/step - loss: 0.3982 - accuracy: 0.8145\n",
      "Epoch 114/200\n",
      "305/305 [==============================] - 0s 424us/step - loss: 0.3968 - accuracy: 0.8145\n",
      "Epoch 115/200\n",
      "305/305 [==============================] - 0s 455us/step - loss: 0.3954 - accuracy: 0.8071\n",
      "Epoch 116/200\n",
      "305/305 [==============================] - 0s 439us/step - loss: 0.4026 - accuracy: 0.8079\n",
      "Epoch 117/200\n",
      "305/305 [==============================] - 0s 428us/step - loss: 0.3989 - accuracy: 0.8040\n",
      "Epoch 118/200\n",
      "305/305 [==============================] - 0s 429us/step - loss: 0.3991 - accuracy: 0.8096\n",
      "Epoch 119/200\n",
      "305/305 [==============================] - 0s 449us/step - loss: 0.3965 - accuracy: 0.8104\n",
      "Epoch 120/200\n",
      "305/305 [==============================] - 0s 445us/step - loss: 0.3958 - accuracy: 0.8127\n",
      "Epoch 121/200\n",
      "305/305 [==============================] - 0s 441us/step - loss: 0.3976 - accuracy: 0.8104\n",
      "Epoch 122/200\n",
      "305/305 [==============================] - 0s 425us/step - loss: 0.3986 - accuracy: 0.8110\n",
      "Epoch 123/200\n",
      "305/305 [==============================] - 0s 436us/step - loss: 0.3981 - accuracy: 0.8106\n",
      "Epoch 124/200\n",
      "305/305 [==============================] - 0s 448us/step - loss: 0.4031 - accuracy: 0.8120\n",
      "Epoch 125/200\n",
      "305/305 [==============================] - 0s 434us/step - loss: 0.3964 - accuracy: 0.8100\n",
      "Epoch 126/200\n",
      "305/305 [==============================] - 0s 479us/step - loss: 0.3982 - accuracy: 0.8090\n",
      "Epoch 127/200\n",
      "305/305 [==============================] - 0s 577us/step - loss: 0.3982 - accuracy: 0.8096\n",
      "Epoch 128/200\n",
      "305/305 [==============================] - 0s 504us/step - loss: 0.3981 - accuracy: 0.8104\n",
      "Epoch 129/200\n",
      "305/305 [==============================] - 0s 540us/step - loss: 0.3951 - accuracy: 0.8120\n",
      "Epoch 130/200\n",
      "305/305 [==============================] - 0s 505us/step - loss: 0.3979 - accuracy: 0.8094\n",
      "Epoch 131/200\n",
      "305/305 [==============================] - 0s 449us/step - loss: 0.3982 - accuracy: 0.8083\n",
      "Epoch 132/200\n",
      "305/305 [==============================] - 0s 427us/step - loss: 0.3973 - accuracy: 0.8098\n",
      "Epoch 133/200\n",
      "305/305 [==============================] - 0s 436us/step - loss: 0.3971 - accuracy: 0.8098\n",
      "Epoch 134/200\n",
      "305/305 [==============================] - 0s 443us/step - loss: 0.4020 - accuracy: 0.8120\n",
      "Epoch 135/200\n",
      "305/305 [==============================] - 0s 439us/step - loss: 0.3980 - accuracy: 0.8106\n",
      "Epoch 136/200\n",
      "305/305 [==============================] - 0s 439us/step - loss: 0.3958 - accuracy: 0.8166\n",
      "Epoch 137/200\n",
      "305/305 [==============================] - 0s 434us/step - loss: 0.3962 - accuracy: 0.8106\n",
      "Epoch 138/200\n",
      "305/305 [==============================] - 0s 434us/step - loss: 0.4013 - accuracy: 0.8071\n",
      "Epoch 139/200\n",
      "305/305 [==============================] - 0s 429us/step - loss: 0.3965 - accuracy: 0.8164\n",
      "Epoch 140/200\n",
      "305/305 [==============================] - 0s 445us/step - loss: 0.3973 - accuracy: 0.8104\n",
      "Epoch 141/200\n",
      "305/305 [==============================] - 0s 450us/step - loss: 0.3947 - accuracy: 0.8127\n",
      "Epoch 142/200\n",
      "305/305 [==============================] - 0s 432us/step - loss: 0.3944 - accuracy: 0.8098\n",
      "Epoch 143/200\n",
      "305/305 [==============================] - 0s 589us/step - loss: 0.3956 - accuracy: 0.8174\n",
      "Epoch 144/200\n",
      "305/305 [==============================] - 0s 519us/step - loss: 0.3992 - accuracy: 0.8139\n",
      "Epoch 145/200\n",
      "305/305 [==============================] - 0s 435us/step - loss: 0.3948 - accuracy: 0.8147\n",
      "Epoch 146/200\n",
      "305/305 [==============================] - 0s 445us/step - loss: 0.3950 - accuracy: 0.8108\n",
      "Epoch 147/200\n",
      "305/305 [==============================] - 0s 441us/step - loss: 0.3980 - accuracy: 0.8120\n",
      "Epoch 148/200\n",
      "305/305 [==============================] - 0s 438us/step - loss: 0.3956 - accuracy: 0.8145\n",
      "Epoch 149/200\n",
      "305/305 [==============================] - 0s 437us/step - loss: 0.3942 - accuracy: 0.8124\n",
      "Epoch 150/200\n",
      "305/305 [==============================] - 0s 428us/step - loss: 0.3935 - accuracy: 0.8104\n",
      "Epoch 151/200\n",
      "305/305 [==============================] - 0s 436us/step - loss: 0.3940 - accuracy: 0.8104\n",
      "Epoch 152/200\n",
      "305/305 [==============================] - 0s 432us/step - loss: 0.4012 - accuracy: 0.8104\n",
      "Epoch 153/200\n",
      "305/305 [==============================] - 0s 436us/step - loss: 0.3962 - accuracy: 0.8135\n",
      "Epoch 154/200\n",
      "305/305 [==============================] - 0s 435us/step - loss: 0.3957 - accuracy: 0.8151\n",
      "Epoch 155/200\n",
      "305/305 [==============================] - 0s 441us/step - loss: 0.3943 - accuracy: 0.8145\n",
      "Epoch 156/200\n",
      "305/305 [==============================] - 0s 432us/step - loss: 0.3978 - accuracy: 0.8122\n",
      "Epoch 157/200\n",
      "305/305 [==============================] - 0s 457us/step - loss: 0.3937 - accuracy: 0.8219\n",
      "Epoch 158/200\n",
      "305/305 [==============================] - 0s 437us/step - loss: 0.3986 - accuracy: 0.8063\n",
      "Epoch 159/200\n",
      "305/305 [==============================] - 0s 433us/step - loss: 0.3910 - accuracy: 0.8077\n",
      "Epoch 160/200\n",
      "305/305 [==============================] - 0s 434us/step - loss: 0.3962 - accuracy: 0.8096\n",
      "Epoch 161/200\n",
      "305/305 [==============================] - 0s 441us/step - loss: 0.3985 - accuracy: 0.8077\n",
      "Epoch 162/200\n",
      "305/305 [==============================] - 0s 468us/step - loss: 0.3982 - accuracy: 0.8090\n",
      "Epoch 163/200\n",
      "305/305 [==============================] - 0s 442us/step - loss: 0.3910 - accuracy: 0.8151\n",
      "Epoch 164/200\n",
      "305/305 [==============================] - 0s 667us/step - loss: 0.3933 - accuracy: 0.8124\n",
      "Epoch 165/200\n",
      "305/305 [==============================] - 0s 438us/step - loss: 0.3943 - accuracy: 0.8077\n",
      "Epoch 166/200\n",
      "305/305 [==============================] - 0s 491us/step - loss: 0.3951 - accuracy: 0.8102\n",
      "Epoch 167/200\n",
      "305/305 [==============================] - 0s 439us/step - loss: 0.3968 - accuracy: 0.8094\n",
      "Epoch 168/200\n",
      "305/305 [==============================] - 0s 436us/step - loss: 0.3940 - accuracy: 0.8124\n",
      "Epoch 169/200\n",
      "305/305 [==============================] - 0s 442us/step - loss: 0.3987 - accuracy: 0.8020\n",
      "Epoch 170/200\n",
      "305/305 [==============================] - 0s 435us/step - loss: 0.3946 - accuracy: 0.8106\n",
      "Epoch 171/200\n",
      "305/305 [==============================] - 0s 443us/step - loss: 0.3958 - accuracy: 0.8100\n",
      "Epoch 172/200\n",
      "305/305 [==============================] - 0s 437us/step - loss: 0.3966 - accuracy: 0.8092\n",
      "Epoch 173/200\n",
      "305/305 [==============================] - 0s 440us/step - loss: 0.3911 - accuracy: 0.8164\n",
      "Epoch 174/200\n",
      "305/305 [==============================] - 0s 434us/step - loss: 0.3919 - accuracy: 0.8096\n",
      "Epoch 175/200\n",
      "305/305 [==============================] - 0s 472us/step - loss: 0.3953 - accuracy: 0.8124\n",
      "Epoch 176/200\n",
      "305/305 [==============================] - 0s 438us/step - loss: 0.3893 - accuracy: 0.8164\n",
      "Epoch 177/200\n",
      "305/305 [==============================] - 0s 448us/step - loss: 0.3963 - accuracy: 0.8143\n",
      "Epoch 178/200\n",
      "305/305 [==============================] - 0s 582us/step - loss: 0.3964 - accuracy: 0.8120\n",
      "Epoch 179/200\n",
      "305/305 [==============================] - 0s 451us/step - loss: 0.3956 - accuracy: 0.8131\n",
      "Epoch 180/200\n",
      "305/305 [==============================] - 0s 499us/step - loss: 0.3929 - accuracy: 0.8120\n",
      "Epoch 181/200\n",
      "305/305 [==============================] - 0s 439us/step - loss: 0.3937 - accuracy: 0.8166\n",
      "Epoch 182/200\n",
      "305/305 [==============================] - 0s 433us/step - loss: 0.3940 - accuracy: 0.8141\n",
      "Epoch 183/200\n",
      "305/305 [==============================] - 0s 444us/step - loss: 0.3965 - accuracy: 0.8098\n",
      "Epoch 184/200\n",
      "305/305 [==============================] - 0s 431us/step - loss: 0.3914 - accuracy: 0.8133\n",
      "Epoch 185/200\n",
      "305/305 [==============================] - 0s 424us/step - loss: 0.3926 - accuracy: 0.8129\n",
      "Epoch 186/200\n",
      "305/305 [==============================] - 0s 438us/step - loss: 0.3920 - accuracy: 0.8071\n",
      "Epoch 187/200\n",
      "305/305 [==============================] - 0s 414us/step - loss: 0.3947 - accuracy: 0.8108\n",
      "Epoch 188/200\n",
      "305/305 [==============================] - 0s 435us/step - loss: 0.3941 - accuracy: 0.8116\n",
      "Epoch 189/200\n",
      "305/305 [==============================] - 0s 439us/step - loss: 0.3923 - accuracy: 0.8159\n",
      "Epoch 190/200\n",
      "305/305 [==============================] - 0s 428us/step - loss: 0.3891 - accuracy: 0.8135\n",
      "Epoch 191/200\n",
      "305/305 [==============================] - 0s 421us/step - loss: 0.3980 - accuracy: 0.8139\n",
      "Epoch 192/200\n",
      "305/305 [==============================] - 0s 436us/step - loss: 0.3956 - accuracy: 0.8145\n",
      "Epoch 193/200\n",
      "305/305 [==============================] - 0s 425us/step - loss: 0.3930 - accuracy: 0.8172\n",
      "Epoch 194/200\n",
      "305/305 [==============================] - 0s 429us/step - loss: 0.3911 - accuracy: 0.8153\n",
      "Epoch 195/200\n",
      "305/305 [==============================] - 0s 437us/step - loss: 0.3911 - accuracy: 0.8164\n",
      "Epoch 196/200\n",
      "305/305 [==============================] - 0s 429us/step - loss: 0.3955 - accuracy: 0.8137\n",
      "Epoch 197/200\n",
      "305/305 [==============================] - 0s 438us/step - loss: 0.3894 - accuracy: 0.8192\n",
      "Epoch 198/200\n",
      "305/305 [==============================] - 0s 436us/step - loss: 0.3945 - accuracy: 0.8157\n",
      "Epoch 199/200\n",
      "305/305 [==============================] - 0s 433us/step - loss: 0.3866 - accuracy: 0.8182\n",
      "Epoch 200/200\n",
      "305/305 [==============================] - 0s 431us/step - loss: 0.3952 - accuracy: 0.8110\n",
      "39/39 [==============================] - 0s 651us/step\n",
      "Epoch 1/100\n",
      "153/153 [==============================] - 0s 495us/step - loss: 0.5808 - accuracy: 0.7025\n",
      "Epoch 2/100\n",
      "153/153 [==============================] - 0s 445us/step - loss: 0.4502 - accuracy: 0.7845\n",
      "Epoch 3/100\n",
      "153/153 [==============================] - 0s 464us/step - loss: 0.4362 - accuracy: 0.7909\n",
      "Epoch 4/100\n",
      "153/153 [==============================] - 0s 459us/step - loss: 0.4320 - accuracy: 0.7929\n",
      "Epoch 5/100\n",
      "153/153 [==============================] - 0s 624us/step - loss: 0.4269 - accuracy: 0.7977\n",
      "Epoch 6/100\n",
      "153/153 [==============================] - 0s 443us/step - loss: 0.4258 - accuracy: 0.7979\n",
      "Epoch 7/100\n",
      "153/153 [==============================] - 0s 442us/step - loss: 0.4239 - accuracy: 0.8022\n",
      "Epoch 8/100\n",
      "153/153 [==============================] - 0s 434us/step - loss: 0.4250 - accuracy: 0.8014\n",
      "Epoch 9/100\n",
      "153/153 [==============================] - 0s 449us/step - loss: 0.4171 - accuracy: 0.8014\n",
      "Epoch 10/100\n",
      "153/153 [==============================] - 0s 443us/step - loss: 0.4211 - accuracy: 0.8018\n",
      "Epoch 11/100\n",
      "153/153 [==============================] - 0s 458us/step - loss: 0.4177 - accuracy: 0.8026\n",
      "Epoch 12/100\n",
      "153/153 [==============================] - 0s 446us/step - loss: 0.4191 - accuracy: 0.8077\n",
      "Epoch 13/100\n",
      "153/153 [==============================] - 0s 438us/step - loss: 0.4139 - accuracy: 0.8018\n",
      "Epoch 14/100\n",
      "153/153 [==============================] - 0s 429us/step - loss: 0.4204 - accuracy: 0.8051\n",
      "Epoch 15/100\n",
      "153/153 [==============================] - 0s 430us/step - loss: 0.4136 - accuracy: 0.8069\n",
      "Epoch 16/100\n",
      "153/153 [==============================] - 0s 440us/step - loss: 0.4178 - accuracy: 0.8059\n",
      "Epoch 17/100\n",
      "153/153 [==============================] - 0s 449us/step - loss: 0.4111 - accuracy: 0.8085\n",
      "Epoch 18/100\n",
      "153/153 [==============================] - 0s 431us/step - loss: 0.4138 - accuracy: 0.8048\n",
      "Epoch 19/100\n",
      "153/153 [==============================] - 0s 441us/step - loss: 0.4129 - accuracy: 0.8034\n",
      "Epoch 20/100\n",
      "153/153 [==============================] - 0s 425us/step - loss: 0.4093 - accuracy: 0.8065\n",
      "Epoch 21/100\n",
      "153/153 [==============================] - 0s 435us/step - loss: 0.4091 - accuracy: 0.8085\n",
      "Epoch 22/100\n",
      "153/153 [==============================] - 0s 441us/step - loss: 0.4108 - accuracy: 0.8032\n",
      "Epoch 23/100\n",
      "153/153 [==============================] - 0s 440us/step - loss: 0.4121 - accuracy: 0.8016\n",
      "Epoch 24/100\n",
      "153/153 [==============================] - 0s 434us/step - loss: 0.4094 - accuracy: 0.8122\n",
      "Epoch 25/100\n",
      "153/153 [==============================] - 0s 457us/step - loss: 0.4044 - accuracy: 0.8108\n",
      "Epoch 26/100\n",
      "153/153 [==============================] - 0s 715us/step - loss: 0.4066 - accuracy: 0.8081\n",
      "Epoch 27/100\n",
      "153/153 [==============================] - 0s 462us/step - loss: 0.4064 - accuracy: 0.8094\n",
      "Epoch 28/100\n",
      "153/153 [==============================] - 0s 455us/step - loss: 0.4080 - accuracy: 0.8061\n",
      "Epoch 29/100\n",
      "153/153 [==============================] - 0s 467us/step - loss: 0.4053 - accuracy: 0.8110\n",
      "Epoch 30/100\n",
      "153/153 [==============================] - 0s 454us/step - loss: 0.4077 - accuracy: 0.8071\n",
      "Epoch 31/100\n",
      "153/153 [==============================] - 0s 558us/step - loss: 0.4068 - accuracy: 0.8090\n",
      "Epoch 32/100\n",
      "153/153 [==============================] - 0s 446us/step - loss: 0.4069 - accuracy: 0.8108\n",
      "Epoch 33/100\n",
      "153/153 [==============================] - 0s 445us/step - loss: 0.4021 - accuracy: 0.8118\n",
      "Epoch 34/100\n",
      "153/153 [==============================] - 0s 440us/step - loss: 0.4036 - accuracy: 0.8108\n",
      "Epoch 35/100\n",
      "153/153 [==============================] - 0s 438us/step - loss: 0.4009 - accuracy: 0.8081\n",
      "Epoch 36/100\n",
      "153/153 [==============================] - 0s 443us/step - loss: 0.4015 - accuracy: 0.8088\n",
      "Epoch 37/100\n",
      "153/153 [==============================] - 0s 469us/step - loss: 0.4005 - accuracy: 0.8096\n",
      "Epoch 38/100\n",
      "153/153 [==============================] - 0s 462us/step - loss: 0.4055 - accuracy: 0.8090\n",
      "Epoch 39/100\n",
      "153/153 [==============================] - 0s 446us/step - loss: 0.4016 - accuracy: 0.8102\n",
      "Epoch 40/100\n",
      "153/153 [==============================] - 0s 457us/step - loss: 0.4056 - accuracy: 0.8053\n",
      "Epoch 41/100\n",
      "153/153 [==============================] - 0s 442us/step - loss: 0.3969 - accuracy: 0.8168\n",
      "Epoch 42/100\n",
      "153/153 [==============================] - 0s 441us/step - loss: 0.3983 - accuracy: 0.8143\n",
      "Epoch 43/100\n",
      "153/153 [==============================] - 0s 423us/step - loss: 0.3996 - accuracy: 0.8137\n",
      "Epoch 44/100\n",
      "153/153 [==============================] - 0s 451us/step - loss: 0.3971 - accuracy: 0.8122\n",
      "Epoch 45/100\n",
      "153/153 [==============================] - 0s 446us/step - loss: 0.3972 - accuracy: 0.8114\n",
      "Epoch 46/100\n",
      "153/153 [==============================] - 0s 452us/step - loss: 0.3973 - accuracy: 0.8161\n",
      "Epoch 47/100\n",
      "153/153 [==============================] - 0s 460us/step - loss: 0.3973 - accuracy: 0.8092\n",
      "Epoch 48/100\n",
      "153/153 [==============================] - 0s 447us/step - loss: 0.3963 - accuracy: 0.8149\n",
      "Epoch 49/100\n",
      "153/153 [==============================] - 0s 444us/step - loss: 0.3963 - accuracy: 0.8133\n",
      "Epoch 50/100\n",
      "153/153 [==============================] - 0s 435us/step - loss: 0.3956 - accuracy: 0.8141\n",
      "Epoch 51/100\n",
      "153/153 [==============================] - 0s 430us/step - loss: 0.3975 - accuracy: 0.8133\n",
      "Epoch 52/100\n",
      "153/153 [==============================] - 0s 440us/step - loss: 0.3901 - accuracy: 0.8194\n",
      "Epoch 53/100\n",
      "153/153 [==============================] - 0s 432us/step - loss: 0.3932 - accuracy: 0.8139\n",
      "Epoch 54/100\n",
      "153/153 [==============================] - 0s 446us/step - loss: 0.3944 - accuracy: 0.8172\n",
      "Epoch 55/100\n",
      "153/153 [==============================] - 0s 433us/step - loss: 0.3934 - accuracy: 0.8112\n",
      "Epoch 56/100\n",
      "153/153 [==============================] - 0s 437us/step - loss: 0.3939 - accuracy: 0.8143\n",
      "Epoch 57/100\n",
      "153/153 [==============================] - 0s 428us/step - loss: 0.3968 - accuracy: 0.8112\n",
      "Epoch 58/100\n",
      "153/153 [==============================] - 0s 437us/step - loss: 0.3946 - accuracy: 0.8164\n",
      "Epoch 59/100\n",
      "153/153 [==============================] - 0s 428us/step - loss: 0.3895 - accuracy: 0.8155\n",
      "Epoch 60/100\n",
      "153/153 [==============================] - 0s 439us/step - loss: 0.3926 - accuracy: 0.8120\n",
      "Epoch 61/100\n",
      "153/153 [==============================] - 0s 429us/step - loss: 0.3907 - accuracy: 0.8168\n",
      "Epoch 62/100\n",
      "153/153 [==============================] - 0s 429us/step - loss: 0.3884 - accuracy: 0.8180\n",
      "Epoch 63/100\n",
      "153/153 [==============================] - 0s 447us/step - loss: 0.3929 - accuracy: 0.8159\n",
      "Epoch 64/100\n",
      "153/153 [==============================] - 0s 690us/step - loss: 0.3932 - accuracy: 0.8131\n",
      "Epoch 65/100\n",
      "153/153 [==============================] - 0s 434us/step - loss: 0.3893 - accuracy: 0.8184\n",
      "Epoch 66/100\n",
      "153/153 [==============================] - 0s 461us/step - loss: 0.3882 - accuracy: 0.8166\n",
      "Epoch 67/100\n",
      "153/153 [==============================] - 0s 436us/step - loss: 0.3913 - accuracy: 0.8155\n",
      "Epoch 68/100\n",
      "153/153 [==============================] - 0s 571us/step - loss: 0.3892 - accuracy: 0.8145\n",
      "Epoch 69/100\n",
      "153/153 [==============================] - 0s 436us/step - loss: 0.3947 - accuracy: 0.8085\n",
      "Epoch 70/100\n",
      "153/153 [==============================] - 0s 453us/step - loss: 0.3927 - accuracy: 0.8116\n",
      "Epoch 71/100\n",
      "153/153 [==============================] - 0s 442us/step - loss: 0.3890 - accuracy: 0.8176\n",
      "Epoch 72/100\n",
      "153/153 [==============================] - 0s 446us/step - loss: 0.3899 - accuracy: 0.8155\n",
      "Epoch 73/100\n",
      "153/153 [==============================] - 0s 430us/step - loss: 0.3872 - accuracy: 0.8168\n",
      "Epoch 74/100\n",
      "153/153 [==============================] - 0s 437us/step - loss: 0.3927 - accuracy: 0.8153\n",
      "Epoch 75/100\n",
      "153/153 [==============================] - 0s 436us/step - loss: 0.3896 - accuracy: 0.8203\n",
      "Epoch 76/100\n",
      "153/153 [==============================] - 0s 436us/step - loss: 0.3851 - accuracy: 0.8200\n",
      "Epoch 77/100\n",
      "153/153 [==============================] - 0s 438us/step - loss: 0.3890 - accuracy: 0.8135\n",
      "Epoch 78/100\n",
      "153/153 [==============================] - 0s 442us/step - loss: 0.3879 - accuracy: 0.8170\n",
      "Epoch 79/100\n",
      "153/153 [==============================] - 0s 439us/step - loss: 0.3893 - accuracy: 0.8188\n",
      "Epoch 80/100\n",
      "153/153 [==============================] - 0s 491us/step - loss: 0.3905 - accuracy: 0.8149\n",
      "Epoch 81/100\n",
      "153/153 [==============================] - 0s 438us/step - loss: 0.3872 - accuracy: 0.8170\n",
      "Epoch 82/100\n",
      "153/153 [==============================] - 0s 439us/step - loss: 0.3910 - accuracy: 0.8184\n",
      "Epoch 83/100\n",
      "153/153 [==============================] - 0s 438us/step - loss: 0.3866 - accuracy: 0.8141\n",
      "Epoch 84/100\n",
      "153/153 [==============================] - 0s 442us/step - loss: 0.3880 - accuracy: 0.8157\n",
      "Epoch 85/100\n",
      "153/153 [==============================] - 0s 432us/step - loss: 0.3832 - accuracy: 0.8203\n",
      "Epoch 86/100\n",
      "153/153 [==============================] - 0s 448us/step - loss: 0.3853 - accuracy: 0.8192\n",
      "Epoch 87/100\n",
      "153/153 [==============================] - 0s 438us/step - loss: 0.3860 - accuracy: 0.8196\n",
      "Epoch 88/100\n",
      "153/153 [==============================] - 0s 443us/step - loss: 0.3873 - accuracy: 0.8194\n",
      "Epoch 89/100\n",
      "153/153 [==============================] - 0s 440us/step - loss: 0.3859 - accuracy: 0.8137\n",
      "Epoch 90/100\n",
      "153/153 [==============================] - 0s 450us/step - loss: 0.3908 - accuracy: 0.8129\n",
      "Epoch 91/100\n",
      "153/153 [==============================] - 0s 437us/step - loss: 0.3862 - accuracy: 0.8172\n",
      "Epoch 92/100\n",
      "153/153 [==============================] - 0s 430us/step - loss: 0.3886 - accuracy: 0.8153\n",
      "Epoch 93/100\n",
      "153/153 [==============================] - 0s 440us/step - loss: 0.3869 - accuracy: 0.8182\n",
      "Epoch 94/100\n",
      "153/153 [==============================] - 0s 696us/step - loss: 0.3852 - accuracy: 0.8209\n",
      "Epoch 95/100\n",
      "153/153 [==============================] - 0s 443us/step - loss: 0.3871 - accuracy: 0.8172\n",
      "Epoch 96/100\n",
      "153/153 [==============================] - 0s 437us/step - loss: 0.3894 - accuracy: 0.8168\n",
      "Epoch 97/100\n",
      "153/153 [==============================] - 0s 449us/step - loss: 0.3851 - accuracy: 0.8180\n",
      "Epoch 98/100\n",
      "153/153 [==============================] - 0s 436us/step - loss: 0.3869 - accuracy: 0.8166\n",
      "Epoch 99/100\n",
      "153/153 [==============================] - 0s 537us/step - loss: 0.3837 - accuracy: 0.8242\n",
      "Epoch 100/100\n",
      "153/153 [==============================] - 0s 430us/step - loss: 0.3871 - accuracy: 0.8213\n",
      "39/39 [==============================] - 0s 329us/step\n",
      "Epoch 1/100\n",
      "153/153 [==============================] - 0s 485us/step - loss: 0.5863 - accuracy: 0.7190\n",
      "Epoch 2/100\n",
      "153/153 [==============================] - 0s 431us/step - loss: 0.4440 - accuracy: 0.7872\n",
      "Epoch 3/100\n",
      "153/153 [==============================] - 0s 437us/step - loss: 0.4307 - accuracy: 0.7954\n",
      "Epoch 4/100\n",
      "153/153 [==============================] - 0s 437us/step - loss: 0.4266 - accuracy: 0.7960\n",
      "Epoch 5/100\n",
      "153/153 [==============================] - 0s 443us/step - loss: 0.4208 - accuracy: 0.7977\n",
      "Epoch 6/100\n",
      "153/153 [==============================] - 0s 442us/step - loss: 0.4180 - accuracy: 0.8024\n",
      "Epoch 7/100\n",
      "153/153 [==============================] - 0s 449us/step - loss: 0.4182 - accuracy: 0.7979\n",
      "Epoch 8/100\n",
      "153/153 [==============================] - 0s 443us/step - loss: 0.4175 - accuracy: 0.7958\n",
      "Epoch 9/100\n",
      "153/153 [==============================] - 0s 440us/step - loss: 0.4131 - accuracy: 0.8007\n",
      "Epoch 10/100\n",
      "153/153 [==============================] - 0s 427us/step - loss: 0.4184 - accuracy: 0.8016\n",
      "Epoch 11/100\n",
      "153/153 [==============================] - 0s 431us/step - loss: 0.4098 - accuracy: 0.8038\n",
      "Epoch 12/100\n",
      "153/153 [==============================] - 0s 431us/step - loss: 0.4137 - accuracy: 0.7999\n",
      "Epoch 13/100\n",
      "153/153 [==============================] - 0s 438us/step - loss: 0.4093 - accuracy: 0.8036\n",
      "Epoch 14/100\n",
      "153/153 [==============================] - 0s 439us/step - loss: 0.4136 - accuracy: 0.8005\n",
      "Epoch 15/100\n",
      "153/153 [==============================] - 0s 435us/step - loss: 0.4089 - accuracy: 0.8110\n",
      "Epoch 16/100\n",
      "153/153 [==============================] - 0s 453us/step - loss: 0.4048 - accuracy: 0.8085\n",
      "Epoch 17/100\n",
      "153/153 [==============================] - 0s 428us/step - loss: 0.4065 - accuracy: 0.8032\n",
      "Epoch 18/100\n",
      "153/153 [==============================] - 0s 427us/step - loss: 0.4026 - accuracy: 0.8061\n",
      "Epoch 19/100\n",
      "153/153 [==============================] - 0s 439us/step - loss: 0.4021 - accuracy: 0.8094\n",
      "Epoch 20/100\n",
      "153/153 [==============================] - 0s 434us/step - loss: 0.4042 - accuracy: 0.8059\n",
      "Epoch 21/100\n",
      "153/153 [==============================] - 0s 435us/step - loss: 0.4057 - accuracy: 0.8075\n",
      "Epoch 22/100\n",
      "153/153 [==============================] - 0s 433us/step - loss: 0.4056 - accuracy: 0.8061\n",
      "Epoch 23/100\n",
      "153/153 [==============================] - 0s 440us/step - loss: 0.4050 - accuracy: 0.8053\n",
      "Epoch 24/100\n",
      "153/153 [==============================] - 0s 426us/step - loss: 0.4031 - accuracy: 0.8118\n",
      "Epoch 25/100\n",
      "153/153 [==============================] - 0s 436us/step - loss: 0.3994 - accuracy: 0.8090\n",
      "Epoch 26/100\n",
      "153/153 [==============================] - 0s 433us/step - loss: 0.4008 - accuracy: 0.8092\n",
      "Epoch 27/100\n",
      "153/153 [==============================] - 0s 433us/step - loss: 0.4007 - accuracy: 0.8118\n",
      "Epoch 28/100\n",
      "153/153 [==============================] - 0s 468us/step - loss: 0.4021 - accuracy: 0.8079\n",
      "Epoch 29/100\n",
      "153/153 [==============================] - 0s 444us/step - loss: 0.3978 - accuracy: 0.8147\n",
      "Epoch 30/100\n",
      "153/153 [==============================] - 0s 442us/step - loss: 0.3993 - accuracy: 0.8149\n",
      "Epoch 31/100\n",
      "153/153 [==============================] - 0s 701us/step - loss: 0.4041 - accuracy: 0.8122\n",
      "Epoch 32/100\n",
      "153/153 [==============================] - 0s 455us/step - loss: 0.3982 - accuracy: 0.8104\n",
      "Epoch 33/100\n",
      "153/153 [==============================] - 0s 443us/step - loss: 0.3984 - accuracy: 0.8102\n",
      "Epoch 34/100\n",
      "153/153 [==============================] - 0s 453us/step - loss: 0.3938 - accuracy: 0.8188\n",
      "Epoch 35/100\n",
      "153/153 [==============================] - 0s 525us/step - loss: 0.3972 - accuracy: 0.8127\n",
      "Epoch 36/100\n",
      "153/153 [==============================] - 0s 453us/step - loss: 0.3974 - accuracy: 0.8133\n",
      "Epoch 37/100\n",
      "153/153 [==============================] - 0s 431us/step - loss: 0.4010 - accuracy: 0.8112\n",
      "Epoch 38/100\n",
      "153/153 [==============================] - 0s 433us/step - loss: 0.3936 - accuracy: 0.8106\n",
      "Epoch 39/100\n",
      "153/153 [==============================] - 0s 429us/step - loss: 0.3970 - accuracy: 0.8114\n",
      "Epoch 40/100\n",
      "153/153 [==============================] - 0s 429us/step - loss: 0.3952 - accuracy: 0.8139\n",
      "Epoch 41/100\n",
      "153/153 [==============================] - 0s 435us/step - loss: 0.3942 - accuracy: 0.8139\n",
      "Epoch 42/100\n",
      "153/153 [==============================] - 0s 442us/step - loss: 0.3953 - accuracy: 0.8120\n",
      "Epoch 43/100\n",
      "153/153 [==============================] - 0s 439us/step - loss: 0.3954 - accuracy: 0.8139\n",
      "Epoch 44/100\n",
      "153/153 [==============================] - 0s 433us/step - loss: 0.3989 - accuracy: 0.8081\n",
      "Epoch 45/100\n",
      "153/153 [==============================] - 0s 432us/step - loss: 0.3994 - accuracy: 0.8149\n",
      "Epoch 46/100\n",
      "153/153 [==============================] - 0s 433us/step - loss: 0.4022 - accuracy: 0.8129\n",
      "Epoch 47/100\n",
      "153/153 [==============================] - 0s 435us/step - loss: 0.3952 - accuracy: 0.8085\n",
      "Epoch 48/100\n",
      "153/153 [==============================] - 0s 439us/step - loss: 0.3944 - accuracy: 0.8157\n",
      "Epoch 49/100\n",
      "153/153 [==============================] - 0s 449us/step - loss: 0.3988 - accuracy: 0.8149\n",
      "Epoch 50/100\n",
      "153/153 [==============================] - 0s 455us/step - loss: 0.3949 - accuracy: 0.8159\n",
      "Epoch 51/100\n",
      "153/153 [==============================] - 0s 431us/step - loss: 0.3908 - accuracy: 0.8151\n",
      "Epoch 52/100\n",
      "153/153 [==============================] - 0s 456us/step - loss: 0.3930 - accuracy: 0.8168\n",
      "Epoch 53/100\n",
      "153/153 [==============================] - 0s 439us/step - loss: 0.3927 - accuracy: 0.8122\n",
      "Epoch 54/100\n",
      "153/153 [==============================] - 0s 446us/step - loss: 0.3951 - accuracy: 0.8166\n",
      "Epoch 55/100\n",
      "153/153 [==============================] - 0s 434us/step - loss: 0.3946 - accuracy: 0.8147\n",
      "Epoch 56/100\n",
      "153/153 [==============================] - 0s 437us/step - loss: 0.3950 - accuracy: 0.8118\n",
      "Epoch 57/100\n",
      "153/153 [==============================] - 0s 443us/step - loss: 0.3950 - accuracy: 0.8102\n",
      "Epoch 58/100\n",
      "153/153 [==============================] - 0s 445us/step - loss: 0.3908 - accuracy: 0.8157\n",
      "Epoch 59/100\n",
      "153/153 [==============================] - 0s 433us/step - loss: 0.3885 - accuracy: 0.8217\n",
      "Epoch 60/100\n",
      "153/153 [==============================] - 0s 439us/step - loss: 0.3920 - accuracy: 0.8164\n",
      "Epoch 61/100\n",
      "153/153 [==============================] - 0s 431us/step - loss: 0.3961 - accuracy: 0.8143\n",
      "Epoch 62/100\n",
      "153/153 [==============================] - 0s 433us/step - loss: 0.3915 - accuracy: 0.8168\n",
      "Epoch 63/100\n",
      "153/153 [==============================] - 0s 433us/step - loss: 0.3934 - accuracy: 0.8085\n",
      "Epoch 64/100\n",
      "153/153 [==============================] - 0s 686us/step - loss: 0.3933 - accuracy: 0.8164\n",
      "Epoch 65/100\n",
      "153/153 [==============================] - 0s 442us/step - loss: 0.3880 - accuracy: 0.8166\n",
      "Epoch 66/100\n",
      "153/153 [==============================] - 0s 451us/step - loss: 0.3877 - accuracy: 0.8182\n",
      "Epoch 67/100\n",
      "153/153 [==============================] - 0s 438us/step - loss: 0.3912 - accuracy: 0.8170\n",
      "Epoch 68/100\n",
      "153/153 [==============================] - 0s 548us/step - loss: 0.3871 - accuracy: 0.8207\n",
      "Epoch 69/100\n",
      "153/153 [==============================] - 0s 423us/step - loss: 0.3895 - accuracy: 0.8178\n",
      "Epoch 70/100\n",
      "153/153 [==============================] - 0s 452us/step - loss: 0.3915 - accuracy: 0.8149\n",
      "Epoch 71/100\n",
      "153/153 [==============================] - 0s 432us/step - loss: 0.3933 - accuracy: 0.8149\n",
      "Epoch 72/100\n",
      "153/153 [==============================] - 0s 443us/step - loss: 0.3881 - accuracy: 0.8217\n",
      "Epoch 73/100\n",
      "153/153 [==============================] - 0s 432us/step - loss: 0.3938 - accuracy: 0.8192\n",
      "Epoch 74/100\n",
      "153/153 [==============================] - 0s 435us/step - loss: 0.3882 - accuracy: 0.8155\n",
      "Epoch 75/100\n",
      "153/153 [==============================] - 0s 448us/step - loss: 0.3892 - accuracy: 0.8116\n",
      "Epoch 76/100\n",
      "153/153 [==============================] - 0s 441us/step - loss: 0.3948 - accuracy: 0.8151\n",
      "Epoch 77/100\n",
      "153/153 [==============================] - 0s 440us/step - loss: 0.3899 - accuracy: 0.8209\n",
      "Epoch 78/100\n",
      "153/153 [==============================] - 0s 448us/step - loss: 0.3896 - accuracy: 0.8116\n",
      "Epoch 79/100\n",
      "153/153 [==============================] - 0s 444us/step - loss: 0.3860 - accuracy: 0.8186\n",
      "Epoch 80/100\n",
      "153/153 [==============================] - 0s 415us/step - loss: 0.3870 - accuracy: 0.8186\n",
      "Epoch 81/100\n",
      "153/153 [==============================] - 0s 428us/step - loss: 0.3863 - accuracy: 0.8194\n",
      "Epoch 82/100\n",
      "153/153 [==============================] - 0s 443us/step - loss: 0.3863 - accuracy: 0.8207\n",
      "Epoch 83/100\n",
      "153/153 [==============================] - 0s 444us/step - loss: 0.3848 - accuracy: 0.8250\n",
      "Epoch 84/100\n",
      "153/153 [==============================] - 0s 452us/step - loss: 0.3851 - accuracy: 0.8190\n",
      "Epoch 85/100\n",
      "153/153 [==============================] - 0s 443us/step - loss: 0.3846 - accuracy: 0.8188\n",
      "Epoch 86/100\n",
      "153/153 [==============================] - 0s 464us/step - loss: 0.3871 - accuracy: 0.8200\n",
      "Epoch 87/100\n",
      "153/153 [==============================] - 0s 447us/step - loss: 0.3894 - accuracy: 0.8205\n",
      "Epoch 88/100\n",
      "153/153 [==============================] - 0s 449us/step - loss: 0.3910 - accuracy: 0.8178\n",
      "Epoch 89/100\n",
      "153/153 [==============================] - 0s 451us/step - loss: 0.3881 - accuracy: 0.8159\n",
      "Epoch 90/100\n",
      "153/153 [==============================] - 0s 456us/step - loss: 0.3884 - accuracy: 0.8166\n",
      "Epoch 91/100\n",
      "153/153 [==============================] - 0s 452us/step - loss: 0.3867 - accuracy: 0.8205\n",
      "Epoch 92/100\n",
      "153/153 [==============================] - 0s 465us/step - loss: 0.3855 - accuracy: 0.8203\n",
      "Epoch 93/100\n",
      "153/153 [==============================] - 0s 436us/step - loss: 0.3866 - accuracy: 0.8149\n",
      "Epoch 94/100\n",
      "153/153 [==============================] - 0s 439us/step - loss: 0.3857 - accuracy: 0.8219\n",
      "Epoch 95/100\n",
      "153/153 [==============================] - 0s 416us/step - loss: 0.3909 - accuracy: 0.8182\n",
      "Epoch 96/100\n",
      "153/153 [==============================] - 0s 450us/step - loss: 0.3869 - accuracy: 0.8159\n",
      "Epoch 97/100\n",
      "153/153 [==============================] - 0s 441us/step - loss: 0.3874 - accuracy: 0.8172\n",
      "Epoch 98/100\n",
      "153/153 [==============================] - 0s 430us/step - loss: 0.3880 - accuracy: 0.8178\n",
      "Epoch 99/100\n",
      "153/153 [==============================] - 0s 436us/step - loss: 0.3830 - accuracy: 0.8244\n",
      "Epoch 100/100\n",
      "153/153 [==============================] - 0s 724us/step - loss: 0.3875 - accuracy: 0.8205\n",
      "39/39 [==============================] - 0s 334us/step\n",
      "Epoch 1/100\n",
      "153/153 [==============================] - 0s 483us/step - loss: 0.6001 - accuracy: 0.6882\n",
      "Epoch 2/100\n",
      "153/153 [==============================] - 0s 438us/step - loss: 0.4491 - accuracy: 0.7886\n",
      "Epoch 3/100\n",
      "153/153 [==============================] - 0s 440us/step - loss: 0.4376 - accuracy: 0.7925\n",
      "Epoch 4/100\n",
      "153/153 [==============================] - 0s 443us/step - loss: 0.4268 - accuracy: 0.7989\n",
      "Epoch 5/100\n",
      "153/153 [==============================] - 0s 445us/step - loss: 0.4268 - accuracy: 0.7979\n",
      "Epoch 6/100\n",
      "153/153 [==============================] - 0s 437us/step - loss: 0.4264 - accuracy: 0.7979\n",
      "Epoch 7/100\n",
      "153/153 [==============================] - 0s 428us/step - loss: 0.4191 - accuracy: 0.8026\n",
      "Epoch 8/100\n",
      "153/153 [==============================] - 0s 439us/step - loss: 0.4219 - accuracy: 0.8001\n",
      "Epoch 9/100\n",
      "153/153 [==============================] - 0s 450us/step - loss: 0.4205 - accuracy: 0.7989\n",
      "Epoch 10/100\n",
      "153/153 [==============================] - 0s 440us/step - loss: 0.4181 - accuracy: 0.8063\n",
      "Epoch 11/100\n",
      "153/153 [==============================] - 0s 440us/step - loss: 0.4186 - accuracy: 0.8012\n",
      "Epoch 12/100\n",
      "153/153 [==============================] - 0s 438us/step - loss: 0.4172 - accuracy: 0.8075\n",
      "Epoch 13/100\n",
      "153/153 [==============================] - 0s 446us/step - loss: 0.4171 - accuracy: 0.8003\n",
      "Epoch 14/100\n",
      "153/153 [==============================] - 0s 433us/step - loss: 0.4143 - accuracy: 0.8088\n",
      "Epoch 15/100\n",
      "153/153 [==============================] - 0s 446us/step - loss: 0.4113 - accuracy: 0.8061\n",
      "Epoch 16/100\n",
      "153/153 [==============================] - 0s 427us/step - loss: 0.4111 - accuracy: 0.8081\n",
      "Epoch 17/100\n",
      "153/153 [==============================] - 0s 654us/step - loss: 0.4127 - accuracy: 0.8061\n",
      "Epoch 18/100\n",
      "153/153 [==============================] - 0s 443us/step - loss: 0.4073 - accuracy: 0.8110\n",
      "Epoch 19/100\n",
      "153/153 [==============================] - 0s 437us/step - loss: 0.4068 - accuracy: 0.8081\n",
      "Epoch 20/100\n",
      "153/153 [==============================] - 0s 438us/step - loss: 0.4080 - accuracy: 0.8059\n",
      "Epoch 21/100\n",
      "153/153 [==============================] - 0s 432us/step - loss: 0.4148 - accuracy: 0.8020\n",
      "Epoch 22/100\n",
      "153/153 [==============================] - 0s 446us/step - loss: 0.4071 - accuracy: 0.8081\n",
      "Epoch 23/100\n",
      "153/153 [==============================] - 0s 433us/step - loss: 0.4073 - accuracy: 0.8075\n",
      "Epoch 24/100\n",
      "153/153 [==============================] - 0s 430us/step - loss: 0.4102 - accuracy: 0.8005\n",
      "Epoch 25/100\n",
      "153/153 [==============================] - 0s 429us/step - loss: 0.4046 - accuracy: 0.8141\n",
      "Epoch 26/100\n",
      "153/153 [==============================] - 0s 681us/step - loss: 0.4037 - accuracy: 0.8083\n",
      "Epoch 27/100\n",
      "153/153 [==============================] - 0s 439us/step - loss: 0.4069 - accuracy: 0.8088\n",
      "Epoch 28/100\n",
      "153/153 [==============================] - 0s 452us/step - loss: 0.4025 - accuracy: 0.8106\n",
      "Epoch 29/100\n",
      "153/153 [==============================] - 0s 449us/step - loss: 0.4027 - accuracy: 0.8073\n",
      "Epoch 30/100\n",
      "153/153 [==============================] - 0s 471us/step - loss: 0.4023 - accuracy: 0.8094\n",
      "Epoch 31/100\n",
      "153/153 [==============================] - 0s 535us/step - loss: 0.4019 - accuracy: 0.8131\n",
      "Epoch 32/100\n",
      "153/153 [==============================] - 0s 435us/step - loss: 0.4014 - accuracy: 0.8098\n",
      "Epoch 33/100\n",
      "153/153 [==============================] - 0s 433us/step - loss: 0.4013 - accuracy: 0.8096\n",
      "Epoch 34/100\n",
      "153/153 [==============================] - 0s 442us/step - loss: 0.4005 - accuracy: 0.8137\n",
      "Epoch 35/100\n",
      "153/153 [==============================] - 0s 427us/step - loss: 0.4027 - accuracy: 0.8077\n",
      "Epoch 36/100\n",
      "153/153 [==============================] - 0s 438us/step - loss: 0.3934 - accuracy: 0.8182\n",
      "Epoch 37/100\n",
      "153/153 [==============================] - 0s 437us/step - loss: 0.4004 - accuracy: 0.8102\n",
      "Epoch 38/100\n",
      "153/153 [==============================] - 0s 439us/step - loss: 0.3989 - accuracy: 0.8122\n",
      "Epoch 39/100\n",
      "153/153 [==============================] - 0s 427us/step - loss: 0.4034 - accuracy: 0.8088\n",
      "Epoch 40/100\n",
      "153/153 [==============================] - 0s 441us/step - loss: 0.4039 - accuracy: 0.8051\n",
      "Epoch 41/100\n",
      "153/153 [==============================] - 0s 577us/step - loss: 0.3994 - accuracy: 0.8149\n",
      "Epoch 42/100\n",
      "153/153 [==============================] - 0s 451us/step - loss: 0.3954 - accuracy: 0.8106\n",
      "Epoch 43/100\n",
      "153/153 [==============================] - 0s 460us/step - loss: 0.3986 - accuracy: 0.8090\n",
      "Epoch 44/100\n",
      "153/153 [==============================] - 0s 437us/step - loss: 0.4019 - accuracy: 0.8092\n",
      "Epoch 45/100\n",
      "153/153 [==============================] - 0s 439us/step - loss: 0.3974 - accuracy: 0.8114\n",
      "Epoch 46/100\n",
      "153/153 [==============================] - 0s 562us/step - loss: 0.3994 - accuracy: 0.8065\n",
      "Epoch 47/100\n",
      "153/153 [==============================] - 0s 439us/step - loss: 0.3986 - accuracy: 0.8092\n",
      "Epoch 48/100\n",
      "153/153 [==============================] - 0s 429us/step - loss: 0.3973 - accuracy: 0.8114\n",
      "Epoch 49/100\n",
      "153/153 [==============================] - 0s 490us/step - loss: 0.4023 - accuracy: 0.8108\n",
      "Epoch 50/100\n",
      "153/153 [==============================] - 0s 407us/step - loss: 0.3958 - accuracy: 0.8131\n",
      "Epoch 51/100\n",
      "153/153 [==============================] - 0s 453us/step - loss: 0.3992 - accuracy: 0.8102\n",
      "Epoch 52/100\n",
      "153/153 [==============================] - 0s 865us/step - loss: 0.3925 - accuracy: 0.8161\n",
      "Epoch 53/100\n",
      "153/153 [==============================] - 0s 532us/step - loss: 0.3971 - accuracy: 0.8104\n",
      "Epoch 54/100\n",
      "153/153 [==============================] - 0s 485us/step - loss: 0.3967 - accuracy: 0.8079\n",
      "Epoch 55/100\n",
      "153/153 [==============================] - 0s 480us/step - loss: 0.3972 - accuracy: 0.8131\n",
      "Epoch 56/100\n",
      "153/153 [==============================] - 0s 479us/step - loss: 0.3989 - accuracy: 0.8108\n",
      "Epoch 57/100\n",
      "153/153 [==============================] - 0s 450us/step - loss: 0.3968 - accuracy: 0.8137\n",
      "Epoch 58/100\n",
      "153/153 [==============================] - 0s 428us/step - loss: 0.3962 - accuracy: 0.8145\n",
      "Epoch 59/100\n",
      "153/153 [==============================] - 0s 453us/step - loss: 0.3955 - accuracy: 0.8159\n",
      "Epoch 60/100\n",
      "153/153 [==============================] - 0s 951us/step - loss: 0.3942 - accuracy: 0.8139\n",
      "Epoch 61/100\n",
      "153/153 [==============================] - 0s 452us/step - loss: 0.3998 - accuracy: 0.8096\n",
      "Epoch 62/100\n",
      "153/153 [==============================] - 0s 447us/step - loss: 0.3970 - accuracy: 0.8100\n",
      "Epoch 63/100\n",
      "153/153 [==============================] - 0s 462us/step - loss: 0.3928 - accuracy: 0.8155\n",
      "Epoch 64/100\n",
      "153/153 [==============================] - 0s 560us/step - loss: 0.3937 - accuracy: 0.8147\n",
      "Epoch 65/100\n",
      "153/153 [==============================] - 0s 437us/step - loss: 0.4023 - accuracy: 0.8098\n",
      "Epoch 66/100\n",
      "153/153 [==============================] - 0s 428us/step - loss: 0.3928 - accuracy: 0.8170\n",
      "Epoch 67/100\n",
      "153/153 [==============================] - 0s 471us/step - loss: 0.3969 - accuracy: 0.8108\n",
      "Epoch 68/100\n",
      "153/153 [==============================] - 0s 437us/step - loss: 0.3888 - accuracy: 0.8157\n",
      "Epoch 69/100\n",
      "153/153 [==============================] - 0s 452us/step - loss: 0.3952 - accuracy: 0.8092\n",
      "Epoch 70/100\n",
      "153/153 [==============================] - 0s 508us/step - loss: 0.3904 - accuracy: 0.8153\n",
      "Epoch 71/100\n",
      "153/153 [==============================] - 0s 667us/step - loss: 0.3927 - accuracy: 0.8174\n",
      "Epoch 72/100\n",
      "153/153 [==============================] - 0s 504us/step - loss: 0.3983 - accuracy: 0.8141\n",
      "Epoch 73/100\n",
      "153/153 [==============================] - 0s 474us/step - loss: 0.3900 - accuracy: 0.8137\n",
      "Epoch 74/100\n",
      "153/153 [==============================] - 0s 463us/step - loss: 0.3946 - accuracy: 0.8151\n",
      "Epoch 75/100\n",
      "153/153 [==============================] - 0s 443us/step - loss: 0.3935 - accuracy: 0.8108\n",
      "Epoch 76/100\n",
      "153/153 [==============================] - 0s 1ms/step - loss: 0.3890 - accuracy: 0.8145\n",
      "Epoch 77/100\n",
      "153/153 [==============================] - 0s 564us/step - loss: 0.3918 - accuracy: 0.8168\n",
      "Epoch 78/100\n",
      "153/153 [==============================] - 0s 529us/step - loss: 0.3896 - accuracy: 0.8161\n",
      "Epoch 79/100\n",
      "153/153 [==============================] - 0s 463us/step - loss: 0.3914 - accuracy: 0.8155\n",
      "Epoch 80/100\n",
      "153/153 [==============================] - 0s 471us/step - loss: 0.3873 - accuracy: 0.8188\n",
      "Epoch 81/100\n",
      "153/153 [==============================] - 0s 436us/step - loss: 0.3911 - accuracy: 0.8135\n",
      "Epoch 82/100\n",
      "153/153 [==============================] - 0s 435us/step - loss: 0.3902 - accuracy: 0.8166\n",
      "Epoch 83/100\n",
      "153/153 [==============================] - 0s 448us/step - loss: 0.3896 - accuracy: 0.8170\n",
      "Epoch 84/100\n",
      "153/153 [==============================] - 0s 486us/step - loss: 0.3909 - accuracy: 0.8192\n",
      "Epoch 85/100\n",
      "153/153 [==============================] - 0s 454us/step - loss: 0.3894 - accuracy: 0.8133\n",
      "Epoch 86/100\n",
      "153/153 [==============================] - 0s 462us/step - loss: 0.3899 - accuracy: 0.8096\n",
      "Epoch 87/100\n",
      "153/153 [==============================] - 0s 449us/step - loss: 0.3897 - accuracy: 0.8207\n",
      "Epoch 88/100\n",
      "153/153 [==============================] - 0s 437us/step - loss: 0.3922 - accuracy: 0.8153\n",
      "Epoch 89/100\n",
      "153/153 [==============================] - 0s 547us/step - loss: 0.3876 - accuracy: 0.8176\n",
      "Epoch 90/100\n",
      "153/153 [==============================] - 0s 452us/step - loss: 0.3879 - accuracy: 0.8153\n",
      "Epoch 91/100\n",
      "153/153 [==============================] - 0s 443us/step - loss: 0.3917 - accuracy: 0.8141\n",
      "Epoch 92/100\n",
      "153/153 [==============================] - 0s 429us/step - loss: 0.3908 - accuracy: 0.8137\n",
      "Epoch 93/100\n",
      "153/153 [==============================] - 0s 906us/step - loss: 0.3921 - accuracy: 0.8129\n",
      "Epoch 94/100\n",
      "153/153 [==============================] - 0s 526us/step - loss: 0.3928 - accuracy: 0.8120\n",
      "Epoch 95/100\n",
      "153/153 [==============================] - 0s 467us/step - loss: 0.3906 - accuracy: 0.8188\n",
      "Epoch 96/100\n",
      "153/153 [==============================] - 0s 452us/step - loss: 0.3937 - accuracy: 0.8184\n",
      "Epoch 97/100\n",
      "153/153 [==============================] - 0s 577us/step - loss: 0.3890 - accuracy: 0.8172\n",
      "Epoch 98/100\n",
      "153/153 [==============================] - 0s 454us/step - loss: 0.3951 - accuracy: 0.8155\n",
      "Epoch 99/100\n",
      "153/153 [==============================] - 0s 443us/step - loss: 0.3885 - accuracy: 0.8198\n",
      "Epoch 100/100\n",
      "153/153 [==============================] - 0s 482us/step - loss: 0.3880 - accuracy: 0.8157\n",
      "39/39 [==============================] - 0s 375us/step\n",
      "Epoch 1/100\n",
      "153/153 [==============================] - 0s 488us/step - loss: 0.5827 - accuracy: 0.7159\n",
      "Epoch 2/100\n",
      "153/153 [==============================] - 0s 453us/step - loss: 0.4474 - accuracy: 0.7874\n",
      "Epoch 3/100\n",
      "153/153 [==============================] - 0s 480us/step - loss: 0.4343 - accuracy: 0.7892\n",
      "Epoch 4/100\n",
      "153/153 [==============================] - 0s 443us/step - loss: 0.4290 - accuracy: 0.7935\n",
      "Epoch 5/100\n",
      "153/153 [==============================] - 0s 451us/step - loss: 0.4252 - accuracy: 0.7938\n",
      "Epoch 6/100\n",
      "153/153 [==============================] - 0s 445us/step - loss: 0.4248 - accuracy: 0.7975\n",
      "Epoch 7/100\n",
      "153/153 [==============================] - 0s 449us/step - loss: 0.4249 - accuracy: 0.7970\n",
      "Epoch 8/100\n",
      "153/153 [==============================] - 0s 452us/step - loss: 0.4195 - accuracy: 0.7950\n",
      "Epoch 9/100\n",
      "153/153 [==============================] - 0s 439us/step - loss: 0.4201 - accuracy: 0.7942\n",
      "Epoch 10/100\n",
      "153/153 [==============================] - 0s 441us/step - loss: 0.4179 - accuracy: 0.7964\n",
      "Epoch 11/100\n",
      "153/153 [==============================] - 0s 431us/step - loss: 0.4186 - accuracy: 0.8020\n",
      "Epoch 12/100\n",
      "153/153 [==============================] - 0s 445us/step - loss: 0.4204 - accuracy: 0.8030\n",
      "Epoch 13/100\n",
      "153/153 [==============================] - 0s 439us/step - loss: 0.4152 - accuracy: 0.8016\n",
      "Epoch 14/100\n",
      "153/153 [==============================] - 0s 444us/step - loss: 0.4146 - accuracy: 0.8036\n",
      "Epoch 15/100\n",
      "153/153 [==============================] - 0s 435us/step - loss: 0.4172 - accuracy: 0.8012\n",
      "Epoch 16/100\n",
      "153/153 [==============================] - 0s 442us/step - loss: 0.4126 - accuracy: 0.8036\n",
      "Epoch 17/100\n",
      "153/153 [==============================] - 0s 430us/step - loss: 0.4118 - accuracy: 0.8046\n",
      "Epoch 18/100\n",
      "153/153 [==============================] - 0s 436us/step - loss: 0.4134 - accuracy: 0.8009\n",
      "Epoch 19/100\n",
      "153/153 [==============================] - 0s 444us/step - loss: 0.4097 - accuracy: 0.8022\n",
      "Epoch 20/100\n",
      "153/153 [==============================] - 0s 704us/step - loss: 0.4120 - accuracy: 0.8026\n",
      "Epoch 21/100\n",
      "153/153 [==============================] - 0s 444us/step - loss: 0.4114 - accuracy: 0.8055\n",
      "Epoch 22/100\n",
      "153/153 [==============================] - 0s 441us/step - loss: 0.4132 - accuracy: 0.7966\n",
      "Epoch 23/100\n",
      "153/153 [==============================] - 0s 440us/step - loss: 0.4137 - accuracy: 0.7954\n",
      "Epoch 24/100\n",
      "153/153 [==============================] - 0s 473us/step - loss: 0.4069 - accuracy: 0.8057\n",
      "Epoch 25/100\n",
      "153/153 [==============================] - 0s 528us/step - loss: 0.4056 - accuracy: 0.8053\n",
      "Epoch 26/100\n",
      "153/153 [==============================] - 0s 435us/step - loss: 0.4094 - accuracy: 0.8014\n",
      "Epoch 27/100\n",
      "153/153 [==============================] - 0s 436us/step - loss: 0.4090 - accuracy: 0.8026\n",
      "Epoch 28/100\n",
      "153/153 [==============================] - 0s 453us/step - loss: 0.4037 - accuracy: 0.8094\n",
      "Epoch 29/100\n",
      "153/153 [==============================] - 0s 431us/step - loss: 0.4068 - accuracy: 0.8020\n",
      "Epoch 30/100\n",
      "153/153 [==============================] - 0s 442us/step - loss: 0.4088 - accuracy: 0.8061\n",
      "Epoch 31/100\n",
      "153/153 [==============================] - 0s 429us/step - loss: 0.4050 - accuracy: 0.8075\n",
      "Epoch 32/100\n",
      "153/153 [==============================] - 0s 453us/step - loss: 0.4065 - accuracy: 0.8046\n",
      "Epoch 33/100\n",
      "153/153 [==============================] - 0s 429us/step - loss: 0.4013 - accuracy: 0.8110\n",
      "Epoch 34/100\n",
      "153/153 [==============================] - 0s 435us/step - loss: 0.4023 - accuracy: 0.8053\n",
      "Epoch 35/100\n",
      "153/153 [==============================] - 0s 434us/step - loss: 0.4049 - accuracy: 0.8001\n",
      "Epoch 36/100\n",
      "153/153 [==============================] - 0s 441us/step - loss: 0.4068 - accuracy: 0.8063\n",
      "Epoch 37/100\n",
      "153/153 [==============================] - 0s 435us/step - loss: 0.4020 - accuracy: 0.8051\n",
      "Epoch 38/100\n",
      "153/153 [==============================] - 0s 435us/step - loss: 0.4084 - accuracy: 0.8059\n",
      "Epoch 39/100\n",
      "153/153 [==============================] - 0s 457us/step - loss: 0.4054 - accuracy: 0.8022\n",
      "Epoch 40/100\n",
      "153/153 [==============================] - 0s 440us/step - loss: 0.4030 - accuracy: 0.8030\n",
      "Epoch 41/100\n",
      "153/153 [==============================] - 0s 446us/step - loss: 0.4000 - accuracy: 0.8116\n",
      "Epoch 42/100\n",
      "153/153 [==============================] - 0s 439us/step - loss: 0.3952 - accuracy: 0.8090\n",
      "Epoch 43/100\n",
      "153/153 [==============================] - 0s 431us/step - loss: 0.4018 - accuracy: 0.8055\n",
      "Epoch 44/100\n",
      "153/153 [==============================] - 0s 425us/step - loss: 0.4006 - accuracy: 0.8059\n",
      "Epoch 45/100\n",
      "153/153 [==============================] - 0s 447us/step - loss: 0.3997 - accuracy: 0.8100\n",
      "Epoch 46/100\n",
      "153/153 [==============================] - 0s 475us/step - loss: 0.3986 - accuracy: 0.8061\n",
      "Epoch 47/100\n",
      "153/153 [==============================] - 0s 450us/step - loss: 0.3976 - accuracy: 0.8081\n",
      "Epoch 48/100\n",
      "153/153 [==============================] - 0s 436us/step - loss: 0.4020 - accuracy: 0.8040\n",
      "Epoch 49/100\n",
      "153/153 [==============================] - 0s 432us/step - loss: 0.3969 - accuracy: 0.8110\n",
      "Epoch 50/100\n",
      "153/153 [==============================] - 0s 434us/step - loss: 0.3971 - accuracy: 0.8055\n",
      "Epoch 51/100\n",
      "153/153 [==============================] - 0s 463us/step - loss: 0.3946 - accuracy: 0.8096\n",
      "Epoch 52/100\n",
      "153/153 [==============================] - 0s 435us/step - loss: 0.4033 - accuracy: 0.8024\n",
      "Epoch 53/100\n",
      "153/153 [==============================] - 0s 439us/step - loss: 0.3972 - accuracy: 0.8044\n",
      "Epoch 54/100\n",
      "153/153 [==============================] - 0s 437us/step - loss: 0.4005 - accuracy: 0.8075\n",
      "Epoch 55/100\n",
      "153/153 [==============================] - 0s 441us/step - loss: 0.3995 - accuracy: 0.8069\n",
      "Epoch 56/100\n",
      "153/153 [==============================] - 0s 428us/step - loss: 0.3990 - accuracy: 0.8077\n",
      "Epoch 57/100\n",
      "153/153 [==============================] - 0s 842us/step - loss: 0.3993 - accuracy: 0.8129\n",
      "Epoch 58/100\n",
      "153/153 [==============================] - 0s 432us/step - loss: 0.3976 - accuracy: 0.8044\n",
      "Epoch 59/100\n",
      "153/153 [==============================] - 0s 460us/step - loss: 0.3969 - accuracy: 0.8067\n",
      "Epoch 60/100\n",
      "153/153 [==============================] - 0s 451us/step - loss: 0.3997 - accuracy: 0.8090\n",
      "Epoch 61/100\n",
      "153/153 [==============================] - 0s 591us/step - loss: 0.3974 - accuracy: 0.8077\n",
      "Epoch 62/100\n",
      "153/153 [==============================] - 0s 465us/step - loss: 0.3973 - accuracy: 0.8092\n",
      "Epoch 63/100\n",
      "153/153 [==============================] - 0s 437us/step - loss: 0.3978 - accuracy: 0.8104\n",
      "Epoch 64/100\n",
      "153/153 [==============================] - 0s 444us/step - loss: 0.3999 - accuracy: 0.8094\n",
      "Epoch 65/100\n",
      "153/153 [==============================] - 0s 445us/step - loss: 0.3949 - accuracy: 0.8124\n",
      "Epoch 66/100\n",
      "153/153 [==============================] - 0s 438us/step - loss: 0.3989 - accuracy: 0.8065\n",
      "Epoch 67/100\n",
      "153/153 [==============================] - 0s 472us/step - loss: 0.3988 - accuracy: 0.8108\n",
      "Epoch 68/100\n",
      "153/153 [==============================] - 0s 448us/step - loss: 0.3948 - accuracy: 0.8106\n",
      "Epoch 69/100\n",
      "153/153 [==============================] - 0s 441us/step - loss: 0.3943 - accuracy: 0.8139\n",
      "Epoch 70/100\n",
      "153/153 [==============================] - 0s 433us/step - loss: 0.3972 - accuracy: 0.8079\n",
      "Epoch 71/100\n",
      "153/153 [==============================] - 0s 509us/step - loss: 0.3964 - accuracy: 0.8096\n",
      "Epoch 72/100\n",
      "153/153 [==============================] - 0s 465us/step - loss: 0.3958 - accuracy: 0.8110\n",
      "Epoch 73/100\n",
      "153/153 [==============================] - 0s 459us/step - loss: 0.3967 - accuracy: 0.8053\n",
      "Epoch 74/100\n",
      "153/153 [==============================] - 0s 445us/step - loss: 0.4012 - accuracy: 0.8018\n",
      "Epoch 75/100\n",
      "153/153 [==============================] - 0s 444us/step - loss: 0.3939 - accuracy: 0.8083\n",
      "Epoch 76/100\n",
      "153/153 [==============================] - 0s 437us/step - loss: 0.3920 - accuracy: 0.8106\n",
      "Epoch 77/100\n",
      "153/153 [==============================] - 0s 452us/step - loss: 0.3958 - accuracy: 0.8096\n",
      "Epoch 78/100\n",
      "153/153 [==============================] - 0s 435us/step - loss: 0.3994 - accuracy: 0.8092\n",
      "Epoch 79/100\n",
      "153/153 [==============================] - 0s 428us/step - loss: 0.3933 - accuracy: 0.8120\n",
      "Epoch 80/100\n",
      "153/153 [==============================] - 0s 441us/step - loss: 0.3936 - accuracy: 0.8081\n",
      "Epoch 81/100\n",
      "153/153 [==============================] - 0s 442us/step - loss: 0.3945 - accuracy: 0.8077\n",
      "Epoch 82/100\n",
      "153/153 [==============================] - 0s 445us/step - loss: 0.3948 - accuracy: 0.8114\n",
      "Epoch 83/100\n",
      "153/153 [==============================] - 0s 445us/step - loss: 0.3874 - accuracy: 0.8166\n",
      "Epoch 84/100\n",
      "153/153 [==============================] - 0s 480us/step - loss: 0.3986 - accuracy: 0.8129\n",
      "Epoch 85/100\n",
      "153/153 [==============================] - 0s 445us/step - loss: 0.3956 - accuracy: 0.8088\n",
      "Epoch 86/100\n",
      "153/153 [==============================] - 0s 441us/step - loss: 0.3927 - accuracy: 0.8100\n",
      "Epoch 87/100\n",
      "153/153 [==============================] - 0s 456us/step - loss: 0.3970 - accuracy: 0.8071\n",
      "Epoch 88/100\n",
      "153/153 [==============================] - 0s 478us/step - loss: 0.3921 - accuracy: 0.8149\n",
      "Epoch 89/100\n",
      "153/153 [==============================] - 0s 775us/step - loss: 0.3964 - accuracy: 0.8092\n",
      "Epoch 90/100\n",
      "153/153 [==============================] - 0s 455us/step - loss: 0.3914 - accuracy: 0.8096\n",
      "Epoch 91/100\n",
      "153/153 [==============================] - 0s 479us/step - loss: 0.3937 - accuracy: 0.8094\n",
      "Epoch 92/100\n",
      "153/153 [==============================] - 0s 458us/step - loss: 0.3923 - accuracy: 0.8114\n",
      "Epoch 93/100\n",
      "153/153 [==============================] - 0s 706us/step - loss: 0.3939 - accuracy: 0.8081\n",
      "Epoch 94/100\n",
      "153/153 [==============================] - 0s 656us/step - loss: 0.3901 - accuracy: 0.8143\n",
      "Epoch 95/100\n",
      "153/153 [==============================] - 0s 654us/step - loss: 0.3941 - accuracy: 0.8090\n",
      "Epoch 96/100\n",
      "153/153 [==============================] - 0s 442us/step - loss: 0.3914 - accuracy: 0.8102\n",
      "Epoch 97/100\n",
      "153/153 [==============================] - 0s 474us/step - loss: 0.3894 - accuracy: 0.8122\n",
      "Epoch 98/100\n",
      "153/153 [==============================] - 0s 453us/step - loss: 0.3894 - accuracy: 0.8153\n",
      "Epoch 99/100\n",
      "153/153 [==============================] - 0s 445us/step - loss: 0.3921 - accuracy: 0.8141\n",
      "Epoch 100/100\n",
      "153/153 [==============================] - 0s 561us/step - loss: 0.3905 - accuracy: 0.8188\n",
      "39/39 [==============================] - 0s 337us/step\n",
      "Epoch 1/100\n",
      "153/153 [==============================] - 0s 553us/step - loss: 0.5824 - accuracy: 0.6995\n",
      "Epoch 2/100\n",
      "153/153 [==============================] - 0s 752us/step - loss: 0.4633 - accuracy: 0.7685\n",
      "Epoch 3/100\n",
      "153/153 [==============================] - 0s 451us/step - loss: 0.4484 - accuracy: 0.7853\n",
      "Epoch 4/100\n",
      "153/153 [==============================] - 0s 589us/step - loss: 0.4470 - accuracy: 0.7876\n",
      "Epoch 5/100\n",
      "153/153 [==============================] - 0s 486us/step - loss: 0.4414 - accuracy: 0.7866\n",
      "Epoch 6/100\n",
      "153/153 [==============================] - 0s 463us/step - loss: 0.4386 - accuracy: 0.7882\n",
      "Epoch 7/100\n",
      "153/153 [==============================] - 0s 464us/step - loss: 0.4360 - accuracy: 0.7919\n",
      "Epoch 8/100\n",
      "153/153 [==============================] - 0s 460us/step - loss: 0.4343 - accuracy: 0.7919\n",
      "Epoch 9/100\n",
      "153/153 [==============================] - 0s 481us/step - loss: 0.4378 - accuracy: 0.7907\n",
      "Epoch 10/100\n",
      "153/153 [==============================] - 0s 489us/step - loss: 0.4323 - accuracy: 0.7923\n",
      "Epoch 11/100\n",
      "153/153 [==============================] - 0s 472us/step - loss: 0.4324 - accuracy: 0.7894\n",
      "Epoch 12/100\n",
      "153/153 [==============================] - 0s 466us/step - loss: 0.4288 - accuracy: 0.7946\n",
      "Epoch 13/100\n",
      "153/153 [==============================] - 0s 454us/step - loss: 0.4259 - accuracy: 0.8016\n",
      "Epoch 14/100\n",
      "153/153 [==============================] - 0s 440us/step - loss: 0.4273 - accuracy: 0.7970\n",
      "Epoch 15/100\n",
      "153/153 [==============================] - 0s 450us/step - loss: 0.4275 - accuracy: 0.7935\n",
      "Epoch 16/100\n",
      "153/153 [==============================] - 0s 446us/step - loss: 0.4258 - accuracy: 0.7911\n",
      "Epoch 17/100\n",
      "153/153 [==============================] - 0s 922us/step - loss: 0.4259 - accuracy: 0.7944\n",
      "Epoch 18/100\n",
      "153/153 [==============================] - 0s 420us/step - loss: 0.4208 - accuracy: 0.8007\n",
      "Epoch 19/100\n",
      "153/153 [==============================] - 0s 425us/step - loss: 0.4276 - accuracy: 0.7995\n",
      "Epoch 20/100\n",
      "153/153 [==============================] - 0s 451us/step - loss: 0.4234 - accuracy: 0.7975\n",
      "Epoch 21/100\n",
      "153/153 [==============================] - 0s 590us/step - loss: 0.4240 - accuracy: 0.7942\n",
      "Epoch 22/100\n",
      "153/153 [==============================] - 0s 494us/step - loss: 0.4219 - accuracy: 0.7964\n",
      "Epoch 23/100\n",
      "153/153 [==============================] - 0s 449us/step - loss: 0.4193 - accuracy: 0.7970\n",
      "Epoch 24/100\n",
      "153/153 [==============================] - 0s 421us/step - loss: 0.4174 - accuracy: 0.8046\n",
      "Epoch 25/100\n",
      "153/153 [==============================] - 0s 413us/step - loss: 0.4180 - accuracy: 0.8018\n",
      "Epoch 26/100\n",
      "153/153 [==============================] - 0s 408us/step - loss: 0.4191 - accuracy: 0.8009\n",
      "Epoch 27/100\n",
      "153/153 [==============================] - 0s 455us/step - loss: 0.4149 - accuracy: 0.8007\n",
      "Epoch 28/100\n",
      "153/153 [==============================] - 0s 452us/step - loss: 0.4175 - accuracy: 0.7995\n",
      "Epoch 29/100\n",
      "153/153 [==============================] - 0s 453us/step - loss: 0.4149 - accuracy: 0.8040\n",
      "Epoch 30/100\n",
      "153/153 [==============================] - 0s 442us/step - loss: 0.4169 - accuracy: 0.7962\n",
      "Epoch 31/100\n",
      "153/153 [==============================] - 0s 461us/step - loss: 0.4139 - accuracy: 0.8012\n",
      "Epoch 32/100\n",
      "153/153 [==============================] - 0s 481us/step - loss: 0.4142 - accuracy: 0.8003\n",
      "Epoch 33/100\n",
      "153/153 [==============================] - 0s 578us/step - loss: 0.4144 - accuracy: 0.8067\n",
      "Epoch 34/100\n",
      "153/153 [==============================] - 0s 554us/step - loss: 0.4110 - accuracy: 0.8042\n",
      "Epoch 35/100\n",
      "153/153 [==============================] - 0s 458us/step - loss: 0.4117 - accuracy: 0.8051\n",
      "Epoch 36/100\n",
      "153/153 [==============================] - 0s 498us/step - loss: 0.4128 - accuracy: 0.8003\n",
      "Epoch 37/100\n",
      "153/153 [==============================] - 0s 418us/step - loss: 0.4132 - accuracy: 0.8016\n",
      "Epoch 38/100\n",
      "153/153 [==============================] - 0s 454us/step - loss: 0.4110 - accuracy: 0.8069\n",
      "Epoch 39/100\n",
      "153/153 [==============================] - 0s 544us/step - loss: 0.4105 - accuracy: 0.8026\n",
      "Epoch 40/100\n",
      "153/153 [==============================] - 0s 443us/step - loss: 0.4078 - accuracy: 0.8059\n",
      "Epoch 41/100\n",
      "153/153 [==============================] - 0s 529us/step - loss: 0.4103 - accuracy: 0.8048\n",
      "Epoch 42/100\n",
      "153/153 [==============================] - 0s 459us/step - loss: 0.4040 - accuracy: 0.8063\n",
      "Epoch 43/100\n",
      "153/153 [==============================] - 0s 529us/step - loss: 0.4108 - accuracy: 0.8009\n",
      "Epoch 44/100\n",
      "153/153 [==============================] - 0s 445us/step - loss: 0.4087 - accuracy: 0.8036\n",
      "Epoch 45/100\n",
      "153/153 [==============================] - 0s 457us/step - loss: 0.4080 - accuracy: 0.8030\n",
      "Epoch 46/100\n",
      "153/153 [==============================] - 0s 456us/step - loss: 0.4076 - accuracy: 0.8069\n",
      "Epoch 47/100\n",
      "153/153 [==============================] - 0s 466us/step - loss: 0.4081 - accuracy: 0.8012\n",
      "Epoch 48/100\n",
      "153/153 [==============================] - 0s 450us/step - loss: 0.4090 - accuracy: 0.8012\n",
      "Epoch 49/100\n",
      "153/153 [==============================] - 0s 549us/step - loss: 0.4075 - accuracy: 0.8032\n",
      "Epoch 50/100\n",
      "153/153 [==============================] - 0s 453us/step - loss: 0.4123 - accuracy: 0.7995\n",
      "Epoch 51/100\n",
      "153/153 [==============================] - 0s 450us/step - loss: 0.4052 - accuracy: 0.8063\n",
      "Epoch 52/100\n",
      "153/153 [==============================] - 0s 551us/step - loss: 0.4051 - accuracy: 0.8038\n",
      "Epoch 53/100\n",
      "153/153 [==============================] - 0s 860us/step - loss: 0.4089 - accuracy: 0.8028\n",
      "Epoch 54/100\n",
      "153/153 [==============================] - 0s 465us/step - loss: 0.4024 - accuracy: 0.8090\n",
      "Epoch 55/100\n",
      "153/153 [==============================] - 0s 578us/step - loss: 0.4051 - accuracy: 0.8032\n",
      "Epoch 56/100\n",
      "153/153 [==============================] - 0s 451us/step - loss: 0.4053 - accuracy: 0.8065\n",
      "Epoch 57/100\n",
      "153/153 [==============================] - 0s 450us/step - loss: 0.4102 - accuracy: 0.8044\n",
      "Epoch 58/100\n",
      "153/153 [==============================] - 0s 460us/step - loss: 0.4039 - accuracy: 0.8014\n",
      "Epoch 59/100\n",
      "153/153 [==============================] - 0s 453us/step - loss: 0.4015 - accuracy: 0.8073\n",
      "Epoch 60/100\n",
      "153/153 [==============================] - 0s 739us/step - loss: 0.4038 - accuracy: 0.8042\n",
      "Epoch 61/100\n",
      "153/153 [==============================] - 0s 486us/step - loss: 0.4037 - accuracy: 0.8061\n",
      "Epoch 62/100\n",
      "153/153 [==============================] - 0s 433us/step - loss: 0.4081 - accuracy: 0.8040\n",
      "Epoch 63/100\n",
      "153/153 [==============================] - 0s 546us/step - loss: 0.4032 - accuracy: 0.8067\n",
      "Epoch 64/100\n",
      "153/153 [==============================] - 0s 506us/step - loss: 0.4067 - accuracy: 0.8026\n",
      "Epoch 65/100\n",
      "153/153 [==============================] - 0s 494us/step - loss: 0.4039 - accuracy: 0.8036\n",
      "Epoch 66/100\n",
      "153/153 [==============================] - 0s 516us/step - loss: 0.3993 - accuracy: 0.8044\n",
      "Epoch 67/100\n",
      "153/153 [==============================] - 0s 448us/step - loss: 0.4003 - accuracy: 0.8063\n",
      "Epoch 68/100\n",
      "153/153 [==============================] - 0s 483us/step - loss: 0.3994 - accuracy: 0.8073\n",
      "Epoch 69/100\n",
      "153/153 [==============================] - 0s 417us/step - loss: 0.4013 - accuracy: 0.8071\n",
      "Epoch 70/100\n",
      "153/153 [==============================] - 0s 434us/step - loss: 0.4072 - accuracy: 0.8009\n",
      "Epoch 71/100\n",
      "153/153 [==============================] - 0s 462us/step - loss: 0.4007 - accuracy: 0.8102\n",
      "Epoch 72/100\n",
      "153/153 [==============================] - 0s 459us/step - loss: 0.4014 - accuracy: 0.8073\n",
      "Epoch 73/100\n",
      "153/153 [==============================] - 0s 442us/step - loss: 0.4064 - accuracy: 0.8057\n",
      "Epoch 74/100\n",
      "153/153 [==============================] - 0s 455us/step - loss: 0.4051 - accuracy: 0.8055\n",
      "Epoch 75/100\n",
      "153/153 [==============================] - 0s 452us/step - loss: 0.4005 - accuracy: 0.8077\n",
      "Epoch 76/100\n",
      "153/153 [==============================] - 0s 449us/step - loss: 0.4022 - accuracy: 0.8083\n",
      "Epoch 77/100\n",
      "153/153 [==============================] - 0s 455us/step - loss: 0.3982 - accuracy: 0.8048\n",
      "Epoch 78/100\n",
      "153/153 [==============================] - 0s 466us/step - loss: 0.4009 - accuracy: 0.8048\n",
      "Epoch 79/100\n",
      "153/153 [==============================] - 0s 465us/step - loss: 0.4016 - accuracy: 0.8079\n",
      "Epoch 80/100\n",
      "153/153 [==============================] - 0s 490us/step - loss: 0.4042 - accuracy: 0.8048\n",
      "Epoch 81/100\n",
      "153/153 [==============================] - 0s 484us/step - loss: 0.4001 - accuracy: 0.8083\n",
      "Epoch 82/100\n",
      "153/153 [==============================] - 0s 461us/step - loss: 0.3967 - accuracy: 0.8085\n",
      "Epoch 83/100\n",
      "153/153 [==============================] - 0s 466us/step - loss: 0.4041 - accuracy: 0.8022\n",
      "Epoch 84/100\n",
      "153/153 [==============================] - 0s 470us/step - loss: 0.3986 - accuracy: 0.8094\n",
      "Epoch 85/100\n",
      "153/153 [==============================] - 0s 778us/step - loss: 0.3943 - accuracy: 0.8135\n",
      "Epoch 86/100\n",
      "153/153 [==============================] - 0s 447us/step - loss: 0.3976 - accuracy: 0.8100\n",
      "Epoch 87/100\n",
      "153/153 [==============================] - 0s 458us/step - loss: 0.4028 - accuracy: 0.8020\n",
      "Epoch 88/100\n",
      "153/153 [==============================] - 0s 592us/step - loss: 0.3957 - accuracy: 0.8112\n",
      "Epoch 89/100\n",
      "153/153 [==============================] - 0s 447us/step - loss: 0.3973 - accuracy: 0.8094\n",
      "Epoch 90/100\n",
      "153/153 [==============================] - 0s 456us/step - loss: 0.3996 - accuracy: 0.8122\n",
      "Epoch 91/100\n",
      "153/153 [==============================] - 0s 469us/step - loss: 0.3993 - accuracy: 0.8063\n",
      "Epoch 92/100\n",
      "153/153 [==============================] - 0s 448us/step - loss: 0.3948 - accuracy: 0.8110\n",
      "Epoch 93/100\n",
      "153/153 [==============================] - 0s 442us/step - loss: 0.3936 - accuracy: 0.8139\n",
      "Epoch 94/100\n",
      "153/153 [==============================] - 0s 443us/step - loss: 0.3982 - accuracy: 0.8085\n",
      "Epoch 95/100\n",
      "153/153 [==============================] - 0s 460us/step - loss: 0.3971 - accuracy: 0.8104\n",
      "Epoch 96/100\n",
      "153/153 [==============================] - 0s 462us/step - loss: 0.4001 - accuracy: 0.8059\n",
      "Epoch 97/100\n",
      "153/153 [==============================] - 0s 443us/step - loss: 0.4005 - accuracy: 0.8063\n",
      "Epoch 98/100\n",
      "153/153 [==============================] - 0s 431us/step - loss: 0.3974 - accuracy: 0.8116\n",
      "Epoch 99/100\n",
      "153/153 [==============================] - 0s 443us/step - loss: 0.3990 - accuracy: 0.8104\n",
      "Epoch 100/100\n",
      "153/153 [==============================] - 0s 451us/step - loss: 0.4048 - accuracy: 0.8063\n",
      "39/39 [==============================] - 0s 329us/step\n",
      "Epoch 1/200\n",
      "153/153 [==============================] - 1s 476us/step - loss: 0.5915 - accuracy: 0.6871\n",
      "Epoch 2/200\n",
      "153/153 [==============================] - 0s 512us/step - loss: 0.4476 - accuracy: 0.7818\n",
      "Epoch 3/200\n",
      "153/153 [==============================] - 0s 429us/step - loss: 0.4349 - accuracy: 0.7940\n",
      "Epoch 4/200\n",
      "153/153 [==============================] - 0s 462us/step - loss: 0.4315 - accuracy: 0.7933\n",
      "Epoch 5/200\n",
      "153/153 [==============================] - 0s 670us/step - loss: 0.4284 - accuracy: 0.7975\n",
      "Epoch 6/200\n",
      "153/153 [==============================] - 0s 489us/step - loss: 0.4280 - accuracy: 0.7886\n",
      "Epoch 7/200\n",
      "153/153 [==============================] - 0s 634us/step - loss: 0.4228 - accuracy: 0.8022\n",
      "Epoch 8/200\n",
      "153/153 [==============================] - 0s 480us/step - loss: 0.4216 - accuracy: 0.7983\n",
      "Epoch 9/200\n",
      "153/153 [==============================] - 0s 590us/step - loss: 0.4207 - accuracy: 0.8001\n",
      "Epoch 10/200\n",
      "153/153 [==============================] - 0s 454us/step - loss: 0.4164 - accuracy: 0.8059\n",
      "Epoch 11/200\n",
      "153/153 [==============================] - 0s 555us/step - loss: 0.4170 - accuracy: 0.8065\n",
      "Epoch 12/200\n",
      "153/153 [==============================] - 0s 443us/step - loss: 0.4186 - accuracy: 0.8005\n",
      "Epoch 13/200\n",
      "153/153 [==============================] - 0s 453us/step - loss: 0.4193 - accuracy: 0.8003\n",
      "Epoch 14/200\n",
      "153/153 [==============================] - 0s 621us/step - loss: 0.4117 - accuracy: 0.8028\n",
      "Epoch 15/200\n",
      "153/153 [==============================] - 0s 455us/step - loss: 0.4167 - accuracy: 0.8032\n",
      "Epoch 16/200\n",
      "153/153 [==============================] - 0s 472us/step - loss: 0.4143 - accuracy: 0.8036\n",
      "Epoch 17/200\n",
      "153/153 [==============================] - 0s 442us/step - loss: 0.4162 - accuracy: 0.7960\n",
      "Epoch 18/200\n",
      "153/153 [==============================] - 0s 448us/step - loss: 0.4102 - accuracy: 0.8032\n",
      "Epoch 19/200\n",
      "153/153 [==============================] - 0s 441us/step - loss: 0.4127 - accuracy: 0.8032\n",
      "Epoch 20/200\n",
      "153/153 [==============================] - 0s 453us/step - loss: 0.4087 - accuracy: 0.8016\n",
      "Epoch 21/200\n",
      "153/153 [==============================] - 0s 440us/step - loss: 0.4117 - accuracy: 0.8030\n",
      "Epoch 22/200\n",
      "153/153 [==============================] - 0s 450us/step - loss: 0.4097 - accuracy: 0.8026\n",
      "Epoch 23/200\n",
      "153/153 [==============================] - 0s 431us/step - loss: 0.4082 - accuracy: 0.8044\n",
      "Epoch 24/200\n",
      "153/153 [==============================] - 0s 461us/step - loss: 0.4102 - accuracy: 0.8024\n",
      "Epoch 25/200\n",
      "153/153 [==============================] - 0s 434us/step - loss: 0.4115 - accuracy: 0.8026\n",
      "Epoch 26/200\n",
      "153/153 [==============================] - 0s 439us/step - loss: 0.4057 - accuracy: 0.8042\n",
      "Epoch 27/200\n",
      "153/153 [==============================] - 0s 444us/step - loss: 0.4006 - accuracy: 0.8110\n",
      "Epoch 28/200\n",
      "153/153 [==============================] - 0s 456us/step - loss: 0.4040 - accuracy: 0.8114\n",
      "Epoch 29/200\n",
      "153/153 [==============================] - 0s 432us/step - loss: 0.4065 - accuracy: 0.8083\n",
      "Epoch 30/200\n",
      "153/153 [==============================] - 0s 441us/step - loss: 0.4001 - accuracy: 0.8102\n",
      "Epoch 31/200\n",
      "153/153 [==============================] - 0s 443us/step - loss: 0.4042 - accuracy: 0.8067\n",
      "Epoch 32/200\n",
      "153/153 [==============================] - 0s 498us/step - loss: 0.4019 - accuracy: 0.8071\n",
      "Epoch 33/200\n",
      "153/153 [==============================] - 0s 442us/step - loss: 0.4022 - accuracy: 0.8075\n",
      "Epoch 34/200\n",
      "153/153 [==============================] - 0s 441us/step - loss: 0.4049 - accuracy: 0.8044\n",
      "Epoch 35/200\n",
      "153/153 [==============================] - 0s 450us/step - loss: 0.4035 - accuracy: 0.8065\n",
      "Epoch 36/200\n",
      "153/153 [==============================] - 0s 864us/step - loss: 0.4029 - accuracy: 0.8065\n",
      "Epoch 37/200\n",
      "153/153 [==============================] - 0s 445us/step - loss: 0.4014 - accuracy: 0.8048\n",
      "Epoch 38/200\n",
      "153/153 [==============================] - 0s 523us/step - loss: 0.3999 - accuracy: 0.8112\n",
      "Epoch 39/200\n",
      "153/153 [==============================] - 0s 466us/step - loss: 0.3972 - accuracy: 0.8092\n",
      "Epoch 40/200\n",
      "153/153 [==============================] - 0s 632us/step - loss: 0.4022 - accuracy: 0.8048\n",
      "Epoch 41/200\n",
      "153/153 [==============================] - 0s 445us/step - loss: 0.4001 - accuracy: 0.8157\n",
      "Epoch 42/200\n",
      "153/153 [==============================] - 0s 441us/step - loss: 0.4042 - accuracy: 0.8069\n",
      "Epoch 43/200\n",
      "153/153 [==============================] - 0s 447us/step - loss: 0.4005 - accuracy: 0.8149\n",
      "Epoch 44/200\n",
      "153/153 [==============================] - 0s 452us/step - loss: 0.4068 - accuracy: 0.8036\n",
      "Epoch 45/200\n",
      "153/153 [==============================] - 0s 461us/step - loss: 0.3983 - accuracy: 0.8088\n",
      "Epoch 46/200\n",
      "153/153 [==============================] - 0s 479us/step - loss: 0.4007 - accuracy: 0.8102\n",
      "Epoch 47/200\n",
      "153/153 [==============================] - 0s 481us/step - loss: 0.4014 - accuracy: 0.8094\n",
      "Epoch 48/200\n",
      "153/153 [==============================] - 0s 484us/step - loss: 0.3981 - accuracy: 0.8108\n",
      "Epoch 49/200\n",
      "153/153 [==============================] - 0s 435us/step - loss: 0.4010 - accuracy: 0.8071\n",
      "Epoch 50/200\n",
      "153/153 [==============================] - 0s 453us/step - loss: 0.3975 - accuracy: 0.8110\n",
      "Epoch 51/200\n",
      "153/153 [==============================] - 0s 450us/step - loss: 0.3966 - accuracy: 0.8090\n",
      "Epoch 52/200\n",
      "153/153 [==============================] - 0s 482us/step - loss: 0.3948 - accuracy: 0.8135\n",
      "Epoch 53/200\n",
      "153/153 [==============================] - 0s 455us/step - loss: 0.3957 - accuracy: 0.8116\n",
      "Epoch 54/200\n",
      "153/153 [==============================] - 0s 453us/step - loss: 0.3991 - accuracy: 0.8069\n",
      "Epoch 55/200\n",
      "153/153 [==============================] - 0s 451us/step - loss: 0.3982 - accuracy: 0.8088\n",
      "Epoch 56/200\n",
      "153/153 [==============================] - 0s 447us/step - loss: 0.3960 - accuracy: 0.8102\n",
      "Epoch 57/200\n",
      "153/153 [==============================] - 0s 442us/step - loss: 0.3990 - accuracy: 0.8102\n",
      "Epoch 58/200\n",
      "153/153 [==============================] - 0s 450us/step - loss: 0.3975 - accuracy: 0.8129\n",
      "Epoch 59/200\n",
      "153/153 [==============================] - 0s 439us/step - loss: 0.3962 - accuracy: 0.8124\n",
      "Epoch 60/200\n",
      "153/153 [==============================] - 0s 441us/step - loss: 0.3939 - accuracy: 0.8139\n",
      "Epoch 61/200\n",
      "153/153 [==============================] - 0s 436us/step - loss: 0.3978 - accuracy: 0.8116\n",
      "Epoch 62/200\n",
      "153/153 [==============================] - 0s 453us/step - loss: 0.3954 - accuracy: 0.8118\n",
      "Epoch 63/200\n",
      "153/153 [==============================] - 0s 455us/step - loss: 0.3987 - accuracy: 0.8075\n",
      "Epoch 64/200\n",
      "153/153 [==============================] - 0s 436us/step - loss: 0.3959 - accuracy: 0.8077\n",
      "Epoch 65/200\n",
      "153/153 [==============================] - 0s 449us/step - loss: 0.3943 - accuracy: 0.8145\n",
      "Epoch 66/200\n",
      "153/153 [==============================] - 0s 452us/step - loss: 0.3950 - accuracy: 0.8182\n",
      "Epoch 67/200\n",
      "153/153 [==============================] - 0s 711us/step - loss: 0.3973 - accuracy: 0.8104\n",
      "Epoch 68/200\n",
      "153/153 [==============================] - 0s 447us/step - loss: 0.3966 - accuracy: 0.8071\n",
      "Epoch 69/200\n",
      "153/153 [==============================] - 0s 457us/step - loss: 0.3980 - accuracy: 0.8096\n",
      "Epoch 70/200\n",
      "153/153 [==============================] - 0s 437us/step - loss: 0.4002 - accuracy: 0.8077\n",
      "Epoch 71/200\n",
      "153/153 [==============================] - 0s 555us/step - loss: 0.3990 - accuracy: 0.8067\n",
      "Epoch 72/200\n",
      "153/153 [==============================] - 0s 462us/step - loss: 0.3929 - accuracy: 0.8112\n",
      "Epoch 73/200\n",
      "153/153 [==============================] - 0s 470us/step - loss: 0.3947 - accuracy: 0.8137\n",
      "Epoch 74/200\n",
      "153/153 [==============================] - 0s 455us/step - loss: 0.3919 - accuracy: 0.8149\n",
      "Epoch 75/200\n",
      "153/153 [==============================] - 0s 443us/step - loss: 0.3973 - accuracy: 0.8055\n",
      "Epoch 76/200\n",
      "153/153 [==============================] - 0s 443us/step - loss: 0.3917 - accuracy: 0.8114\n",
      "Epoch 77/200\n",
      "153/153 [==============================] - 0s 440us/step - loss: 0.3927 - accuracy: 0.8100\n",
      "Epoch 78/200\n",
      "153/153 [==============================] - 0s 434us/step - loss: 0.3937 - accuracy: 0.8135\n",
      "Epoch 79/200\n",
      "153/153 [==============================] - 0s 443us/step - loss: 0.3939 - accuracy: 0.8098\n",
      "Epoch 80/200\n",
      "153/153 [==============================] - 0s 431us/step - loss: 0.3972 - accuracy: 0.8139\n",
      "Epoch 81/200\n",
      "153/153 [==============================] - 0s 437us/step - loss: 0.3998 - accuracy: 0.8026\n",
      "Epoch 82/200\n",
      "153/153 [==============================] - 0s 449us/step - loss: 0.3950 - accuracy: 0.8094\n",
      "Epoch 83/200\n",
      "153/153 [==============================] - 0s 454us/step - loss: 0.3956 - accuracy: 0.8114\n",
      "Epoch 84/200\n",
      "153/153 [==============================] - 0s 445us/step - loss: 0.3929 - accuracy: 0.8180\n",
      "Epoch 85/200\n",
      "153/153 [==============================] - 0s 448us/step - loss: 0.3962 - accuracy: 0.8127\n",
      "Epoch 86/200\n",
      "153/153 [==============================] - 0s 436us/step - loss: 0.3961 - accuracy: 0.8077\n",
      "Epoch 87/200\n",
      "153/153 [==============================] - 0s 450us/step - loss: 0.3939 - accuracy: 0.8085\n",
      "Epoch 88/200\n",
      "153/153 [==============================] - 0s 436us/step - loss: 0.3926 - accuracy: 0.8071\n",
      "Epoch 89/200\n",
      "153/153 [==============================] - 0s 443us/step - loss: 0.3926 - accuracy: 0.8116\n",
      "Epoch 90/200\n",
      "153/153 [==============================] - 0s 447us/step - loss: 0.3921 - accuracy: 0.8102\n",
      "Epoch 91/200\n",
      "153/153 [==============================] - 0s 445us/step - loss: 0.3889 - accuracy: 0.8141\n",
      "Epoch 92/200\n",
      "153/153 [==============================] - 0s 441us/step - loss: 0.3943 - accuracy: 0.8120\n",
      "Epoch 93/200\n",
      "153/153 [==============================] - 0s 448us/step - loss: 0.3908 - accuracy: 0.8120\n",
      "Epoch 94/200\n",
      "153/153 [==============================] - 0s 456us/step - loss: 0.3920 - accuracy: 0.8083\n",
      "Epoch 95/200\n",
      "153/153 [==============================] - 0s 471us/step - loss: 0.3908 - accuracy: 0.8118\n",
      "Epoch 96/200\n",
      "153/153 [==============================] - 0s 443us/step - loss: 0.3910 - accuracy: 0.8122\n",
      "Epoch 97/200\n",
      "153/153 [==============================] - 0s 447us/step - loss: 0.3921 - accuracy: 0.8100\n",
      "Epoch 98/200\n",
      "153/153 [==============================] - 0s 442us/step - loss: 0.3886 - accuracy: 0.8129\n",
      "Epoch 99/200\n",
      "153/153 [==============================] - 0s 433us/step - loss: 0.3878 - accuracy: 0.8153\n",
      "Epoch 100/200\n",
      "153/153 [==============================] - 0s 755us/step - loss: 0.3944 - accuracy: 0.8079\n",
      "Epoch 101/200\n",
      "153/153 [==============================] - 0s 443us/step - loss: 0.3902 - accuracy: 0.8149\n",
      "Epoch 102/200\n",
      "153/153 [==============================] - 0s 452us/step - loss: 0.3875 - accuracy: 0.8164\n",
      "Epoch 103/200\n",
      "153/153 [==============================] - 0s 455us/step - loss: 0.3900 - accuracy: 0.8127\n",
      "Epoch 104/200\n",
      "153/153 [==============================] - 0s 683us/step - loss: 0.3932 - accuracy: 0.8108\n",
      "Epoch 105/200\n",
      "153/153 [==============================] - 0s 528us/step - loss: 0.3927 - accuracy: 0.8106\n",
      "Epoch 106/200\n",
      "153/153 [==============================] - 0s 446us/step - loss: 0.3910 - accuracy: 0.8127\n",
      "Epoch 107/200\n",
      "153/153 [==============================] - 0s 437us/step - loss: 0.3905 - accuracy: 0.8108\n",
      "Epoch 108/200\n",
      "153/153 [==============================] - 0s 444us/step - loss: 0.3869 - accuracy: 0.8153\n",
      "Epoch 109/200\n",
      "153/153 [==============================] - 0s 450us/step - loss: 0.3884 - accuracy: 0.8147\n",
      "Epoch 110/200\n",
      "153/153 [==============================] - 0s 460us/step - loss: 0.3948 - accuracy: 0.8096\n",
      "Epoch 111/200\n",
      "153/153 [==============================] - 0s 468us/step - loss: 0.3912 - accuracy: 0.8102\n",
      "Epoch 112/200\n",
      "153/153 [==============================] - 0s 473us/step - loss: 0.3892 - accuracy: 0.8118\n",
      "Epoch 113/200\n",
      "153/153 [==============================] - 0s 470us/step - loss: 0.3875 - accuracy: 0.8149\n",
      "Epoch 114/200\n",
      "153/153 [==============================] - 0s 492us/step - loss: 0.3915 - accuracy: 0.8090\n",
      "Epoch 115/200\n",
      "153/153 [==============================] - 0s 469us/step - loss: 0.3900 - accuracy: 0.8102\n",
      "Epoch 116/200\n",
      "153/153 [==============================] - 0s 443us/step - loss: 0.3938 - accuracy: 0.8077\n",
      "Epoch 117/200\n",
      "153/153 [==============================] - 0s 440us/step - loss: 0.3866 - accuracy: 0.8172\n",
      "Epoch 118/200\n",
      "153/153 [==============================] - 0s 433us/step - loss: 0.3871 - accuracy: 0.8122\n",
      "Epoch 119/200\n",
      "153/153 [==============================] - 0s 455us/step - loss: 0.3849 - accuracy: 0.8133\n",
      "Epoch 120/200\n",
      "153/153 [==============================] - 0s 440us/step - loss: 0.3856 - accuracy: 0.8178\n",
      "Epoch 121/200\n",
      "153/153 [==============================] - 0s 457us/step - loss: 0.3904 - accuracy: 0.8135\n",
      "Epoch 122/200\n",
      "153/153 [==============================] - 0s 432us/step - loss: 0.3881 - accuracy: 0.8092\n",
      "Epoch 123/200\n",
      "153/153 [==============================] - 0s 430us/step - loss: 0.3845 - accuracy: 0.8159\n",
      "Epoch 124/200\n",
      "153/153 [==============================] - 0s 422us/step - loss: 0.3849 - accuracy: 0.8182\n",
      "Epoch 125/200\n",
      "153/153 [==============================] - 0s 451us/step - loss: 0.3861 - accuracy: 0.8139\n",
      "Epoch 126/200\n",
      "153/153 [==============================] - 0s 436us/step - loss: 0.3877 - accuracy: 0.8135\n",
      "Epoch 127/200\n",
      "153/153 [==============================] - 0s 424us/step - loss: 0.3858 - accuracy: 0.8182\n",
      "Epoch 128/200\n",
      "153/153 [==============================] - 0s 449us/step - loss: 0.3906 - accuracy: 0.8120\n",
      "Epoch 129/200\n",
      "153/153 [==============================] - 0s 436us/step - loss: 0.3837 - accuracy: 0.8188\n",
      "Epoch 130/200\n",
      "153/153 [==============================] - 0s 726us/step - loss: 0.3844 - accuracy: 0.8124\n",
      "Epoch 131/200\n",
      "153/153 [==============================] - 0s 441us/step - loss: 0.3827 - accuracy: 0.8200\n",
      "Epoch 132/200\n",
      "153/153 [==============================] - 0s 1ms/step - loss: 0.3841 - accuracy: 0.8182\n",
      "Epoch 133/200\n",
      "153/153 [==============================] - 0s 2ms/step - loss: 0.3871 - accuracy: 0.8139\n",
      "Epoch 134/200\n",
      "153/153 [==============================] - 0s 520us/step - loss: 0.3858 - accuracy: 0.8116\n",
      "Epoch 135/200\n",
      "153/153 [==============================] - 0s 1ms/step - loss: 0.3837 - accuracy: 0.8174\n",
      "Epoch 136/200\n",
      "153/153 [==============================] - 0s 1ms/step - loss: 0.3875 - accuracy: 0.8122\n",
      "Epoch 137/200\n",
      "153/153 [==============================] - 0s 513us/step - loss: 0.3839 - accuracy: 0.8135\n",
      "Epoch 138/200\n",
      "153/153 [==============================] - 0s 456us/step - loss: 0.3858 - accuracy: 0.8129\n",
      "Epoch 139/200\n",
      "153/153 [==============================] - 0s 522us/step - loss: 0.3896 - accuracy: 0.8104\n",
      "Epoch 140/200\n",
      "153/153 [==============================] - 0s 449us/step - loss: 0.3881 - accuracy: 0.8090\n",
      "Epoch 141/200\n",
      "153/153 [==============================] - 0s 460us/step - loss: 0.3868 - accuracy: 0.8088\n",
      "Epoch 142/200\n",
      "153/153 [==============================] - 0s 454us/step - loss: 0.3888 - accuracy: 0.8196\n",
      "Epoch 143/200\n",
      "153/153 [==============================] - 0s 450us/step - loss: 0.3848 - accuracy: 0.8176\n",
      "Epoch 144/200\n",
      "153/153 [==============================] - 0s 501us/step - loss: 0.3869 - accuracy: 0.8124\n",
      "Epoch 145/200\n",
      "153/153 [==============================] - 0s 486us/step - loss: 0.3871 - accuracy: 0.8112\n",
      "Epoch 146/200\n",
      "153/153 [==============================] - 0s 449us/step - loss: 0.3824 - accuracy: 0.8161\n",
      "Epoch 147/200\n",
      "153/153 [==============================] - 0s 477us/step - loss: 0.3814 - accuracy: 0.8180\n",
      "Epoch 148/200\n",
      "153/153 [==============================] - 0s 499us/step - loss: 0.3814 - accuracy: 0.8186\n",
      "Epoch 149/200\n",
      "153/153 [==============================] - 0s 442us/step - loss: 0.3822 - accuracy: 0.8153\n",
      "Epoch 150/200\n",
      "153/153 [==============================] - 0s 451us/step - loss: 0.3848 - accuracy: 0.8180\n",
      "Epoch 151/200\n",
      "153/153 [==============================] - 0s 435us/step - loss: 0.3811 - accuracy: 0.8180\n",
      "Epoch 152/200\n",
      "153/153 [==============================] - 0s 465us/step - loss: 0.3810 - accuracy: 0.8227\n",
      "Epoch 153/200\n",
      "153/153 [==============================] - 0s 449us/step - loss: 0.3877 - accuracy: 0.8133\n",
      "Epoch 154/200\n",
      "153/153 [==============================] - 0s 435us/step - loss: 0.3845 - accuracy: 0.8164\n",
      "Epoch 155/200\n",
      "153/153 [==============================] - 0s 601us/step - loss: 0.3830 - accuracy: 0.8182\n",
      "Epoch 156/200\n",
      "153/153 [==============================] - 0s 446us/step - loss: 0.3792 - accuracy: 0.8170\n",
      "Epoch 157/200\n",
      "153/153 [==============================] - 0s 443us/step - loss: 0.3859 - accuracy: 0.8149\n",
      "Epoch 158/200\n",
      "153/153 [==============================] - 0s 441us/step - loss: 0.3791 - accuracy: 0.8194\n",
      "Epoch 159/200\n",
      "153/153 [==============================] - 0s 439us/step - loss: 0.3856 - accuracy: 0.8153\n",
      "Epoch 160/200\n",
      "153/153 [==============================] - 0s 432us/step - loss: 0.3843 - accuracy: 0.8168\n",
      "Epoch 161/200\n",
      "153/153 [==============================] - 0s 450us/step - loss: 0.3859 - accuracy: 0.8131\n",
      "Epoch 162/200\n",
      "153/153 [==============================] - 0s 435us/step - loss: 0.3841 - accuracy: 0.8133\n",
      "Epoch 163/200\n",
      "153/153 [==============================] - 0s 449us/step - loss: 0.3801 - accuracy: 0.8170\n",
      "Epoch 164/200\n",
      "153/153 [==============================] - 0s 433us/step - loss: 0.3801 - accuracy: 0.8159\n",
      "Epoch 165/200\n",
      "153/153 [==============================] - 0s 465us/step - loss: 0.3794 - accuracy: 0.8170\n",
      "Epoch 166/200\n",
      "153/153 [==============================] - 0s 477us/step - loss: 0.3821 - accuracy: 0.8188\n",
      "Epoch 167/200\n",
      "153/153 [==============================] - 0s 427us/step - loss: 0.3803 - accuracy: 0.8166\n",
      "Epoch 168/200\n",
      "153/153 [==============================] - 0s 449us/step - loss: 0.3847 - accuracy: 0.8170\n",
      "Epoch 169/200\n",
      "153/153 [==============================] - 0s 452us/step - loss: 0.3863 - accuracy: 0.8133\n",
      "Epoch 170/200\n",
      "153/153 [==============================] - 0s 507us/step - loss: 0.3870 - accuracy: 0.8145\n",
      "Epoch 171/200\n",
      "153/153 [==============================] - 0s 445us/step - loss: 0.3846 - accuracy: 0.8155\n",
      "Epoch 172/200\n",
      "153/153 [==============================] - 0s 460us/step - loss: 0.3795 - accuracy: 0.8180\n",
      "Epoch 173/200\n",
      "153/153 [==============================] - 0s 457us/step - loss: 0.3845 - accuracy: 0.8164\n",
      "Epoch 174/200\n",
      "153/153 [==============================] - 0s 442us/step - loss: 0.3844 - accuracy: 0.8129\n",
      "Epoch 175/200\n",
      "153/153 [==============================] - 0s 462us/step - loss: 0.3788 - accuracy: 0.8190\n",
      "Epoch 176/200\n",
      "153/153 [==============================] - 0s 441us/step - loss: 0.3812 - accuracy: 0.8172\n",
      "Epoch 177/200\n",
      "153/153 [==============================] - 0s 514us/step - loss: 0.3805 - accuracy: 0.8184\n",
      "Epoch 178/200\n",
      "153/153 [==============================] - 0s 585us/step - loss: 0.3826 - accuracy: 0.8137\n",
      "Epoch 179/200\n",
      "153/153 [==============================] - 0s 488us/step - loss: 0.3829 - accuracy: 0.8155\n",
      "Epoch 180/200\n",
      "153/153 [==============================] - 0s 467us/step - loss: 0.3838 - accuracy: 0.8124\n",
      "Epoch 181/200\n",
      "153/153 [==============================] - 0s 458us/step - loss: 0.3866 - accuracy: 0.8166\n",
      "Epoch 182/200\n",
      "153/153 [==============================] - 0s 484us/step - loss: 0.3819 - accuracy: 0.8092\n",
      "Epoch 183/200\n",
      "153/153 [==============================] - 0s 773us/step - loss: 0.3803 - accuracy: 0.8145\n",
      "Epoch 184/200\n",
      "153/153 [==============================] - 0s 455us/step - loss: 0.3772 - accuracy: 0.8215\n",
      "Epoch 185/200\n",
      "153/153 [==============================] - 0s 460us/step - loss: 0.3823 - accuracy: 0.8159\n",
      "Epoch 186/200\n",
      "153/153 [==============================] - 0s 449us/step - loss: 0.3790 - accuracy: 0.8161\n",
      "Epoch 187/200\n",
      "153/153 [==============================] - 0s 438us/step - loss: 0.3776 - accuracy: 0.8139\n",
      "Epoch 188/200\n",
      "153/153 [==============================] - 0s 438us/step - loss: 0.3785 - accuracy: 0.8194\n",
      "Epoch 189/200\n",
      "153/153 [==============================] - 0s 475us/step - loss: 0.3766 - accuracy: 0.8198\n",
      "Epoch 190/200\n",
      "153/153 [==============================] - 0s 456us/step - loss: 0.3871 - accuracy: 0.8106\n",
      "Epoch 191/200\n",
      "153/153 [==============================] - 0s 442us/step - loss: 0.3788 - accuracy: 0.8180\n",
      "Epoch 192/200\n",
      "153/153 [==============================] - 0s 451us/step - loss: 0.3786 - accuracy: 0.8147\n",
      "Epoch 193/200\n",
      "153/153 [==============================] - 0s 433us/step - loss: 0.3759 - accuracy: 0.8178\n",
      "Epoch 194/200\n",
      "153/153 [==============================] - 0s 423us/step - loss: 0.3850 - accuracy: 0.8102\n",
      "Epoch 195/200\n",
      "153/153 [==============================] - 0s 489us/step - loss: 0.3800 - accuracy: 0.8153\n",
      "Epoch 196/200\n",
      "153/153 [==============================] - 0s 454us/step - loss: 0.3764 - accuracy: 0.8235\n",
      "Epoch 197/200\n",
      "153/153 [==============================] - 0s 478us/step - loss: 0.3785 - accuracy: 0.8166\n",
      "Epoch 198/200\n",
      "153/153 [==============================] - 0s 572us/step - loss: 0.3806 - accuracy: 0.8188\n",
      "Epoch 199/200\n",
      "153/153 [==============================] - 0s 493us/step - loss: 0.3830 - accuracy: 0.8168\n",
      "Epoch 200/200\n",
      "153/153 [==============================] - 0s 452us/step - loss: 0.3842 - accuracy: 0.8143\n",
      "39/39 [==============================] - 0s 332us/step\n",
      "Epoch 1/200\n",
      "153/153 [==============================] - 0s 551us/step - loss: 0.5773 - accuracy: 0.6974\n",
      "Epoch 2/200\n",
      "153/153 [==============================] - 0s 523us/step - loss: 0.4407 - accuracy: 0.7820\n",
      "Epoch 3/200\n",
      "153/153 [==============================] - 0s 450us/step - loss: 0.4333 - accuracy: 0.7946\n",
      "Epoch 4/200\n",
      "153/153 [==============================] - 0s 480us/step - loss: 0.4244 - accuracy: 0.7925\n",
      "Epoch 5/200\n",
      "153/153 [==============================] - 0s 522us/step - loss: 0.4183 - accuracy: 0.8014\n",
      "Epoch 6/200\n",
      "153/153 [==============================] - 0s 479us/step - loss: 0.4224 - accuracy: 0.7925\n",
      "Epoch 7/200\n",
      "153/153 [==============================] - 0s 450us/step - loss: 0.4237 - accuracy: 0.7981\n",
      "Epoch 8/200\n",
      "153/153 [==============================] - 0s 434us/step - loss: 0.4227 - accuracy: 0.8020\n",
      "Epoch 9/200\n",
      "153/153 [==============================] - 0s 460us/step - loss: 0.4176 - accuracy: 0.8018\n",
      "Epoch 10/200\n",
      "153/153 [==============================] - 0s 438us/step - loss: 0.4143 - accuracy: 0.8007\n",
      "Epoch 11/200\n",
      "153/153 [==============================] - 0s 430us/step - loss: 0.4138 - accuracy: 0.8016\n",
      "Epoch 12/200\n",
      "153/153 [==============================] - 0s 442us/step - loss: 0.4150 - accuracy: 0.8040\n",
      "Epoch 13/200\n",
      "153/153 [==============================] - 0s 438us/step - loss: 0.4121 - accuracy: 0.8026\n",
      "Epoch 14/200\n",
      "153/153 [==============================] - 0s 454us/step - loss: 0.4117 - accuracy: 0.7989\n",
      "Epoch 15/200\n",
      "153/153 [==============================] - 0s 496us/step - loss: 0.4142 - accuracy: 0.8007\n",
      "Epoch 16/200\n",
      "153/153 [==============================] - 0s 459us/step - loss: 0.4097 - accuracy: 0.8012\n",
      "Epoch 17/200\n",
      "153/153 [==============================] - 0s 451us/step - loss: 0.4083 - accuracy: 0.8044\n",
      "Epoch 18/200\n",
      "153/153 [==============================] - 0s 452us/step - loss: 0.4121 - accuracy: 0.8014\n",
      "Epoch 19/200\n",
      "153/153 [==============================] - 0s 684us/step - loss: 0.4112 - accuracy: 0.7975\n",
      "Epoch 20/200\n",
      "153/153 [==============================] - 0s 1ms/step - loss: 0.4084 - accuracy: 0.8038\n",
      "Epoch 21/200\n",
      "153/153 [==============================] - 0s 467us/step - loss: 0.4040 - accuracy: 0.8088\n",
      "Epoch 22/200\n",
      "153/153 [==============================] - 0s 1ms/step - loss: 0.4020 - accuracy: 0.8069\n",
      "Epoch 23/200\n",
      "153/153 [==============================] - 0s 523us/step - loss: 0.4049 - accuracy: 0.8048\n",
      "Epoch 24/200\n",
      "153/153 [==============================] - 0s 647us/step - loss: 0.4046 - accuracy: 0.8036\n",
      "Epoch 25/200\n",
      "153/153 [==============================] - 0s 615us/step - loss: 0.4035 - accuracy: 0.8046\n",
      "Epoch 26/200\n",
      "153/153 [==============================] - 0s 482us/step - loss: 0.4050 - accuracy: 0.8081\n",
      "Epoch 27/200\n",
      "153/153 [==============================] - 0s 438us/step - loss: 0.3979 - accuracy: 0.8096\n",
      "Epoch 28/200\n",
      "153/153 [==============================] - 0s 419us/step - loss: 0.4000 - accuracy: 0.8077\n",
      "Epoch 29/200\n",
      "153/153 [==============================] - 0s 720us/step - loss: 0.4031 - accuracy: 0.8026\n",
      "Epoch 30/200\n",
      "153/153 [==============================] - 0s 960us/step - loss: 0.4045 - accuracy: 0.8040\n",
      "Epoch 31/200\n",
      "153/153 [==============================] - 0s 447us/step - loss: 0.4029 - accuracy: 0.8073\n",
      "Epoch 32/200\n",
      "153/153 [==============================] - 0s 435us/step - loss: 0.4018 - accuracy: 0.8059\n",
      "Epoch 33/200\n",
      "153/153 [==============================] - 0s 415us/step - loss: 0.3979 - accuracy: 0.8108\n",
      "Epoch 34/200\n",
      "153/153 [==============================] - 0s 442us/step - loss: 0.4019 - accuracy: 0.8057\n",
      "Epoch 35/200\n",
      "153/153 [==============================] - 0s 405us/step - loss: 0.4057 - accuracy: 0.8053\n",
      "Epoch 36/200\n",
      "153/153 [==============================] - 0s 426us/step - loss: 0.4003 - accuracy: 0.8083\n",
      "Epoch 37/200\n",
      "153/153 [==============================] - 0s 409us/step - loss: 0.4017 - accuracy: 0.8040\n",
      "Epoch 38/200\n",
      "153/153 [==============================] - 0s 433us/step - loss: 0.4005 - accuracy: 0.8057\n",
      "Epoch 39/200\n",
      "153/153 [==============================] - 0s 440us/step - loss: 0.4019 - accuracy: 0.8085\n",
      "Epoch 40/200\n",
      "153/153 [==============================] - 0s 439us/step - loss: 0.3987 - accuracy: 0.8118\n",
      "Epoch 41/200\n",
      "153/153 [==============================] - 0s 424us/step - loss: 0.3997 - accuracy: 0.8038\n",
      "Epoch 42/200\n",
      "153/153 [==============================] - 0s 2ms/step - loss: 0.3956 - accuracy: 0.8096\n",
      "Epoch 43/200\n",
      "153/153 [==============================] - 0s 388us/step - loss: 0.3970 - accuracy: 0.8038\n",
      "Epoch 44/200\n",
      "153/153 [==============================] - 0s 385us/step - loss: 0.4004 - accuracy: 0.8057\n",
      "Epoch 45/200\n",
      "153/153 [==============================] - 0s 443us/step - loss: 0.3989 - accuracy: 0.8120\n",
      "Epoch 46/200\n",
      "153/153 [==============================] - 0s 402us/step - loss: 0.3927 - accuracy: 0.8135\n",
      "Epoch 47/200\n",
      "153/153 [==============================] - 0s 462us/step - loss: 0.3982 - accuracy: 0.8085\n",
      "Epoch 48/200\n",
      "153/153 [==============================] - 0s 390us/step - loss: 0.3922 - accuracy: 0.8164\n",
      "Epoch 49/200\n",
      "153/153 [==============================] - 0s 389us/step - loss: 0.3917 - accuracy: 0.8118\n",
      "Epoch 50/200\n",
      "153/153 [==============================] - 0s 408us/step - loss: 0.3898 - accuracy: 0.8114\n",
      "Epoch 51/200\n",
      "153/153 [==============================] - 0s 401us/step - loss: 0.3968 - accuracy: 0.8102\n",
      "Epoch 52/200\n",
      "153/153 [==============================] - 0s 478us/step - loss: 0.3942 - accuracy: 0.8094\n",
      "Epoch 53/200\n",
      "153/153 [==============================] - 0s 404us/step - loss: 0.3952 - accuracy: 0.8108\n",
      "Epoch 54/200\n",
      "153/153 [==============================] - 0s 394us/step - loss: 0.3916 - accuracy: 0.8122\n",
      "Epoch 55/200\n",
      "153/153 [==============================] - 0s 603us/step - loss: 0.3943 - accuracy: 0.8059\n",
      "Epoch 56/200\n",
      "153/153 [==============================] - 0s 453us/step - loss: 0.3916 - accuracy: 0.8118\n",
      "Epoch 57/200\n",
      "153/153 [==============================] - 0s 388us/step - loss: 0.3949 - accuracy: 0.8077\n",
      "Epoch 58/200\n",
      "153/153 [==============================] - 0s 437us/step - loss: 0.3978 - accuracy: 0.8077\n",
      "Epoch 59/200\n",
      "153/153 [==============================] - 0s 492us/step - loss: 0.3873 - accuracy: 0.8094\n",
      "Epoch 60/200\n",
      "153/153 [==============================] - 0s 967us/step - loss: 0.3908 - accuracy: 0.8071\n",
      "Epoch 61/200\n",
      "153/153 [==============================] - 0s 808us/step - loss: 0.3902 - accuracy: 0.8145\n",
      "Epoch 62/200\n",
      "153/153 [==============================] - 0s 439us/step - loss: 0.3894 - accuracy: 0.8090\n",
      "Epoch 63/200\n",
      "153/153 [==============================] - 0s 447us/step - loss: 0.3944 - accuracy: 0.8057\n",
      "Epoch 64/200\n",
      "153/153 [==============================] - 0s 466us/step - loss: 0.3860 - accuracy: 0.8143\n",
      "Epoch 65/200\n",
      "153/153 [==============================] - 0s 439us/step - loss: 0.3923 - accuracy: 0.8092\n",
      "Epoch 66/200\n",
      "153/153 [==============================] - 0s 455us/step - loss: 0.3955 - accuracy: 0.8073\n",
      "Epoch 67/200\n",
      "153/153 [==============================] - 0s 448us/step - loss: 0.3916 - accuracy: 0.8059\n",
      "Epoch 68/200\n",
      "153/153 [==============================] - 0s 406us/step - loss: 0.3915 - accuracy: 0.8108\n",
      "Epoch 69/200\n",
      "153/153 [==============================] - 0s 397us/step - loss: 0.3896 - accuracy: 0.8104\n",
      "Epoch 70/200\n",
      "153/153 [==============================] - 0s 417us/step - loss: 0.3872 - accuracy: 0.8135\n",
      "Epoch 71/200\n",
      "153/153 [==============================] - 0s 389us/step - loss: 0.3879 - accuracy: 0.8075\n",
      "Epoch 72/200\n",
      "153/153 [==============================] - 0s 415us/step - loss: 0.3861 - accuracy: 0.8141\n",
      "Epoch 73/200\n",
      "153/153 [==============================] - 0s 383us/step - loss: 0.3842 - accuracy: 0.8147\n",
      "Epoch 74/200\n",
      "153/153 [==============================] - 0s 412us/step - loss: 0.3907 - accuracy: 0.8137\n",
      "Epoch 75/200\n",
      "153/153 [==============================] - 0s 405us/step - loss: 0.3848 - accuracy: 0.8182\n",
      "Epoch 76/200\n",
      "153/153 [==============================] - 0s 385us/step - loss: 0.3884 - accuracy: 0.8094\n",
      "Epoch 77/200\n",
      "153/153 [==============================] - 0s 386us/step - loss: 0.3871 - accuracy: 0.8124\n",
      "Epoch 78/200\n",
      "153/153 [==============================] - 0s 391us/step - loss: 0.3901 - accuracy: 0.8124\n",
      "Epoch 79/200\n",
      "153/153 [==============================] - 0s 396us/step - loss: 0.3886 - accuracy: 0.8131\n",
      "Epoch 80/200\n",
      "153/153 [==============================] - 0s 390us/step - loss: 0.3863 - accuracy: 0.8147\n",
      "Epoch 81/200\n",
      "153/153 [==============================] - 0s 420us/step - loss: 0.3876 - accuracy: 0.8096\n",
      "Epoch 82/200\n",
      "153/153 [==============================] - 0s 405us/step - loss: 0.3887 - accuracy: 0.8112\n",
      "Epoch 83/200\n",
      "153/153 [==============================] - 0s 495us/step - loss: 0.3872 - accuracy: 0.8135\n",
      "Epoch 84/200\n",
      "153/153 [==============================] - 0s 801us/step - loss: 0.3868 - accuracy: 0.8079\n",
      "Epoch 85/200\n",
      "153/153 [==============================] - 0s 485us/step - loss: 0.3873 - accuracy: 0.8153\n",
      "Epoch 86/200\n",
      "153/153 [==============================] - 0s 505us/step - loss: 0.3837 - accuracy: 0.8124\n",
      "Epoch 87/200\n",
      "153/153 [==============================] - 0s 434us/step - loss: 0.3845 - accuracy: 0.8153\n",
      "Epoch 88/200\n",
      "153/153 [==============================] - 0s 470us/step - loss: 0.3869 - accuracy: 0.8110\n",
      "Epoch 89/200\n",
      "153/153 [==============================] - 0s 668us/step - loss: 0.3887 - accuracy: 0.8055\n",
      "Epoch 90/200\n",
      "153/153 [==============================] - 0s 443us/step - loss: 0.3819 - accuracy: 0.8168\n",
      "Epoch 91/200\n",
      "153/153 [==============================] - 0s 436us/step - loss: 0.3866 - accuracy: 0.8116\n",
      "Epoch 92/200\n",
      "153/153 [==============================] - 0s 431us/step - loss: 0.3884 - accuracy: 0.8110\n",
      "Epoch 93/200\n",
      "153/153 [==============================] - 0s 455us/step - loss: 0.3877 - accuracy: 0.8124\n",
      "Epoch 94/200\n",
      "153/153 [==============================] - 0s 463us/step - loss: 0.3881 - accuracy: 0.8143\n",
      "Epoch 95/200\n",
      "153/153 [==============================] - 0s 494us/step - loss: 0.3823 - accuracy: 0.8133\n",
      "Epoch 96/200\n",
      "153/153 [==============================] - 0s 444us/step - loss: 0.3844 - accuracy: 0.8120\n",
      "Epoch 97/200\n",
      "153/153 [==============================] - 0s 440us/step - loss: 0.3808 - accuracy: 0.8192\n",
      "Epoch 98/200\n",
      "153/153 [==============================] - 0s 469us/step - loss: 0.3831 - accuracy: 0.8088\n",
      "Epoch 99/200\n",
      "153/153 [==============================] - 0s 455us/step - loss: 0.3839 - accuracy: 0.8129\n",
      "Epoch 100/200\n",
      "153/153 [==============================] - 0s 568us/step - loss: 0.3832 - accuracy: 0.8153\n",
      "Epoch 101/200\n",
      "153/153 [==============================] - 0s 465us/step - loss: 0.3863 - accuracy: 0.8133\n",
      "Epoch 102/200\n",
      "153/153 [==============================] - 0s 443us/step - loss: 0.3907 - accuracy: 0.8147\n",
      "Epoch 103/200\n",
      "153/153 [==============================] - 0s 461us/step - loss: 0.3801 - accuracy: 0.8190\n",
      "Epoch 104/200\n",
      "153/153 [==============================] - 0s 433us/step - loss: 0.3857 - accuracy: 0.8098\n",
      "Epoch 105/200\n",
      "153/153 [==============================] - 0s 433us/step - loss: 0.3824 - accuracy: 0.8178\n",
      "Epoch 106/200\n",
      "153/153 [==============================] - 0s 444us/step - loss: 0.3865 - accuracy: 0.8116\n",
      "Epoch 107/200\n",
      "153/153 [==============================] - 0s 511us/step - loss: 0.3838 - accuracy: 0.8151\n",
      "Epoch 108/200\n",
      "153/153 [==============================] - 0s 441us/step - loss: 0.3817 - accuracy: 0.8118\n",
      "Epoch 109/200\n",
      "153/153 [==============================] - 0s 538us/step - loss: 0.3826 - accuracy: 0.8137\n",
      "Epoch 110/200\n",
      "153/153 [==============================] - 0s 446us/step - loss: 0.3806 - accuracy: 0.8102\n",
      "Epoch 111/200\n",
      "153/153 [==============================] - 0s 430us/step - loss: 0.3846 - accuracy: 0.8131\n",
      "Epoch 112/200\n",
      "153/153 [==============================] - 0s 434us/step - loss: 0.3855 - accuracy: 0.8124\n",
      "Epoch 113/200\n",
      "153/153 [==============================] - 0s 426us/step - loss: 0.3848 - accuracy: 0.8071\n",
      "Epoch 114/200\n",
      "153/153 [==============================] - 0s 429us/step - loss: 0.3802 - accuracy: 0.8164\n",
      "Epoch 115/200\n",
      "153/153 [==============================] - 0s 426us/step - loss: 0.3830 - accuracy: 0.8141\n",
      "Epoch 116/200\n",
      "153/153 [==============================] - 0s 678us/step - loss: 0.3783 - accuracy: 0.8159\n",
      "Epoch 117/200\n",
      "153/153 [==============================] - 0s 433us/step - loss: 0.3844 - accuracy: 0.8096\n",
      "Epoch 118/200\n",
      "153/153 [==============================] - 0s 439us/step - loss: 0.3819 - accuracy: 0.8147\n",
      "Epoch 119/200\n",
      "153/153 [==============================] - 0s 438us/step - loss: 0.3763 - accuracy: 0.8180\n",
      "Epoch 120/200\n",
      "153/153 [==============================] - 0s 440us/step - loss: 0.3801 - accuracy: 0.8155\n",
      "Epoch 121/200\n",
      "153/153 [==============================] - 0s 456us/step - loss: 0.3795 - accuracy: 0.8153\n",
      "Epoch 122/200\n",
      "153/153 [==============================] - 0s 473us/step - loss: 0.3819 - accuracy: 0.8137\n",
      "Epoch 123/200\n",
      "153/153 [==============================] - 0s 460us/step - loss: 0.3798 - accuracy: 0.8106\n",
      "Epoch 124/200\n",
      "153/153 [==============================] - 0s 441us/step - loss: 0.3816 - accuracy: 0.8118\n",
      "Epoch 125/200\n",
      "153/153 [==============================] - 0s 444us/step - loss: 0.3800 - accuracy: 0.8149\n",
      "Epoch 126/200\n",
      "153/153 [==============================] - 0s 465us/step - loss: 0.3829 - accuracy: 0.8147\n",
      "Epoch 127/200\n",
      "153/153 [==============================] - 0s 681us/step - loss: 0.3848 - accuracy: 0.8147\n",
      "Epoch 128/200\n",
      "153/153 [==============================] - 0s 448us/step - loss: 0.3829 - accuracy: 0.8131\n",
      "Epoch 129/200\n",
      "153/153 [==============================] - 0s 447us/step - loss: 0.3804 - accuracy: 0.8213\n",
      "Epoch 130/200\n",
      "153/153 [==============================] - 0s 463us/step - loss: 0.3806 - accuracy: 0.8172\n",
      "Epoch 131/200\n",
      "153/153 [==============================] - 0s 474us/step - loss: 0.3804 - accuracy: 0.8168\n",
      "Epoch 132/200\n",
      "153/153 [==============================] - 0s 486us/step - loss: 0.3801 - accuracy: 0.8133\n",
      "Epoch 133/200\n",
      "153/153 [==============================] - 0s 508us/step - loss: 0.3776 - accuracy: 0.8168\n",
      "Epoch 134/200\n",
      "153/153 [==============================] - 0s 457us/step - loss: 0.3788 - accuracy: 0.8184\n",
      "Epoch 135/200\n",
      "153/153 [==============================] - 0s 449us/step - loss: 0.3814 - accuracy: 0.8137\n",
      "Epoch 136/200\n",
      "153/153 [==============================] - 0s 445us/step - loss: 0.3797 - accuracy: 0.8145\n",
      "Epoch 137/200\n",
      "153/153 [==============================] - 0s 452us/step - loss: 0.3864 - accuracy: 0.8114\n",
      "Epoch 138/200\n",
      "153/153 [==============================] - 0s 445us/step - loss: 0.3819 - accuracy: 0.8141\n",
      "Epoch 139/200\n",
      "153/153 [==============================] - 0s 399us/step - loss: 0.3829 - accuracy: 0.8174\n",
      "Epoch 140/200\n",
      "153/153 [==============================] - 0s 387us/step - loss: 0.3845 - accuracy: 0.8110\n",
      "Epoch 141/200\n",
      "153/153 [==============================] - 0s 389us/step - loss: 0.3829 - accuracy: 0.8166\n",
      "Epoch 142/200\n",
      "153/153 [==============================] - 0s 409us/step - loss: 0.3801 - accuracy: 0.8133\n",
      "Epoch 143/200\n",
      "153/153 [==============================] - 0s 411us/step - loss: 0.3839 - accuracy: 0.8200\n",
      "Epoch 144/200\n",
      "153/153 [==============================] - 0s 559us/step - loss: 0.3842 - accuracy: 0.8151\n",
      "Epoch 145/200\n",
      "153/153 [==============================] - 0s 444us/step - loss: 0.3757 - accuracy: 0.8180\n",
      "Epoch 146/200\n",
      "153/153 [==============================] - 0s 433us/step - loss: 0.3786 - accuracy: 0.8172\n",
      "Epoch 147/200\n",
      "153/153 [==============================] - 0s 438us/step - loss: 0.3819 - accuracy: 0.8157\n",
      "Epoch 148/200\n",
      "153/153 [==============================] - 0s 438us/step - loss: 0.3775 - accuracy: 0.8178\n",
      "Epoch 149/200\n",
      "153/153 [==============================] - 0s 436us/step - loss: 0.3795 - accuracy: 0.8205\n",
      "Epoch 150/200\n",
      "153/153 [==============================] - 0s 475us/step - loss: 0.3768 - accuracy: 0.8192\n",
      "Epoch 151/200\n",
      "153/153 [==============================] - 0s 723us/step - loss: 0.3824 - accuracy: 0.8143\n",
      "Epoch 152/200\n",
      "153/153 [==============================] - 0s 931us/step - loss: 0.3771 - accuracy: 0.8170\n",
      "Epoch 153/200\n",
      "153/153 [==============================] - 0s 585us/step - loss: 0.3765 - accuracy: 0.8149\n",
      "Epoch 154/200\n",
      "153/153 [==============================] - 0s 732us/step - loss: 0.3827 - accuracy: 0.8145\n",
      "Epoch 155/200\n",
      "153/153 [==============================] - 0s 504us/step - loss: 0.3802 - accuracy: 0.8141\n",
      "Epoch 156/200\n",
      "153/153 [==============================] - 0s 467us/step - loss: 0.3807 - accuracy: 0.8114\n",
      "Epoch 157/200\n",
      "153/153 [==============================] - 0s 455us/step - loss: 0.3807 - accuracy: 0.8155\n",
      "Epoch 158/200\n",
      "153/153 [==============================] - 0s 441us/step - loss: 0.3763 - accuracy: 0.8200\n",
      "Epoch 159/200\n",
      "153/153 [==============================] - 0s 753us/step - loss: 0.3788 - accuracy: 0.8164\n",
      "Epoch 160/200\n",
      "153/153 [==============================] - 0s 465us/step - loss: 0.3757 - accuracy: 0.8188\n",
      "Epoch 161/200\n",
      "153/153 [==============================] - 0s 740us/step - loss: 0.3751 - accuracy: 0.8161\n",
      "Epoch 162/200\n",
      "153/153 [==============================] - 0s 526us/step - loss: 0.3786 - accuracy: 0.8157\n",
      "Epoch 163/200\n",
      "153/153 [==============================] - 0s 453us/step - loss: 0.3816 - accuracy: 0.8192\n",
      "Epoch 164/200\n",
      "153/153 [==============================] - 0s 496us/step - loss: 0.3768 - accuracy: 0.8159\n",
      "Epoch 165/200\n",
      "153/153 [==============================] - 0s 530us/step - loss: 0.3777 - accuracy: 0.8164\n",
      "Epoch 166/200\n",
      "153/153 [==============================] - 0s 623us/step - loss: 0.3754 - accuracy: 0.8135\n",
      "Epoch 167/200\n",
      "153/153 [==============================] - 0s 465us/step - loss: 0.3777 - accuracy: 0.8207\n",
      "Epoch 168/200\n",
      "153/153 [==============================] - 0s 483us/step - loss: 0.3790 - accuracy: 0.8215\n",
      "Epoch 169/200\n",
      "153/153 [==============================] - 0s 498us/step - loss: 0.3755 - accuracy: 0.8209\n",
      "Epoch 170/200\n",
      "153/153 [==============================] - 0s 455us/step - loss: 0.3804 - accuracy: 0.8182\n",
      "Epoch 171/200\n",
      "153/153 [==============================] - 0s 446us/step - loss: 0.3768 - accuracy: 0.8166\n",
      "Epoch 172/200\n",
      "153/153 [==============================] - 0s 443us/step - loss: 0.3772 - accuracy: 0.8186\n",
      "Epoch 173/200\n",
      "153/153 [==============================] - 0s 396us/step - loss: 0.3790 - accuracy: 0.8149\n",
      "Epoch 174/200\n",
      "153/153 [==============================] - 0s 409us/step - loss: 0.3808 - accuracy: 0.8180\n",
      "Epoch 175/200\n",
      "153/153 [==============================] - 0s 398us/step - loss: 0.3807 - accuracy: 0.8096\n",
      "Epoch 176/200\n",
      "153/153 [==============================] - 0s 435us/step - loss: 0.3768 - accuracy: 0.8184\n",
      "Epoch 177/200\n",
      "153/153 [==============================] - 0s 413us/step - loss: 0.3751 - accuracy: 0.8256\n",
      "Epoch 178/200\n",
      "153/153 [==============================] - 0s 412us/step - loss: 0.3811 - accuracy: 0.8139\n",
      "Epoch 179/200\n",
      "153/153 [==============================] - 0s 404us/step - loss: 0.3742 - accuracy: 0.8178\n",
      "Epoch 180/200\n",
      "153/153 [==============================] - 0s 428us/step - loss: 0.3835 - accuracy: 0.8110\n",
      "Epoch 181/200\n",
      "153/153 [==============================] - 0s 449us/step - loss: 0.3796 - accuracy: 0.8205\n",
      "Epoch 182/200\n",
      "153/153 [==============================] - 0s 445us/step - loss: 0.3731 - accuracy: 0.8211\n",
      "Epoch 183/200\n",
      "153/153 [==============================] - 0s 411us/step - loss: 0.3710 - accuracy: 0.8242\n",
      "Epoch 184/200\n",
      "153/153 [==============================] - 0s 590us/step - loss: 0.3738 - accuracy: 0.8242\n",
      "Epoch 185/200\n",
      "153/153 [==============================] - 0s 531us/step - loss: 0.3734 - accuracy: 0.8211\n",
      "Epoch 186/200\n",
      "153/153 [==============================] - 0s 551us/step - loss: 0.3788 - accuracy: 0.8129\n",
      "Epoch 187/200\n",
      "153/153 [==============================] - 0s 596us/step - loss: 0.3768 - accuracy: 0.8178\n",
      "Epoch 188/200\n",
      "153/153 [==============================] - 0s 748us/step - loss: 0.3784 - accuracy: 0.8188\n",
      "Epoch 189/200\n",
      "153/153 [==============================] - 0s 477us/step - loss: 0.3727 - accuracy: 0.8176\n",
      "Epoch 190/200\n",
      "153/153 [==============================] - 0s 864us/step - loss: 0.3790 - accuracy: 0.8155\n",
      "Epoch 191/200\n",
      "153/153 [==============================] - 0s 502us/step - loss: 0.3778 - accuracy: 0.8200\n",
      "Epoch 192/200\n",
      "153/153 [==============================] - 0s 499us/step - loss: 0.3779 - accuracy: 0.8182\n",
      "Epoch 193/200\n",
      "153/153 [==============================] - 0s 451us/step - loss: 0.3742 - accuracy: 0.8231\n",
      "Epoch 194/200\n",
      "153/153 [==============================] - 0s 728us/step - loss: 0.3742 - accuracy: 0.8176\n",
      "Epoch 195/200\n",
      "153/153 [==============================] - 0s 395us/step - loss: 0.3753 - accuracy: 0.8227\n",
      "Epoch 196/200\n",
      "153/153 [==============================] - 0s 444us/step - loss: 0.3761 - accuracy: 0.8186\n",
      "Epoch 197/200\n",
      "153/153 [==============================] - 0s 434us/step - loss: 0.3766 - accuracy: 0.8184\n",
      "Epoch 198/200\n",
      "153/153 [==============================] - 0s 444us/step - loss: 0.3715 - accuracy: 0.8233\n",
      "Epoch 199/200\n",
      "153/153 [==============================] - 0s 760us/step - loss: 0.3795 - accuracy: 0.8205\n",
      "Epoch 200/200\n",
      "153/153 [==============================] - 0s 453us/step - loss: 0.3777 - accuracy: 0.8196\n",
      "39/39 [==============================] - 0s 562us/step\n",
      "Epoch 1/200\n",
      "153/153 [==============================] - 0s 470us/step - loss: 0.5842 - accuracy: 0.7188\n",
      "Epoch 2/200\n",
      "153/153 [==============================] - 0s 438us/step - loss: 0.4505 - accuracy: 0.7767\n",
      "Epoch 3/200\n",
      "153/153 [==============================] - 0s 470us/step - loss: 0.4330 - accuracy: 0.7919\n",
      "Epoch 4/200\n",
      "153/153 [==============================] - 0s 514us/step - loss: 0.4341 - accuracy: 0.7894\n",
      "Epoch 5/200\n",
      "153/153 [==============================] - 0s 489us/step - loss: 0.4251 - accuracy: 0.7995\n",
      "Epoch 6/200\n",
      "153/153 [==============================] - 0s 629us/step - loss: 0.4254 - accuracy: 0.7972\n",
      "Epoch 7/200\n",
      "153/153 [==============================] - 0s 504us/step - loss: 0.4240 - accuracy: 0.8016\n",
      "Epoch 8/200\n",
      "153/153 [==============================] - 0s 470us/step - loss: 0.4212 - accuracy: 0.8009\n",
      "Epoch 9/200\n",
      "153/153 [==============================] - 0s 452us/step - loss: 0.4162 - accuracy: 0.8046\n",
      "Epoch 10/200\n",
      "153/153 [==============================] - 0s 429us/step - loss: 0.4169 - accuracy: 0.7991\n",
      "Epoch 11/200\n",
      "153/153 [==============================] - 0s 725us/step - loss: 0.4185 - accuracy: 0.8009\n",
      "Epoch 12/200\n",
      "153/153 [==============================] - 0s 457us/step - loss: 0.4142 - accuracy: 0.8026\n",
      "Epoch 13/200\n",
      "153/153 [==============================] - 0s 477us/step - loss: 0.4197 - accuracy: 0.8005\n",
      "Epoch 14/200\n",
      "153/153 [==============================] - 0s 484us/step - loss: 0.4133 - accuracy: 0.8007\n",
      "Epoch 15/200\n",
      "153/153 [==============================] - 0s 443us/step - loss: 0.4183 - accuracy: 0.8009\n",
      "Epoch 16/200\n",
      "153/153 [==============================] - 0s 436us/step - loss: 0.4151 - accuracy: 0.8079\n",
      "Epoch 17/200\n",
      "153/153 [==============================] - 0s 618us/step - loss: 0.4174 - accuracy: 0.8016\n",
      "Epoch 18/200\n",
      "153/153 [==============================] - 0s 442us/step - loss: 0.4122 - accuracy: 0.8057\n",
      "Epoch 19/200\n",
      "153/153 [==============================] - 0s 434us/step - loss: 0.4134 - accuracy: 0.8040\n",
      "Epoch 20/200\n",
      "153/153 [==============================] - 0s 436us/step - loss: 0.4127 - accuracy: 0.8028\n",
      "Epoch 21/200\n",
      "153/153 [==============================] - 0s 436us/step - loss: 0.4134 - accuracy: 0.8020\n",
      "Epoch 22/200\n",
      "153/153 [==============================] - 0s 444us/step - loss: 0.4101 - accuracy: 0.8104\n",
      "Epoch 23/200\n",
      "153/153 [==============================] - 0s 445us/step - loss: 0.4115 - accuracy: 0.8028\n",
      "Epoch 24/200\n",
      "153/153 [==============================] - 0s 438us/step - loss: 0.4044 - accuracy: 0.8100\n",
      "Epoch 25/200\n",
      "153/153 [==============================] - 0s 429us/step - loss: 0.4101 - accuracy: 0.8051\n",
      "Epoch 26/200\n",
      "153/153 [==============================] - 0s 430us/step - loss: 0.4107 - accuracy: 0.8016\n",
      "Epoch 27/200\n",
      "153/153 [==============================] - 0s 442us/step - loss: 0.4099 - accuracy: 0.8059\n",
      "Epoch 28/200\n",
      "153/153 [==============================] - 0s 439us/step - loss: 0.4069 - accuracy: 0.8088\n",
      "Epoch 29/200\n",
      "153/153 [==============================] - 0s 446us/step - loss: 0.4072 - accuracy: 0.8063\n",
      "Epoch 30/200\n",
      "153/153 [==============================] - 0s 1ms/step - loss: 0.4065 - accuracy: 0.8079\n",
      "Epoch 31/200\n",
      "153/153 [==============================] - 0s 583us/step - loss: 0.4063 - accuracy: 0.8055\n",
      "Epoch 32/200\n",
      "153/153 [==============================] - 0s 491us/step - loss: 0.4054 - accuracy: 0.8102\n",
      "Epoch 33/200\n",
      "153/153 [==============================] - 0s 488us/step - loss: 0.4070 - accuracy: 0.8053\n",
      "Epoch 34/200\n",
      "153/153 [==============================] - 0s 429us/step - loss: 0.4036 - accuracy: 0.8102\n",
      "Epoch 35/200\n",
      "153/153 [==============================] - 0s 430us/step - loss: 0.4022 - accuracy: 0.8075\n",
      "Epoch 36/200\n",
      "153/153 [==============================] - 0s 583us/step - loss: 0.4033 - accuracy: 0.8088\n",
      "Epoch 37/200\n",
      "153/153 [==============================] - 0s 524us/step - loss: 0.4042 - accuracy: 0.8112\n",
      "Epoch 38/200\n",
      "153/153 [==============================] - 0s 447us/step - loss: 0.4050 - accuracy: 0.8085\n",
      "Epoch 39/200\n",
      "153/153 [==============================] - 0s 492us/step - loss: 0.4032 - accuracy: 0.8090\n",
      "Epoch 40/200\n",
      "153/153 [==============================] - 0s 775us/step - loss: 0.4003 - accuracy: 0.8131\n",
      "Epoch 41/200\n",
      "153/153 [==============================] - 0s 497us/step - loss: 0.4043 - accuracy: 0.8088\n",
      "Epoch 42/200\n",
      "153/153 [==============================] - 0s 860us/step - loss: 0.3988 - accuracy: 0.8098\n",
      "Epoch 43/200\n",
      "153/153 [==============================] - 0s 469us/step - loss: 0.4005 - accuracy: 0.8116\n",
      "Epoch 44/200\n",
      "153/153 [==============================] - 0s 439us/step - loss: 0.3980 - accuracy: 0.8120\n",
      "Epoch 45/200\n",
      "153/153 [==============================] - 0s 419us/step - loss: 0.4022 - accuracy: 0.8133\n",
      "Epoch 46/200\n",
      "153/153 [==============================] - 0s 468us/step - loss: 0.3969 - accuracy: 0.8157\n",
      "Epoch 47/200\n",
      "153/153 [==============================] - 0s 626us/step - loss: 0.3995 - accuracy: 0.8081\n",
      "Epoch 48/200\n",
      "153/153 [==============================] - 0s 479us/step - loss: 0.3944 - accuracy: 0.8135\n",
      "Epoch 49/200\n",
      "153/153 [==============================] - 0s 489us/step - loss: 0.4008 - accuracy: 0.8112\n",
      "Epoch 50/200\n",
      "153/153 [==============================] - 0s 603us/step - loss: 0.3978 - accuracy: 0.8151\n",
      "Epoch 51/200\n",
      "153/153 [==============================] - 0s 890us/step - loss: 0.4001 - accuracy: 0.8106\n",
      "Epoch 52/200\n",
      "153/153 [==============================] - 0s 583us/step - loss: 0.3980 - accuracy: 0.8122\n",
      "Epoch 53/200\n",
      "153/153 [==============================] - 0s 534us/step - loss: 0.3940 - accuracy: 0.8088\n",
      "Epoch 54/200\n",
      "153/153 [==============================] - 0s 748us/step - loss: 0.3986 - accuracy: 0.8118\n",
      "Epoch 55/200\n",
      "153/153 [==============================] - 0s 460us/step - loss: 0.3991 - accuracy: 0.8122\n",
      "Epoch 56/200\n",
      "153/153 [==============================] - 0s 407us/step - loss: 0.3965 - accuracy: 0.8122\n",
      "Epoch 57/200\n",
      "153/153 [==============================] - 0s 539us/step - loss: 0.3944 - accuracy: 0.8164\n",
      "Epoch 58/200\n",
      "153/153 [==============================] - 0s 549us/step - loss: 0.3961 - accuracy: 0.8129\n",
      "Epoch 59/200\n",
      "153/153 [==============================] - 0s 585us/step - loss: 0.3955 - accuracy: 0.8112\n",
      "Epoch 60/200\n",
      "153/153 [==============================] - 0s 558us/step - loss: 0.3959 - accuracy: 0.8102\n",
      "Epoch 61/200\n",
      "153/153 [==============================] - 0s 561us/step - loss: 0.3956 - accuracy: 0.8139\n",
      "Epoch 62/200\n",
      "153/153 [==============================] - 0s 1ms/step - loss: 0.3960 - accuracy: 0.8143\n",
      "Epoch 63/200\n",
      "153/153 [==============================] - 0s 463us/step - loss: 0.4032 - accuracy: 0.8059\n",
      "Epoch 64/200\n",
      "153/153 [==============================] - 0s 1ms/step - loss: 0.3958 - accuracy: 0.8122\n",
      "Epoch 65/200\n",
      "153/153 [==============================] - 0s 2ms/step - loss: 0.3972 - accuracy: 0.8159\n",
      "Epoch 66/200\n",
      "153/153 [==============================] - 0s 422us/step - loss: 0.3967 - accuracy: 0.8110\n",
      "Epoch 67/200\n",
      "153/153 [==============================] - 0s 402us/step - loss: 0.3947 - accuracy: 0.8147\n",
      "Epoch 68/200\n",
      "153/153 [==============================] - 0s 474us/step - loss: 0.3933 - accuracy: 0.8131\n",
      "Epoch 69/200\n",
      "153/153 [==============================] - 0s 437us/step - loss: 0.3929 - accuracy: 0.8157\n",
      "Epoch 70/200\n",
      "153/153 [==============================] - 0s 604us/step - loss: 0.3962 - accuracy: 0.8137\n",
      "Epoch 71/200\n",
      "153/153 [==============================] - 0s 517us/step - loss: 0.3935 - accuracy: 0.8153\n",
      "Epoch 72/200\n",
      "153/153 [==============================] - 0s 677us/step - loss: 0.3897 - accuracy: 0.8188\n",
      "Epoch 73/200\n",
      "153/153 [==============================] - 0s 414us/step - loss: 0.3861 - accuracy: 0.8203\n",
      "Epoch 74/200\n",
      "153/153 [==============================] - 0s 444us/step - loss: 0.3895 - accuracy: 0.8141\n",
      "Epoch 75/200\n",
      "153/153 [==============================] - 0s 427us/step - loss: 0.3926 - accuracy: 0.8155\n",
      "Epoch 76/200\n",
      "153/153 [==============================] - 0s 778us/step - loss: 0.3930 - accuracy: 0.8145\n",
      "Epoch 77/200\n",
      "153/153 [==============================] - 0s 422us/step - loss: 0.3971 - accuracy: 0.8112\n",
      "Epoch 78/200\n",
      "153/153 [==============================] - 0s 520us/step - loss: 0.3903 - accuracy: 0.8178\n",
      "Epoch 79/200\n",
      "153/153 [==============================] - 0s 413us/step - loss: 0.3920 - accuracy: 0.8147\n",
      "Epoch 80/200\n",
      "153/153 [==============================] - 0s 443us/step - loss: 0.3923 - accuracy: 0.8157\n",
      "Epoch 81/200\n",
      "153/153 [==============================] - 0s 461us/step - loss: 0.3950 - accuracy: 0.8083\n",
      "Epoch 82/200\n",
      "153/153 [==============================] - 0s 422us/step - loss: 0.3919 - accuracy: 0.8151\n",
      "Epoch 83/200\n",
      "153/153 [==============================] - 0s 437us/step - loss: 0.3916 - accuracy: 0.8137\n",
      "Epoch 84/200\n",
      "153/153 [==============================] - 0s 446us/step - loss: 0.3886 - accuracy: 0.8157\n",
      "Epoch 85/200\n",
      "153/153 [==============================] - 0s 512us/step - loss: 0.3898 - accuracy: 0.8176\n",
      "Epoch 86/200\n",
      "153/153 [==============================] - 0s 500us/step - loss: 0.3918 - accuracy: 0.8147\n",
      "Epoch 87/200\n",
      "153/153 [==============================] - 0s 448us/step - loss: 0.3906 - accuracy: 0.8137\n",
      "Epoch 88/200\n",
      "153/153 [==============================] - 0s 430us/step - loss: 0.3881 - accuracy: 0.8207\n",
      "Epoch 89/200\n",
      "153/153 [==============================] - 0s 447us/step - loss: 0.3922 - accuracy: 0.8194\n",
      "Epoch 90/200\n",
      "153/153 [==============================] - 0s 453us/step - loss: 0.3903 - accuracy: 0.8161\n",
      "Epoch 91/200\n",
      "153/153 [==============================] - 0s 462us/step - loss: 0.3897 - accuracy: 0.8200\n",
      "Epoch 92/200\n",
      "153/153 [==============================] - 0s 638us/step - loss: 0.3855 - accuracy: 0.8203\n",
      "Epoch 93/200\n",
      "153/153 [==============================] - 0s 588us/step - loss: 0.3902 - accuracy: 0.8159\n",
      "Epoch 94/200\n",
      "153/153 [==============================] - 0s 830us/step - loss: 0.3984 - accuracy: 0.8143\n",
      "Epoch 95/200\n",
      "153/153 [==============================] - 0s 807us/step - loss: 0.3865 - accuracy: 0.8153\n",
      "Epoch 96/200\n",
      "153/153 [==============================] - 0s 639us/step - loss: 0.3897 - accuracy: 0.8188\n",
      "Epoch 97/200\n",
      "153/153 [==============================] - 0s 480us/step - loss: 0.3907 - accuracy: 0.8129\n",
      "Epoch 98/200\n",
      "153/153 [==============================] - 0s 484us/step - loss: 0.3899 - accuracy: 0.8188\n",
      "Epoch 99/200\n",
      "153/153 [==============================] - 0s 660us/step - loss: 0.3931 - accuracy: 0.8114\n",
      "Epoch 100/200\n",
      "153/153 [==============================] - 0s 613us/step - loss: 0.3861 - accuracy: 0.8244\n",
      "Epoch 101/200\n",
      "153/153 [==============================] - 0s 1ms/step - loss: 0.3875 - accuracy: 0.8194\n",
      "Epoch 102/200\n",
      "153/153 [==============================] - 0s 759us/step - loss: 0.3912 - accuracy: 0.8147\n",
      "Epoch 103/200\n",
      "153/153 [==============================] - 0s 508us/step - loss: 0.3888 - accuracy: 0.8168\n",
      "Epoch 104/200\n",
      "153/153 [==============================] - 0s 491us/step - loss: 0.3901 - accuracy: 0.8205\n",
      "Epoch 105/200\n",
      "153/153 [==============================] - 0s 477us/step - loss: 0.3910 - accuracy: 0.8155\n",
      "Epoch 106/200\n",
      "153/153 [==============================] - 0s 799us/step - loss: 0.3879 - accuracy: 0.8182\n",
      "Epoch 107/200\n",
      "153/153 [==============================] - 0s 468us/step - loss: 0.3906 - accuracy: 0.8200\n",
      "Epoch 108/200\n",
      "153/153 [==============================] - 0s 485us/step - loss: 0.3899 - accuracy: 0.8182\n",
      "Epoch 109/200\n",
      "153/153 [==============================] - 0s 440us/step - loss: 0.3872 - accuracy: 0.8194\n",
      "Epoch 110/200\n",
      "153/153 [==============================] - 0s 1ms/step - loss: 0.3858 - accuracy: 0.8229\n",
      "Epoch 111/200\n",
      "153/153 [==============================] - 0s 727us/step - loss: 0.3896 - accuracy: 0.8164\n",
      "Epoch 112/200\n",
      "153/153 [==============================] - 0s 491us/step - loss: 0.3890 - accuracy: 0.8166\n",
      "Epoch 113/200\n",
      "153/153 [==============================] - 0s 451us/step - loss: 0.3892 - accuracy: 0.8170\n",
      "Epoch 114/200\n",
      "153/153 [==============================] - 0s 498us/step - loss: 0.3890 - accuracy: 0.8190\n",
      "Epoch 115/200\n",
      "153/153 [==============================] - 0s 947us/step - loss: 0.3834 - accuracy: 0.8268\n",
      "Epoch 116/200\n",
      "153/153 [==============================] - 0s 510us/step - loss: 0.3893 - accuracy: 0.8137\n",
      "Epoch 117/200\n",
      "153/153 [==============================] - 0s 506us/step - loss: 0.3867 - accuracy: 0.8235\n",
      "Epoch 118/200\n",
      "153/153 [==============================] - 0s 544us/step - loss: 0.3873 - accuracy: 0.8205\n",
      "Epoch 119/200\n",
      "153/153 [==============================] - 0s 514us/step - loss: 0.3898 - accuracy: 0.8196\n",
      "Epoch 120/200\n",
      "153/153 [==============================] - 0s 460us/step - loss: 0.3873 - accuracy: 0.8147\n",
      "Epoch 121/200\n",
      "153/153 [==============================] - 0s 452us/step - loss: 0.3895 - accuracy: 0.8170\n",
      "Epoch 122/200\n",
      "153/153 [==============================] - 0s 479us/step - loss: 0.3841 - accuracy: 0.8198\n",
      "Epoch 123/200\n",
      "153/153 [==============================] - 0s 427us/step - loss: 0.3879 - accuracy: 0.8205\n",
      "Epoch 124/200\n",
      "153/153 [==============================] - 0s 426us/step - loss: 0.3794 - accuracy: 0.8268\n",
      "Epoch 125/200\n",
      "153/153 [==============================] - 0s 566us/step - loss: 0.3891 - accuracy: 0.8166\n",
      "Epoch 126/200\n",
      "153/153 [==============================] - 0s 449us/step - loss: 0.3861 - accuracy: 0.8211\n",
      "Epoch 127/200\n",
      "153/153 [==============================] - 0s 442us/step - loss: 0.3850 - accuracy: 0.8194\n",
      "Epoch 128/200\n",
      "153/153 [==============================] - 0s 445us/step - loss: 0.3871 - accuracy: 0.8225\n",
      "Epoch 129/200\n",
      "153/153 [==============================] - 0s 703us/step - loss: 0.3899 - accuracy: 0.8192\n",
      "Epoch 130/200\n",
      "153/153 [==============================] - 0s 503us/step - loss: 0.3856 - accuracy: 0.8203\n",
      "Epoch 131/200\n",
      "153/153 [==============================] - 0s 443us/step - loss: 0.3884 - accuracy: 0.8166\n",
      "Epoch 132/200\n",
      "153/153 [==============================] - 0s 444us/step - loss: 0.3858 - accuracy: 0.8200\n",
      "Epoch 133/200\n",
      "153/153 [==============================] - 0s 426us/step - loss: 0.3853 - accuracy: 0.8213\n",
      "Epoch 134/200\n",
      "153/153 [==============================] - 0s 442us/step - loss: 0.3795 - accuracy: 0.8262\n",
      "Epoch 135/200\n",
      "153/153 [==============================] - 0s 444us/step - loss: 0.3843 - accuracy: 0.8184\n",
      "Epoch 136/200\n",
      "153/153 [==============================] - 0s 437us/step - loss: 0.3806 - accuracy: 0.8260\n",
      "Epoch 137/200\n",
      "153/153 [==============================] - 0s 443us/step - loss: 0.3846 - accuracy: 0.8186\n",
      "Epoch 138/200\n",
      "153/153 [==============================] - 0s 428us/step - loss: 0.3835 - accuracy: 0.8254\n",
      "Epoch 139/200\n",
      "153/153 [==============================] - 0s 410us/step - loss: 0.3834 - accuracy: 0.8233\n",
      "Epoch 140/200\n",
      "153/153 [==============================] - 0s 439us/step - loss: 0.3894 - accuracy: 0.8161\n",
      "Epoch 141/200\n",
      "153/153 [==============================] - 0s 446us/step - loss: 0.3842 - accuracy: 0.8258\n",
      "Epoch 142/200\n",
      "153/153 [==============================] - 0s 500us/step - loss: 0.3877 - accuracy: 0.8198\n",
      "Epoch 143/200\n",
      "153/153 [==============================] - 0s 477us/step - loss: 0.3842 - accuracy: 0.8248\n",
      "Epoch 144/200\n",
      "153/153 [==============================] - 0s 447us/step - loss: 0.3818 - accuracy: 0.8223\n",
      "Epoch 145/200\n",
      "153/153 [==============================] - 0s 436us/step - loss: 0.3902 - accuracy: 0.8217\n",
      "Epoch 146/200\n",
      "153/153 [==============================] - 0s 437us/step - loss: 0.3823 - accuracy: 0.8200\n",
      "Epoch 147/200\n",
      "153/153 [==============================] - 0s 445us/step - loss: 0.3876 - accuracy: 0.8178\n",
      "Epoch 148/200\n",
      "153/153 [==============================] - 0s 439us/step - loss: 0.3871 - accuracy: 0.8205\n",
      "Epoch 149/200\n",
      "153/153 [==============================] - 0s 442us/step - loss: 0.3809 - accuracy: 0.8233\n",
      "Epoch 150/200\n",
      "153/153 [==============================] - 0s 440us/step - loss: 0.3894 - accuracy: 0.8151\n",
      "Epoch 151/200\n",
      "153/153 [==============================] - 0s 445us/step - loss: 0.3846 - accuracy: 0.8217\n",
      "Epoch 152/200\n",
      "153/153 [==============================] - 0s 463us/step - loss: 0.3859 - accuracy: 0.8227\n",
      "Epoch 153/200\n",
      "153/153 [==============================] - 0s 439us/step - loss: 0.3855 - accuracy: 0.8221\n",
      "Epoch 154/200\n",
      "153/153 [==============================] - 0s 443us/step - loss: 0.3831 - accuracy: 0.8217\n",
      "Epoch 155/200\n",
      "153/153 [==============================] - 0s 643us/step - loss: 0.3823 - accuracy: 0.8231\n",
      "Epoch 156/200\n",
      "153/153 [==============================] - 0s 548us/step - loss: 0.3822 - accuracy: 0.8200\n",
      "Epoch 157/200\n",
      "153/153 [==============================] - 0s 486us/step - loss: 0.3838 - accuracy: 0.8215\n",
      "Epoch 158/200\n",
      "153/153 [==============================] - 0s 573us/step - loss: 0.3815 - accuracy: 0.8240\n",
      "Epoch 159/200\n",
      "153/153 [==============================] - 0s 517us/step - loss: 0.3816 - accuracy: 0.8213\n",
      "Epoch 160/200\n",
      "153/153 [==============================] - 0s 460us/step - loss: 0.3804 - accuracy: 0.8233\n",
      "Epoch 161/200\n",
      "153/153 [==============================] - 0s 460us/step - loss: 0.3855 - accuracy: 0.8211\n",
      "Epoch 162/200\n",
      "153/153 [==============================] - 0s 470us/step - loss: 0.3798 - accuracy: 0.8279\n",
      "Epoch 163/200\n",
      "153/153 [==============================] - 0s 767us/step - loss: 0.3873 - accuracy: 0.8180\n",
      "Epoch 164/200\n",
      "153/153 [==============================] - 0s 489us/step - loss: 0.3842 - accuracy: 0.8237\n",
      "Epoch 165/200\n",
      "153/153 [==============================] - 0s 453us/step - loss: 0.3799 - accuracy: 0.8225\n",
      "Epoch 166/200\n",
      "153/153 [==============================] - 0s 451us/step - loss: 0.3841 - accuracy: 0.8240\n",
      "Epoch 167/200\n",
      "153/153 [==============================] - 0s 666us/step - loss: 0.3825 - accuracy: 0.8217\n",
      "Epoch 168/200\n",
      "153/153 [==============================] - 0s 445us/step - loss: 0.3818 - accuracy: 0.8217\n",
      "Epoch 169/200\n",
      "153/153 [==============================] - 0s 445us/step - loss: 0.3815 - accuracy: 0.8229\n",
      "Epoch 170/200\n",
      "153/153 [==============================] - 0s 445us/step - loss: 0.3839 - accuracy: 0.8200\n",
      "Epoch 171/200\n",
      "153/153 [==============================] - 0s 447us/step - loss: 0.3839 - accuracy: 0.8194\n",
      "Epoch 172/200\n",
      "153/153 [==============================] - 0s 451us/step - loss: 0.3841 - accuracy: 0.8246\n",
      "Epoch 173/200\n",
      "153/153 [==============================] - 0s 449us/step - loss: 0.3885 - accuracy: 0.8161\n",
      "Epoch 174/200\n",
      "153/153 [==============================] - 0s 469us/step - loss: 0.3826 - accuracy: 0.8209\n",
      "Epoch 175/200\n",
      "153/153 [==============================] - 0s 439us/step - loss: 0.3799 - accuracy: 0.8285\n",
      "Epoch 176/200\n",
      "153/153 [==============================] - 0s 453us/step - loss: 0.3858 - accuracy: 0.8207\n",
      "Epoch 177/200\n",
      "153/153 [==============================] - 0s 497us/step - loss: 0.3830 - accuracy: 0.8205\n",
      "Epoch 178/200\n",
      "153/153 [==============================] - 0s 609us/step - loss: 0.3750 - accuracy: 0.8268\n",
      "Epoch 179/200\n",
      "153/153 [==============================] - 0s 453us/step - loss: 0.3871 - accuracy: 0.8240\n",
      "Epoch 180/200\n",
      "153/153 [==============================] - 0s 479us/step - loss: 0.3822 - accuracy: 0.8231\n",
      "Epoch 181/200\n",
      "153/153 [==============================] - 0s 459us/step - loss: 0.3834 - accuracy: 0.8231\n",
      "Epoch 182/200\n",
      "153/153 [==============================] - 0s 481us/step - loss: 0.3867 - accuracy: 0.8198\n",
      "Epoch 183/200\n",
      "153/153 [==============================] - 0s 479us/step - loss: 0.3820 - accuracy: 0.8198\n",
      "Epoch 184/200\n",
      "153/153 [==============================] - 0s 500us/step - loss: 0.3804 - accuracy: 0.8272\n",
      "Epoch 185/200\n",
      "153/153 [==============================] - 0s 501us/step - loss: 0.3822 - accuracy: 0.8254\n",
      "Epoch 186/200\n",
      "153/153 [==============================] - 0s 501us/step - loss: 0.3830 - accuracy: 0.8184\n",
      "Epoch 187/200\n",
      "153/153 [==============================] - 0s 779us/step - loss: 0.3856 - accuracy: 0.8209\n",
      "Epoch 188/200\n",
      "153/153 [==============================] - 0s 451us/step - loss: 0.3827 - accuracy: 0.8219\n",
      "Epoch 189/200\n",
      "153/153 [==============================] - 0s 438us/step - loss: 0.3814 - accuracy: 0.8227\n",
      "Epoch 190/200\n",
      "153/153 [==============================] - 0s 438us/step - loss: 0.3777 - accuracy: 0.8237\n",
      "Epoch 191/200\n",
      "153/153 [==============================] - 0s 454us/step - loss: 0.3823 - accuracy: 0.8231\n",
      "Epoch 192/200\n",
      "153/153 [==============================] - 0s 439us/step - loss: 0.3866 - accuracy: 0.8217\n",
      "Epoch 193/200\n",
      "153/153 [==============================] - 0s 462us/step - loss: 0.3813 - accuracy: 0.8258\n",
      "Epoch 194/200\n",
      "153/153 [==============================] - 0s 452us/step - loss: 0.3790 - accuracy: 0.8254\n",
      "Epoch 195/200\n",
      "153/153 [==============================] - 0s 436us/step - loss: 0.3775 - accuracy: 0.8260\n",
      "Epoch 196/200\n",
      "153/153 [==============================] - 0s 455us/step - loss: 0.3797 - accuracy: 0.8266\n",
      "Epoch 197/200\n",
      "153/153 [==============================] - 0s 483us/step - loss: 0.3799 - accuracy: 0.8258\n",
      "Epoch 198/200\n",
      "153/153 [==============================] - 0s 468us/step - loss: 0.3786 - accuracy: 0.8266\n",
      "Epoch 199/200\n",
      "153/153 [==============================] - 0s 846us/step - loss: 0.3852 - accuracy: 0.8194\n",
      "Epoch 200/200\n",
      "153/153 [==============================] - 0s 464us/step - loss: 0.3770 - accuracy: 0.8316\n",
      "39/39 [==============================] - 0s 369us/step\n",
      "Epoch 1/200\n",
      "153/153 [==============================] - 0s 504us/step - loss: 0.5762 - accuracy: 0.7319\n",
      "Epoch 2/200\n",
      "153/153 [==============================] - 0s 453us/step - loss: 0.4442 - accuracy: 0.7849\n",
      "Epoch 3/200\n",
      "153/153 [==============================] - 0s 451us/step - loss: 0.4358 - accuracy: 0.7872\n",
      "Epoch 4/200\n",
      "153/153 [==============================] - 0s 444us/step - loss: 0.4350 - accuracy: 0.7954\n",
      "Epoch 5/200\n",
      "153/153 [==============================] - 0s 429us/step - loss: 0.4307 - accuracy: 0.7919\n",
      "Epoch 6/200\n",
      "153/153 [==============================] - 0s 447us/step - loss: 0.4257 - accuracy: 0.7993\n",
      "Epoch 7/200\n",
      "153/153 [==============================] - 0s 449us/step - loss: 0.4246 - accuracy: 0.7985\n",
      "Epoch 8/200\n",
      "153/153 [==============================] - 0s 448us/step - loss: 0.4258 - accuracy: 0.7966\n",
      "Epoch 9/200\n",
      "153/153 [==============================] - 0s 441us/step - loss: 0.4197 - accuracy: 0.8020\n",
      "Epoch 10/200\n",
      "153/153 [==============================] - 0s 424us/step - loss: 0.4215 - accuracy: 0.7987\n",
      "Epoch 11/200\n",
      "153/153 [==============================] - 0s 448us/step - loss: 0.4212 - accuracy: 0.7956\n",
      "Epoch 12/200\n",
      "153/153 [==============================] - 0s 464us/step - loss: 0.4199 - accuracy: 0.7987\n",
      "Epoch 13/200\n",
      "153/153 [==============================] - 0s 443us/step - loss: 0.4151 - accuracy: 0.7989\n",
      "Epoch 14/200\n",
      "153/153 [==============================] - 0s 517us/step - loss: 0.4204 - accuracy: 0.7991\n",
      "Epoch 15/200\n",
      "153/153 [==============================] - 0s 450us/step - loss: 0.4166 - accuracy: 0.7993\n",
      "Epoch 16/200\n",
      "153/153 [==============================] - 0s 451us/step - loss: 0.4137 - accuracy: 0.8014\n",
      "Epoch 17/200\n",
      "153/153 [==============================] - 0s 575us/step - loss: 0.4132 - accuracy: 0.8046\n",
      "Epoch 18/200\n",
      "153/153 [==============================] - 0s 442us/step - loss: 0.4099 - accuracy: 0.8104\n",
      "Epoch 19/200\n",
      "153/153 [==============================] - 0s 447us/step - loss: 0.4143 - accuracy: 0.8036\n",
      "Epoch 20/200\n",
      "153/153 [==============================] - 0s 450us/step - loss: 0.4115 - accuracy: 0.8090\n",
      "Epoch 21/200\n",
      "153/153 [==============================] - 0s 464us/step - loss: 0.4121 - accuracy: 0.8051\n",
      "Epoch 22/200\n",
      "153/153 [==============================] - 0s 438us/step - loss: 0.4077 - accuracy: 0.8081\n",
      "Epoch 23/200\n",
      "153/153 [==============================] - 0s 770us/step - loss: 0.4116 - accuracy: 0.8038\n",
      "Epoch 24/200\n",
      "153/153 [==============================] - 0s 454us/step - loss: 0.4090 - accuracy: 0.8053\n",
      "Epoch 25/200\n",
      "153/153 [==============================] - 0s 441us/step - loss: 0.4106 - accuracy: 0.8053\n",
      "Epoch 26/200\n",
      "153/153 [==============================] - 0s 445us/step - loss: 0.4060 - accuracy: 0.8092\n",
      "Epoch 27/200\n",
      "153/153 [==============================] - 0s 451us/step - loss: 0.4103 - accuracy: 0.8061\n",
      "Epoch 28/200\n",
      "153/153 [==============================] - 0s 658us/step - loss: 0.4077 - accuracy: 0.8079\n",
      "Epoch 29/200\n",
      "153/153 [==============================] - 0s 542us/step - loss: 0.4067 - accuracy: 0.8096\n",
      "Epoch 30/200\n",
      "153/153 [==============================] - 0s 461us/step - loss: 0.4048 - accuracy: 0.8083\n",
      "Epoch 31/200\n",
      "153/153 [==============================] - 0s 476us/step - loss: 0.4045 - accuracy: 0.8048\n",
      "Epoch 32/200\n",
      "153/153 [==============================] - 0s 510us/step - loss: 0.4047 - accuracy: 0.8075\n",
      "Epoch 33/200\n",
      "153/153 [==============================] - 0s 470us/step - loss: 0.4039 - accuracy: 0.8067\n",
      "Epoch 34/200\n",
      "153/153 [==============================] - 0s 476us/step - loss: 0.4014 - accuracy: 0.8079\n",
      "Epoch 35/200\n",
      "153/153 [==============================] - 0s 443us/step - loss: 0.4011 - accuracy: 0.8077\n",
      "Epoch 36/200\n",
      "153/153 [==============================] - 0s 475us/step - loss: 0.4061 - accuracy: 0.8044\n",
      "Epoch 37/200\n",
      "153/153 [==============================] - 0s 450us/step - loss: 0.4063 - accuracy: 0.8088\n",
      "Epoch 38/200\n",
      "153/153 [==============================] - 0s 451us/step - loss: 0.4023 - accuracy: 0.8083\n",
      "Epoch 39/200\n",
      "153/153 [==============================] - 0s 442us/step - loss: 0.4043 - accuracy: 0.8069\n",
      "Epoch 40/200\n",
      "153/153 [==============================] - 0s 435us/step - loss: 0.3997 - accuracy: 0.8048\n",
      "Epoch 41/200\n",
      "153/153 [==============================] - 0s 443us/step - loss: 0.4023 - accuracy: 0.8057\n",
      "Epoch 42/200\n",
      "153/153 [==============================] - 0s 477us/step - loss: 0.4033 - accuracy: 0.8081\n",
      "Epoch 43/200\n",
      "153/153 [==============================] - 0s 423us/step - loss: 0.4038 - accuracy: 0.8061\n",
      "Epoch 44/200\n",
      "153/153 [==============================] - 0s 434us/step - loss: 0.4028 - accuracy: 0.8069\n",
      "Epoch 45/200\n",
      "153/153 [==============================] - 0s 424us/step - loss: 0.4004 - accuracy: 0.8075\n",
      "Epoch 46/200\n",
      "153/153 [==============================] - 0s 448us/step - loss: 0.3973 - accuracy: 0.8092\n",
      "Epoch 47/200\n",
      "153/153 [==============================] - 0s 588us/step - loss: 0.3988 - accuracy: 0.8094\n",
      "Epoch 48/200\n",
      "153/153 [==============================] - 0s 502us/step - loss: 0.3992 - accuracy: 0.8096\n",
      "Epoch 49/200\n",
      "153/153 [==============================] - 0s 440us/step - loss: 0.3998 - accuracy: 0.8065\n",
      "Epoch 50/200\n",
      "153/153 [==============================] - 0s 446us/step - loss: 0.3994 - accuracy: 0.8044\n",
      "Epoch 51/200\n",
      "153/153 [==============================] - 0s 437us/step - loss: 0.4009 - accuracy: 0.8036\n",
      "Epoch 52/200\n",
      "153/153 [==============================] - 0s 454us/step - loss: 0.3999 - accuracy: 0.8122\n",
      "Epoch 53/200\n",
      "153/153 [==============================] - 0s 705us/step - loss: 0.3945 - accuracy: 0.8092\n",
      "Epoch 54/200\n",
      "153/153 [==============================] - 0s 439us/step - loss: 0.3972 - accuracy: 0.8088\n",
      "Epoch 55/200\n",
      "153/153 [==============================] - 0s 529us/step - loss: 0.3979 - accuracy: 0.8034\n",
      "Epoch 56/200\n",
      "153/153 [==============================] - 0s 432us/step - loss: 0.3981 - accuracy: 0.8100\n",
      "Epoch 57/200\n",
      "153/153 [==============================] - 0s 441us/step - loss: 0.4008 - accuracy: 0.8001\n",
      "Epoch 58/200\n",
      "153/153 [==============================] - 0s 462us/step - loss: 0.3989 - accuracy: 0.8030\n",
      "Epoch 59/200\n",
      "153/153 [==============================] - 0s 547us/step - loss: 0.4004 - accuracy: 0.8046\n",
      "Epoch 60/200\n",
      "153/153 [==============================] - 0s 434us/step - loss: 0.3977 - accuracy: 0.8069\n",
      "Epoch 61/200\n",
      "153/153 [==============================] - 0s 437us/step - loss: 0.3956 - accuracy: 0.8079\n",
      "Epoch 62/200\n",
      "153/153 [==============================] - 0s 440us/step - loss: 0.3967 - accuracy: 0.8092\n",
      "Epoch 63/200\n",
      "153/153 [==============================] - 0s 708us/step - loss: 0.3980 - accuracy: 0.8069\n",
      "Epoch 64/200\n",
      "153/153 [==============================] - 0s 454us/step - loss: 0.3929 - accuracy: 0.8085\n",
      "Epoch 65/200\n",
      "153/153 [==============================] - 0s 537us/step - loss: 0.3986 - accuracy: 0.8026\n",
      "Epoch 66/200\n",
      "153/153 [==============================] - 0s 454us/step - loss: 0.3974 - accuracy: 0.8059\n",
      "Epoch 67/200\n",
      "153/153 [==============================] - 0s 466us/step - loss: 0.3910 - accuracy: 0.8090\n",
      "Epoch 68/200\n",
      "153/153 [==============================] - 0s 455us/step - loss: 0.3961 - accuracy: 0.8057\n",
      "Epoch 69/200\n",
      "153/153 [==============================] - 0s 454us/step - loss: 0.3952 - accuracy: 0.8067\n",
      "Epoch 70/200\n",
      "153/153 [==============================] - 0s 754us/step - loss: 0.3970 - accuracy: 0.8051\n",
      "Epoch 71/200\n",
      "153/153 [==============================] - 0s 477us/step - loss: 0.3928 - accuracy: 0.8059\n",
      "Epoch 72/200\n",
      "153/153 [==============================] - 0s 447us/step - loss: 0.3897 - accuracy: 0.8112\n",
      "Epoch 73/200\n",
      "153/153 [==============================] - 0s 452us/step - loss: 0.3919 - accuracy: 0.8065\n",
      "Epoch 74/200\n",
      "153/153 [==============================] - 0s 439us/step - loss: 0.3955 - accuracy: 0.8100\n",
      "Epoch 75/200\n",
      "153/153 [==============================] - 0s 445us/step - loss: 0.3917 - accuracy: 0.8071\n",
      "Epoch 76/200\n",
      "153/153 [==============================] - 0s 457us/step - loss: 0.3912 - accuracy: 0.8122\n",
      "Epoch 77/200\n",
      "153/153 [==============================] - 0s 456us/step - loss: 0.3903 - accuracy: 0.8106\n",
      "Epoch 78/200\n",
      "153/153 [==============================] - 0s 452us/step - loss: 0.3888 - accuracy: 0.8120\n",
      "Epoch 79/200\n",
      "153/153 [==============================] - 0s 604us/step - loss: 0.3900 - accuracy: 0.8108\n",
      "Epoch 80/200\n",
      "153/153 [==============================] - 0s 446us/step - loss: 0.3909 - accuracy: 0.8092\n",
      "Epoch 81/200\n",
      "153/153 [==============================] - 0s 435us/step - loss: 0.3893 - accuracy: 0.8102\n",
      "Epoch 82/200\n",
      "153/153 [==============================] - 0s 444us/step - loss: 0.3912 - accuracy: 0.8131\n",
      "Epoch 83/200\n",
      "153/153 [==============================] - 0s 444us/step - loss: 0.3916 - accuracy: 0.8071\n",
      "Epoch 84/200\n",
      "153/153 [==============================] - 0s 455us/step - loss: 0.3860 - accuracy: 0.8164\n",
      "Epoch 85/200\n",
      "153/153 [==============================] - 0s 457us/step - loss: 0.3915 - accuracy: 0.8098\n",
      "Epoch 86/200\n",
      "153/153 [==============================] - 0s 579us/step - loss: 0.3926 - accuracy: 0.8036\n",
      "Epoch 87/200\n",
      "153/153 [==============================] - 0s 432us/step - loss: 0.3946 - accuracy: 0.8014\n",
      "Epoch 88/200\n",
      "153/153 [==============================] - 0s 441us/step - loss: 0.3915 - accuracy: 0.8108\n",
      "Epoch 89/200\n",
      "153/153 [==============================] - 0s 442us/step - loss: 0.3937 - accuracy: 0.8100\n",
      "Epoch 90/200\n",
      "153/153 [==============================] - 0s 455us/step - loss: 0.3890 - accuracy: 0.8112\n",
      "Epoch 91/200\n",
      "153/153 [==============================] - 0s 726us/step - loss: 0.3863 - accuracy: 0.8133\n",
      "Epoch 92/200\n",
      "153/153 [==============================] - 0s 463us/step - loss: 0.3896 - accuracy: 0.8110\n",
      "Epoch 93/200\n",
      "153/153 [==============================] - 0s 458us/step - loss: 0.3927 - accuracy: 0.8112\n",
      "Epoch 94/200\n",
      "153/153 [==============================] - 0s 447us/step - loss: 0.3909 - accuracy: 0.8100\n",
      "Epoch 95/200\n",
      "153/153 [==============================] - 0s 454us/step - loss: 0.3891 - accuracy: 0.8094\n",
      "Epoch 96/200\n",
      "153/153 [==============================] - 0s 495us/step - loss: 0.3909 - accuracy: 0.8100\n",
      "Epoch 97/200\n",
      "153/153 [==============================] - 0s 446us/step - loss: 0.3913 - accuracy: 0.8090\n",
      "Epoch 98/200\n",
      "153/153 [==============================] - 0s 440us/step - loss: 0.3879 - accuracy: 0.8112\n",
      "Epoch 99/200\n",
      "153/153 [==============================] - 0s 440us/step - loss: 0.3898 - accuracy: 0.8085\n",
      "Epoch 100/200\n",
      "153/153 [==============================] - 0s 447us/step - loss: 0.3830 - accuracy: 0.8196\n",
      "Epoch 101/200\n",
      "153/153 [==============================] - 0s 442us/step - loss: 0.3883 - accuracy: 0.8133\n",
      "Epoch 102/200\n",
      "153/153 [==============================] - 0s 447us/step - loss: 0.3889 - accuracy: 0.8106\n",
      "Epoch 103/200\n",
      "153/153 [==============================] - 0s 442us/step - loss: 0.3888 - accuracy: 0.8071\n",
      "Epoch 104/200\n",
      "153/153 [==============================] - 0s 437us/step - loss: 0.3939 - accuracy: 0.8090\n",
      "Epoch 105/200\n",
      "153/153 [==============================] - 0s 437us/step - loss: 0.3918 - accuracy: 0.8090\n",
      "Epoch 106/200\n",
      "153/153 [==============================] - 0s 496us/step - loss: 0.3887 - accuracy: 0.8098\n",
      "Epoch 107/200\n",
      "153/153 [==============================] - 0s 501us/step - loss: 0.3913 - accuracy: 0.8079\n",
      "Epoch 108/200\n",
      "153/153 [==============================] - 0s 443us/step - loss: 0.3906 - accuracy: 0.8104\n",
      "Epoch 109/200\n",
      "153/153 [==============================] - 0s 659us/step - loss: 0.3882 - accuracy: 0.8077\n",
      "Epoch 110/200\n",
      "153/153 [==============================] - 0s 447us/step - loss: 0.3865 - accuracy: 0.8116\n",
      "Epoch 111/200\n",
      "153/153 [==============================] - 0s 447us/step - loss: 0.3908 - accuracy: 0.8098\n",
      "Epoch 112/200\n",
      "153/153 [==============================] - 0s 442us/step - loss: 0.3905 - accuracy: 0.8083\n",
      "Epoch 113/200\n",
      "153/153 [==============================] - 0s 484us/step - loss: 0.3895 - accuracy: 0.8108\n",
      "Epoch 114/200\n",
      "153/153 [==============================] - 0s 762us/step - loss: 0.3927 - accuracy: 0.8055\n",
      "Epoch 115/200\n",
      "153/153 [==============================] - 0s 442us/step - loss: 0.3883 - accuracy: 0.8096\n",
      "Epoch 116/200\n",
      "153/153 [==============================] - 0s 423us/step - loss: 0.3817 - accuracy: 0.8124\n",
      "Epoch 117/200\n",
      "153/153 [==============================] - 0s 435us/step - loss: 0.3887 - accuracy: 0.8124\n",
      "Epoch 118/200\n",
      "153/153 [==============================] - 0s 450us/step - loss: 0.3862 - accuracy: 0.8133\n",
      "Epoch 119/200\n",
      "153/153 [==============================] - 0s 420us/step - loss: 0.3879 - accuracy: 0.8133\n",
      "Epoch 120/200\n",
      "153/153 [==============================] - 0s 492us/step - loss: 0.3883 - accuracy: 0.8067\n",
      "Epoch 121/200\n",
      "153/153 [==============================] - 0s 464us/step - loss: 0.3881 - accuracy: 0.8079\n",
      "Epoch 122/200\n",
      "153/153 [==============================] - 0s 452us/step - loss: 0.3901 - accuracy: 0.8083\n",
      "Epoch 123/200\n",
      "153/153 [==============================] - 0s 424us/step - loss: 0.3856 - accuracy: 0.8104\n",
      "Epoch 124/200\n",
      "153/153 [==============================] - 0s 443us/step - loss: 0.3808 - accuracy: 0.8090\n",
      "Epoch 125/200\n",
      "153/153 [==============================] - 0s 702us/step - loss: 0.3840 - accuracy: 0.8145\n",
      "Epoch 126/200\n",
      "153/153 [==============================] - 0s 462us/step - loss: 0.3841 - accuracy: 0.8131\n",
      "Epoch 127/200\n",
      "153/153 [==============================] - 0s 508us/step - loss: 0.3831 - accuracy: 0.8100\n",
      "Epoch 128/200\n",
      "153/153 [==============================] - 0s 458us/step - loss: 0.3864 - accuracy: 0.8133\n",
      "Epoch 129/200\n",
      "153/153 [==============================] - 0s 468us/step - loss: 0.3898 - accuracy: 0.8159\n",
      "Epoch 130/200\n",
      "153/153 [==============================] - 0s 450us/step - loss: 0.3857 - accuracy: 0.8085\n",
      "Epoch 131/200\n",
      "153/153 [==============================] - 0s 468us/step - loss: 0.3881 - accuracy: 0.8088\n",
      "Epoch 132/200\n",
      "153/153 [==============================] - 0s 458us/step - loss: 0.3865 - accuracy: 0.8079\n",
      "Epoch 133/200\n",
      "153/153 [==============================] - 0s 466us/step - loss: 0.3830 - accuracy: 0.8135\n",
      "Epoch 134/200\n",
      "153/153 [==============================] - 0s 443us/step - loss: 0.3849 - accuracy: 0.8100\n",
      "Epoch 135/200\n",
      "153/153 [==============================] - 0s 455us/step - loss: 0.3875 - accuracy: 0.8081\n",
      "Epoch 136/200\n",
      "153/153 [==============================] - 0s 449us/step - loss: 0.3871 - accuracy: 0.8122\n",
      "Epoch 137/200\n",
      "153/153 [==============================] - 0s 448us/step - loss: 0.3871 - accuracy: 0.8155\n",
      "Epoch 138/200\n",
      "153/153 [==============================] - 0s 434us/step - loss: 0.3862 - accuracy: 0.8155\n",
      "Epoch 139/200\n",
      "153/153 [==============================] - 0s 497us/step - loss: 0.3836 - accuracy: 0.8096\n",
      "Epoch 140/200\n",
      "153/153 [==============================] - 0s 443us/step - loss: 0.3876 - accuracy: 0.8135\n",
      "Epoch 141/200\n",
      "153/153 [==============================] - 0s 446us/step - loss: 0.3853 - accuracy: 0.8118\n",
      "Epoch 142/200\n",
      "153/153 [==============================] - 0s 433us/step - loss: 0.3864 - accuracy: 0.8088\n",
      "Epoch 143/200\n",
      "153/153 [==============================] - 0s 435us/step - loss: 0.3843 - accuracy: 0.8145\n",
      "Epoch 144/200\n",
      "153/153 [==============================] - 0s 444us/step - loss: 0.3865 - accuracy: 0.8120\n",
      "Epoch 145/200\n",
      "153/153 [==============================] - 0s 435us/step - loss: 0.3865 - accuracy: 0.8102\n",
      "Epoch 146/200\n",
      "153/153 [==============================] - 0s 435us/step - loss: 0.3868 - accuracy: 0.8096\n",
      "Epoch 147/200\n",
      "153/153 [==============================] - 0s 435us/step - loss: 0.3859 - accuracy: 0.8104\n",
      "Epoch 148/200\n",
      "153/153 [==============================] - 0s 485us/step - loss: 0.3822 - accuracy: 0.8135\n",
      "Epoch 149/200\n",
      "153/153 [==============================] - 0s 682us/step - loss: 0.3836 - accuracy: 0.8118\n",
      "Epoch 150/200\n",
      "153/153 [==============================] - 0s 643us/step - loss: 0.3850 - accuracy: 0.8092\n",
      "Epoch 151/200\n",
      "153/153 [==============================] - 0s 492us/step - loss: 0.3786 - accuracy: 0.8164\n",
      "Epoch 152/200\n",
      "153/153 [==============================] - 0s 449us/step - loss: 0.3847 - accuracy: 0.8155\n",
      "Epoch 153/200\n",
      "153/153 [==============================] - 0s 483us/step - loss: 0.3850 - accuracy: 0.8092\n",
      "Epoch 154/200\n",
      "153/153 [==============================] - 0s 458us/step - loss: 0.3854 - accuracy: 0.8096\n",
      "Epoch 155/200\n",
      "153/153 [==============================] - 0s 439us/step - loss: 0.3885 - accuracy: 0.8100\n",
      "Epoch 156/200\n",
      "153/153 [==============================] - 0s 446us/step - loss: 0.3883 - accuracy: 0.8112\n",
      "Epoch 157/200\n",
      "153/153 [==============================] - 0s 932us/step - loss: 0.3806 - accuracy: 0.8176\n",
      "Epoch 158/200\n",
      "153/153 [==============================] - 0s 444us/step - loss: 0.3888 - accuracy: 0.8024\n",
      "Epoch 159/200\n",
      "153/153 [==============================] - 0s 459us/step - loss: 0.3871 - accuracy: 0.8108\n",
      "Epoch 160/200\n",
      "153/153 [==============================] - 0s 449us/step - loss: 0.3827 - accuracy: 0.8207\n",
      "Epoch 161/200\n",
      "153/153 [==============================] - 0s 457us/step - loss: 0.3800 - accuracy: 0.8139\n",
      "Epoch 162/200\n",
      "153/153 [==============================] - 0s 449us/step - loss: 0.3868 - accuracy: 0.8143\n",
      "Epoch 163/200\n",
      "153/153 [==============================] - 0s 451us/step - loss: 0.3871 - accuracy: 0.8061\n",
      "Epoch 164/200\n",
      "153/153 [==============================] - 0s 481us/step - loss: 0.3900 - accuracy: 0.8040\n",
      "Epoch 165/200\n",
      "153/153 [==============================] - 0s 446us/step - loss: 0.3847 - accuracy: 0.8077\n",
      "Epoch 166/200\n",
      "153/153 [==============================] - 0s 441us/step - loss: 0.3850 - accuracy: 0.8131\n",
      "Epoch 167/200\n",
      "153/153 [==============================] - 0s 430us/step - loss: 0.3807 - accuracy: 0.8108\n",
      "Epoch 168/200\n",
      "153/153 [==============================] - 0s 444us/step - loss: 0.3851 - accuracy: 0.8088\n",
      "Epoch 169/200\n",
      "153/153 [==============================] - 0s 457us/step - loss: 0.3810 - accuracy: 0.8090\n",
      "Epoch 170/200\n",
      "153/153 [==============================] - 0s 432us/step - loss: 0.3887 - accuracy: 0.8104\n",
      "Epoch 171/200\n",
      "153/153 [==============================] - 0s 434us/step - loss: 0.3761 - accuracy: 0.8137\n",
      "Epoch 172/200\n",
      "153/153 [==============================] - 0s 434us/step - loss: 0.3879 - accuracy: 0.8069\n",
      "Epoch 173/200\n",
      "153/153 [==============================] - 0s 453us/step - loss: 0.3890 - accuracy: 0.8071\n",
      "Epoch 174/200\n",
      "153/153 [==============================] - 0s 456us/step - loss: 0.3868 - accuracy: 0.8069\n",
      "Epoch 175/200\n",
      "153/153 [==============================] - 0s 438us/step - loss: 0.3841 - accuracy: 0.8116\n",
      "Epoch 176/200\n",
      "153/153 [==============================] - 0s 444us/step - loss: 0.3832 - accuracy: 0.8090\n",
      "Epoch 177/200\n",
      "153/153 [==============================] - 0s 438us/step - loss: 0.3816 - accuracy: 0.8147\n",
      "Epoch 178/200\n",
      "153/153 [==============================] - 0s 437us/step - loss: 0.3829 - accuracy: 0.8092\n",
      "Epoch 179/200\n",
      "153/153 [==============================] - 0s 539us/step - loss: 0.3801 - accuracy: 0.8088\n",
      "Epoch 180/200\n",
      "153/153 [==============================] - 0s 434us/step - loss: 0.3810 - accuracy: 0.8172\n",
      "Epoch 181/200\n",
      "153/153 [==============================] - 0s 432us/step - loss: 0.3821 - accuracy: 0.8092\n",
      "Epoch 182/200\n",
      "153/153 [==============================] - 0s 427us/step - loss: 0.3822 - accuracy: 0.8127\n",
      "Epoch 183/200\n",
      "153/153 [==============================] - 0s 440us/step - loss: 0.3874 - accuracy: 0.8065\n",
      "Epoch 184/200\n",
      "153/153 [==============================] - 0s 692us/step - loss: 0.3856 - accuracy: 0.8088\n",
      "Epoch 185/200\n",
      "153/153 [==============================] - 0s 446us/step - loss: 0.3865 - accuracy: 0.8104\n",
      "Epoch 186/200\n",
      "153/153 [==============================] - 0s 449us/step - loss: 0.3847 - accuracy: 0.8083\n",
      "Epoch 187/200\n",
      "153/153 [==============================] - 0s 443us/step - loss: 0.3846 - accuracy: 0.8159\n",
      "Epoch 188/200\n",
      "153/153 [==============================] - 0s 433us/step - loss: 0.3844 - accuracy: 0.8139\n",
      "Epoch 189/200\n",
      "153/153 [==============================] - 0s 435us/step - loss: 0.3816 - accuracy: 0.8079\n",
      "Epoch 190/200\n",
      "153/153 [==============================] - 0s 452us/step - loss: 0.3841 - accuracy: 0.8124\n",
      "Epoch 191/200\n",
      "153/153 [==============================] - 0s 433us/step - loss: 0.3853 - accuracy: 0.8139\n",
      "Epoch 192/200\n",
      "153/153 [==============================] - 0s 432us/step - loss: 0.3843 - accuracy: 0.8112\n",
      "Epoch 193/200\n",
      "153/153 [==============================] - 0s 439us/step - loss: 0.3869 - accuracy: 0.8145\n",
      "Epoch 194/200\n",
      "153/153 [==============================] - 0s 446us/step - loss: 0.3825 - accuracy: 0.8141\n",
      "Epoch 195/200\n",
      "153/153 [==============================] - 0s 442us/step - loss: 0.3846 - accuracy: 0.8090\n",
      "Epoch 196/200\n",
      "153/153 [==============================] - 0s 441us/step - loss: 0.3782 - accuracy: 0.8161\n",
      "Epoch 197/200\n",
      "153/153 [==============================] - 0s 442us/step - loss: 0.3836 - accuracy: 0.8120\n",
      "Epoch 198/200\n",
      "153/153 [==============================] - 0s 431us/step - loss: 0.3856 - accuracy: 0.8106\n",
      "Epoch 199/200\n",
      "153/153 [==============================] - 0s 437us/step - loss: 0.3814 - accuracy: 0.8155\n",
      "Epoch 200/200\n",
      "153/153 [==============================] - 0s 437us/step - loss: 0.3870 - accuracy: 0.8044\n",
      "39/39 [==============================] - 0s 337us/step\n",
      "Epoch 1/200\n",
      "153/153 [==============================] - 0s 783us/step - loss: 0.5923 - accuracy: 0.7056\n",
      "Epoch 2/200\n",
      "153/153 [==============================] - 0s 444us/step - loss: 0.4619 - accuracy: 0.7707\n",
      "Epoch 3/200\n",
      "153/153 [==============================] - 0s 443us/step - loss: 0.4497 - accuracy: 0.7749\n",
      "Epoch 4/200\n",
      "153/153 [==============================] - 0s 448us/step - loss: 0.4446 - accuracy: 0.7794\n",
      "Epoch 5/200\n",
      "153/153 [==============================] - 0s 435us/step - loss: 0.4407 - accuracy: 0.7862\n",
      "Epoch 6/200\n",
      "153/153 [==============================] - 0s 432us/step - loss: 0.4387 - accuracy: 0.7855\n",
      "Epoch 7/200\n",
      "153/153 [==============================] - 0s 431us/step - loss: 0.4362 - accuracy: 0.7851\n",
      "Epoch 8/200\n",
      "153/153 [==============================] - 0s 438us/step - loss: 0.4316 - accuracy: 0.7874\n",
      "Epoch 9/200\n",
      "153/153 [==============================] - 0s 436us/step - loss: 0.4336 - accuracy: 0.7892\n",
      "Epoch 10/200\n",
      "153/153 [==============================] - 0s 452us/step - loss: 0.4323 - accuracy: 0.7882\n",
      "Epoch 11/200\n",
      "153/153 [==============================] - 0s 530us/step - loss: 0.4303 - accuracy: 0.7872\n",
      "Epoch 12/200\n",
      "153/153 [==============================] - 0s 890us/step - loss: 0.4244 - accuracy: 0.7917\n",
      "Epoch 13/200\n",
      "153/153 [==============================] - 0s 483us/step - loss: 0.4276 - accuracy: 0.7892\n",
      "Epoch 14/200\n",
      "153/153 [==============================] - 0s 465us/step - loss: 0.4307 - accuracy: 0.7878\n",
      "Epoch 15/200\n",
      "153/153 [==============================] - 0s 578us/step - loss: 0.4253 - accuracy: 0.7954\n",
      "Epoch 16/200\n",
      "153/153 [==============================] - 0s 539us/step - loss: 0.4265 - accuracy: 0.7946\n",
      "Epoch 17/200\n",
      "153/153 [==============================] - 0s 467us/step - loss: 0.4249 - accuracy: 0.7921\n",
      "Epoch 18/200\n",
      "153/153 [==============================] - 0s 469us/step - loss: 0.4252 - accuracy: 0.7999\n",
      "Epoch 19/200\n",
      "153/153 [==============================] - 0s 448us/step - loss: 0.4228 - accuracy: 0.7964\n",
      "Epoch 20/200\n",
      "153/153 [==============================] - 0s 782us/step - loss: 0.4229 - accuracy: 0.7931\n",
      "Epoch 21/200\n",
      "153/153 [==============================] - 0s 447us/step - loss: 0.4253 - accuracy: 0.7935\n",
      "Epoch 22/200\n",
      "153/153 [==============================] - 0s 483us/step - loss: 0.4181 - accuracy: 0.7948\n",
      "Epoch 23/200\n",
      "153/153 [==============================] - 0s 464us/step - loss: 0.4213 - accuracy: 0.7950\n",
      "Epoch 24/200\n",
      "153/153 [==============================] - 0s 501us/step - loss: 0.4235 - accuracy: 0.7942\n",
      "Epoch 25/200\n",
      "153/153 [==============================] - 0s 624us/step - loss: 0.4235 - accuracy: 0.7890\n",
      "Epoch 26/200\n",
      "153/153 [==============================] - 0s 466us/step - loss: 0.4186 - accuracy: 0.7942\n",
      "Epoch 27/200\n",
      "153/153 [==============================] - 0s 473us/step - loss: 0.4174 - accuracy: 0.7915\n",
      "Epoch 28/200\n",
      "153/153 [==============================] - 0s 488us/step - loss: 0.4176 - accuracy: 0.7942\n",
      "Epoch 29/200\n",
      "153/153 [==============================] - 0s 470us/step - loss: 0.4205 - accuracy: 0.7964\n",
      "Epoch 30/200\n",
      "153/153 [==============================] - 0s 471us/step - loss: 0.4209 - accuracy: 0.7927\n",
      "Epoch 31/200\n",
      "153/153 [==============================] - 0s 439us/step - loss: 0.4164 - accuracy: 0.8009\n",
      "Epoch 32/200\n",
      "153/153 [==============================] - 0s 458us/step - loss: 0.4179 - accuracy: 0.7966\n",
      "Epoch 33/200\n",
      "153/153 [==============================] - 0s 446us/step - loss: 0.4160 - accuracy: 0.7925\n",
      "Epoch 34/200\n",
      "153/153 [==============================] - 0s 436us/step - loss: 0.4202 - accuracy: 0.7975\n",
      "Epoch 35/200\n",
      "153/153 [==============================] - 0s 438us/step - loss: 0.4154 - accuracy: 0.7993\n",
      "Epoch 36/200\n",
      "153/153 [==============================] - 0s 458us/step - loss: 0.4138 - accuracy: 0.7999\n",
      "Epoch 37/200\n",
      "153/153 [==============================] - 0s 482us/step - loss: 0.4197 - accuracy: 0.7929\n",
      "Epoch 38/200\n",
      "153/153 [==============================] - 0s 467us/step - loss: 0.4152 - accuracy: 0.7999\n",
      "Epoch 39/200\n",
      "153/153 [==============================] - 0s 468us/step - loss: 0.4186 - accuracy: 0.7946\n",
      "Epoch 40/200\n",
      "153/153 [==============================] - 0s 442us/step - loss: 0.4134 - accuracy: 0.8040\n",
      "Epoch 41/200\n",
      "153/153 [==============================] - 0s 443us/step - loss: 0.4158 - accuracy: 0.8016\n",
      "Epoch 42/200\n",
      "153/153 [==============================] - 0s 482us/step - loss: 0.4119 - accuracy: 0.7944\n",
      "Epoch 43/200\n",
      "153/153 [==============================] - 0s 450us/step - loss: 0.4146 - accuracy: 0.7964\n",
      "Epoch 44/200\n",
      "153/153 [==============================] - 0s 436us/step - loss: 0.4142 - accuracy: 0.7999\n",
      "Epoch 45/200\n",
      "153/153 [==============================] - 0s 448us/step - loss: 0.4129 - accuracy: 0.7983\n",
      "Epoch 46/200\n",
      "153/153 [==============================] - 0s 423us/step - loss: 0.4157 - accuracy: 0.7954\n",
      "Epoch 47/200\n",
      "153/153 [==============================] - 0s 472us/step - loss: 0.4125 - accuracy: 0.8028\n",
      "Epoch 48/200\n",
      "153/153 [==============================] - 0s 435us/step - loss: 0.4093 - accuracy: 0.8030\n",
      "Epoch 49/200\n",
      "153/153 [==============================] - 0s 440us/step - loss: 0.4120 - accuracy: 0.8055\n",
      "Epoch 50/200\n",
      "153/153 [==============================] - 0s 452us/step - loss: 0.4142 - accuracy: 0.7954\n",
      "Epoch 51/200\n",
      "153/153 [==============================] - 0s 453us/step - loss: 0.4158 - accuracy: 0.7948\n",
      "Epoch 52/200\n",
      "153/153 [==============================] - 0s 474us/step - loss: 0.4071 - accuracy: 0.8040\n",
      "Epoch 53/200\n",
      "153/153 [==============================] - 0s 466us/step - loss: 0.4116 - accuracy: 0.8003\n",
      "Epoch 54/200\n",
      "153/153 [==============================] - 0s 498us/step - loss: 0.4129 - accuracy: 0.8046\n",
      "Epoch 55/200\n",
      "153/153 [==============================] - 0s 486us/step - loss: 0.4114 - accuracy: 0.7989\n",
      "Epoch 56/200\n",
      "153/153 [==============================] - 0s 467us/step - loss: 0.4084 - accuracy: 0.7999\n",
      "Epoch 57/200\n",
      "153/153 [==============================] - 0s 445us/step - loss: 0.4111 - accuracy: 0.8026\n",
      "Epoch 58/200\n",
      "153/153 [==============================] - 0s 537us/step - loss: 0.4087 - accuracy: 0.8034\n",
      "Epoch 59/200\n",
      "153/153 [==============================] - 0s 470us/step - loss: 0.4094 - accuracy: 0.8040\n",
      "Epoch 60/200\n",
      "153/153 [==============================] - 0s 464us/step - loss: 0.4100 - accuracy: 0.7960\n",
      "Epoch 61/200\n",
      "153/153 [==============================] - 0s 462us/step - loss: 0.4095 - accuracy: 0.7987\n",
      "Epoch 62/200\n",
      "153/153 [==============================] - 0s 439us/step - loss: 0.4066 - accuracy: 0.7997\n",
      "Epoch 63/200\n",
      "153/153 [==============================] - 0s 452us/step - loss: 0.4148 - accuracy: 0.7927\n",
      "Epoch 64/200\n",
      "153/153 [==============================] - 0s 457us/step - loss: 0.4076 - accuracy: 0.8055\n",
      "Epoch 65/200\n",
      "153/153 [==============================] - 0s 440us/step - loss: 0.4112 - accuracy: 0.7962\n",
      "Epoch 66/200\n",
      "153/153 [==============================] - 0s 973us/step - loss: 0.4095 - accuracy: 0.8005\n",
      "Epoch 67/200\n",
      "153/153 [==============================] - 0s 457us/step - loss: 0.4126 - accuracy: 0.8014\n",
      "Epoch 68/200\n",
      "153/153 [==============================] - 0s 446us/step - loss: 0.4099 - accuracy: 0.8020\n",
      "Epoch 69/200\n",
      "153/153 [==============================] - 0s 560us/step - loss: 0.4071 - accuracy: 0.8032\n",
      "Epoch 70/200\n",
      "153/153 [==============================] - 0s 699us/step - loss: 0.4101 - accuracy: 0.7960\n",
      "Epoch 71/200\n",
      "153/153 [==============================] - 0s 484us/step - loss: 0.4098 - accuracy: 0.7983\n",
      "Epoch 72/200\n",
      "153/153 [==============================] - 0s 703us/step - loss: 0.4118 - accuracy: 0.8009\n",
      "Epoch 73/200\n",
      "153/153 [==============================] - 0s 461us/step - loss: 0.4108 - accuracy: 0.7968\n",
      "Epoch 74/200\n",
      "153/153 [==============================] - 0s 533us/step - loss: 0.4069 - accuracy: 0.8071\n",
      "Epoch 75/200\n",
      "153/153 [==============================] - 0s 440us/step - loss: 0.4031 - accuracy: 0.8069\n",
      "Epoch 76/200\n",
      "153/153 [==============================] - 0s 466us/step - loss: 0.4070 - accuracy: 0.7972\n",
      "Epoch 77/200\n",
      "153/153 [==============================] - 0s 472us/step - loss: 0.4006 - accuracy: 0.8059\n",
      "Epoch 78/200\n",
      "153/153 [==============================] - 0s 476us/step - loss: 0.4104 - accuracy: 0.8001\n",
      "Epoch 79/200\n",
      "153/153 [==============================] - 0s 471us/step - loss: 0.4063 - accuracy: 0.8046\n",
      "Epoch 80/200\n",
      "153/153 [==============================] - 0s 426us/step - loss: 0.4019 - accuracy: 0.8028\n",
      "Epoch 81/200\n",
      "153/153 [==============================] - 0s 445us/step - loss: 0.4033 - accuracy: 0.8028\n",
      "Epoch 82/200\n",
      "153/153 [==============================] - 0s 433us/step - loss: 0.4063 - accuracy: 0.8024\n",
      "Epoch 83/200\n",
      "153/153 [==============================] - 0s 443us/step - loss: 0.4040 - accuracy: 0.8001\n",
      "Epoch 84/200\n",
      "153/153 [==============================] - 0s 434us/step - loss: 0.4039 - accuracy: 0.8046\n",
      "Epoch 85/200\n",
      "153/153 [==============================] - 0s 445us/step - loss: 0.4076 - accuracy: 0.7983\n",
      "Epoch 86/200\n",
      "153/153 [==============================] - 0s 437us/step - loss: 0.4057 - accuracy: 0.8007\n",
      "Epoch 87/200\n",
      "153/153 [==============================] - 0s 464us/step - loss: 0.4048 - accuracy: 0.8014\n",
      "Epoch 88/200\n",
      "153/153 [==============================] - 0s 439us/step - loss: 0.4045 - accuracy: 0.7991\n",
      "Epoch 89/200\n",
      "153/153 [==============================] - 0s 442us/step - loss: 0.4088 - accuracy: 0.7972\n",
      "Epoch 90/200\n",
      "153/153 [==============================] - 0s 461us/step - loss: 0.4034 - accuracy: 0.8051\n",
      "Epoch 91/200\n",
      "153/153 [==============================] - 0s 459us/step - loss: 0.4075 - accuracy: 0.7999\n",
      "Epoch 92/200\n",
      "153/153 [==============================] - 0s 452us/step - loss: 0.4009 - accuracy: 0.8044\n",
      "Epoch 93/200\n",
      "153/153 [==============================] - 0s 715us/step - loss: 0.4056 - accuracy: 0.8061\n",
      "Epoch 94/200\n",
      "153/153 [==============================] - 0s 470us/step - loss: 0.4042 - accuracy: 0.8065\n",
      "Epoch 95/200\n",
      "153/153 [==============================] - 0s 455us/step - loss: 0.4013 - accuracy: 0.8069\n",
      "Epoch 96/200\n",
      "153/153 [==============================] - 0s 462us/step - loss: 0.4028 - accuracy: 0.8044\n",
      "Epoch 97/200\n",
      "153/153 [==============================] - 0s 563us/step - loss: 0.4012 - accuracy: 0.8003\n",
      "Epoch 98/200\n",
      "153/153 [==============================] - 0s 445us/step - loss: 0.4057 - accuracy: 0.8083\n",
      "Epoch 99/200\n",
      "153/153 [==============================] - 0s 441us/step - loss: 0.4026 - accuracy: 0.8069\n",
      "Epoch 100/200\n",
      "153/153 [==============================] - 0s 449us/step - loss: 0.4041 - accuracy: 0.8022\n",
      "Epoch 101/200\n",
      "153/153 [==============================] - 0s 438us/step - loss: 0.4081 - accuracy: 0.8022\n",
      "Epoch 102/200\n",
      "153/153 [==============================] - 0s 446us/step - loss: 0.4016 - accuracy: 0.8014\n",
      "Epoch 103/200\n",
      "153/153 [==============================] - 0s 436us/step - loss: 0.4020 - accuracy: 0.8030\n",
      "Epoch 104/200\n",
      "153/153 [==============================] - 0s 435us/step - loss: 0.4059 - accuracy: 0.7989\n",
      "Epoch 105/200\n",
      "153/153 [==============================] - 0s 443us/step - loss: 0.4030 - accuracy: 0.8032\n",
      "Epoch 106/200\n",
      "153/153 [==============================] - 0s 436us/step - loss: 0.4037 - accuracy: 0.7956\n",
      "Epoch 107/200\n",
      "153/153 [==============================] - 0s 473us/step - loss: 0.4089 - accuracy: 0.7962\n",
      "Epoch 108/200\n",
      "153/153 [==============================] - 0s 467us/step - loss: 0.4061 - accuracy: 0.7997\n",
      "Epoch 109/200\n",
      "153/153 [==============================] - 0s 516us/step - loss: 0.3992 - accuracy: 0.8057\n",
      "Epoch 110/200\n",
      "153/153 [==============================] - 0s 448us/step - loss: 0.4071 - accuracy: 0.8065\n",
      "Epoch 111/200\n",
      "153/153 [==============================] - 0s 479us/step - loss: 0.4029 - accuracy: 0.8063\n",
      "Epoch 112/200\n",
      "153/153 [==============================] - 0s 433us/step - loss: 0.3995 - accuracy: 0.8075\n",
      "Epoch 113/200\n",
      "153/153 [==============================] - 0s 454us/step - loss: 0.4008 - accuracy: 0.8073\n",
      "Epoch 114/200\n",
      "153/153 [==============================] - 0s 443us/step - loss: 0.4015 - accuracy: 0.8044\n",
      "Epoch 115/200\n",
      "153/153 [==============================] - 0s 443us/step - loss: 0.4001 - accuracy: 0.8032\n",
      "Epoch 116/200\n",
      "153/153 [==============================] - 0s 431us/step - loss: 0.4056 - accuracy: 0.7962\n",
      "Epoch 117/200\n",
      "153/153 [==============================] - 0s 440us/step - loss: 0.3998 - accuracy: 0.8106\n",
      "Epoch 118/200\n",
      "153/153 [==============================] - 0s 436us/step - loss: 0.3996 - accuracy: 0.8114\n",
      "Epoch 119/200\n",
      "153/153 [==============================] - 0s 449us/step - loss: 0.4027 - accuracy: 0.8022\n",
      "Epoch 120/200\n",
      "153/153 [==============================] - 0s 447us/step - loss: 0.4052 - accuracy: 0.8026\n",
      "Epoch 121/200\n",
      "153/153 [==============================] - 0s 443us/step - loss: 0.3988 - accuracy: 0.8073\n",
      "Epoch 122/200\n",
      "153/153 [==============================] - 0s 437us/step - loss: 0.4020 - accuracy: 0.8053\n",
      "Epoch 123/200\n",
      "153/153 [==============================] - 0s 471us/step - loss: 0.4041 - accuracy: 0.8053\n",
      "Epoch 124/200\n",
      "153/153 [==============================] - 0s 568us/step - loss: 0.3963 - accuracy: 0.8038\n",
      "Epoch 125/200\n",
      "153/153 [==============================] - 0s 511us/step - loss: 0.4009 - accuracy: 0.8012\n",
      "Epoch 126/200\n",
      "153/153 [==============================] - 0s 519us/step - loss: 0.4026 - accuracy: 0.8102\n",
      "Epoch 127/200\n",
      "153/153 [==============================] - 0s 482us/step - loss: 0.4013 - accuracy: 0.8007\n",
      "Epoch 128/200\n",
      "153/153 [==============================] - 0s 458us/step - loss: 0.4032 - accuracy: 0.7968\n",
      "Epoch 129/200\n",
      "153/153 [==============================] - 0s 458us/step - loss: 0.4024 - accuracy: 0.8034\n",
      "Epoch 130/200\n",
      "153/153 [==============================] - 0s 453us/step - loss: 0.4017 - accuracy: 0.8081\n",
      "Epoch 131/200\n",
      "153/153 [==============================] - 0s 487us/step - loss: 0.3961 - accuracy: 0.8042\n",
      "Epoch 132/200\n",
      "153/153 [==============================] - 0s 530us/step - loss: 0.3946 - accuracy: 0.8133\n",
      "Epoch 133/200\n",
      "153/153 [==============================] - 0s 490us/step - loss: 0.4016 - accuracy: 0.8032\n",
      "Epoch 134/200\n",
      "153/153 [==============================] - 0s 463us/step - loss: 0.4000 - accuracy: 0.8061\n",
      "Epoch 135/200\n",
      "153/153 [==============================] - 0s 474us/step - loss: 0.3996 - accuracy: 0.8026\n",
      "Epoch 136/200\n",
      "153/153 [==============================] - 0s 444us/step - loss: 0.4005 - accuracy: 0.8048\n",
      "Epoch 137/200\n",
      "153/153 [==============================] - 0s 443us/step - loss: 0.4013 - accuracy: 0.8036\n",
      "Epoch 138/200\n",
      "153/153 [==============================] - 0s 460us/step - loss: 0.3990 - accuracy: 0.8036\n",
      "Epoch 139/200\n",
      "153/153 [==============================] - 0s 436us/step - loss: 0.4008 - accuracy: 0.7997\n",
      "Epoch 140/200\n",
      "153/153 [==============================] - 0s 448us/step - loss: 0.3984 - accuracy: 0.8012\n",
      "Epoch 141/200\n",
      "153/153 [==============================] - 0s 458us/step - loss: 0.4019 - accuracy: 0.8055\n",
      "Epoch 142/200\n",
      "153/153 [==============================] - 0s 456us/step - loss: 0.3969 - accuracy: 0.8053\n",
      "Epoch 143/200\n",
      "153/153 [==============================] - 0s 445us/step - loss: 0.3970 - accuracy: 0.8067\n",
      "Epoch 144/200\n",
      "153/153 [==============================] - 0s 451us/step - loss: 0.3972 - accuracy: 0.8040\n",
      "Epoch 145/200\n",
      "153/153 [==============================] - 0s 448us/step - loss: 0.3996 - accuracy: 0.8014\n",
      "Epoch 146/200\n",
      "153/153 [==============================] - 0s 451us/step - loss: 0.4009 - accuracy: 0.8071\n",
      "Epoch 147/200\n",
      "153/153 [==============================] - 0s 448us/step - loss: 0.3983 - accuracy: 0.8073\n",
      "Epoch 148/200\n",
      "153/153 [==============================] - 0s 489us/step - loss: 0.4025 - accuracy: 0.7972\n",
      "Epoch 149/200\n",
      "153/153 [==============================] - 0s 449us/step - loss: 0.4009 - accuracy: 0.8012\n",
      "Epoch 150/200\n",
      "153/153 [==============================] - 0s 453us/step - loss: 0.3949 - accuracy: 0.8038\n",
      "Epoch 151/200\n",
      "153/153 [==============================] - 0s 446us/step - loss: 0.4010 - accuracy: 0.8042\n",
      "Epoch 152/200\n",
      "153/153 [==============================] - 0s 475us/step - loss: 0.4015 - accuracy: 0.8059\n",
      "Epoch 153/200\n",
      "153/153 [==============================] - 0s 964us/step - loss: 0.3981 - accuracy: 0.8059\n",
      "Epoch 154/200\n",
      "153/153 [==============================] - 0s 452us/step - loss: 0.3991 - accuracy: 0.8085\n",
      "Epoch 155/200\n",
      "153/153 [==============================] - 0s 438us/step - loss: 0.3957 - accuracy: 0.8003\n",
      "Epoch 156/200\n",
      "153/153 [==============================] - 0s 565us/step - loss: 0.3991 - accuracy: 0.8032\n",
      "Epoch 157/200\n",
      "153/153 [==============================] - 0s 435us/step - loss: 0.3988 - accuracy: 0.7983\n",
      "Epoch 158/200\n",
      "153/153 [==============================] - 0s 470us/step - loss: 0.3996 - accuracy: 0.7970\n",
      "Epoch 159/200\n",
      "153/153 [==============================] - 0s 458us/step - loss: 0.3943 - accuracy: 0.8100\n",
      "Epoch 160/200\n",
      "153/153 [==============================] - 0s 445us/step - loss: 0.3991 - accuracy: 0.8048\n",
      "Epoch 161/200\n",
      "153/153 [==============================] - 0s 457us/step - loss: 0.3966 - accuracy: 0.8036\n",
      "Epoch 162/200\n",
      "153/153 [==============================] - 0s 431us/step - loss: 0.3985 - accuracy: 0.8032\n",
      "Epoch 163/200\n",
      "153/153 [==============================] - 0s 461us/step - loss: 0.3994 - accuracy: 0.8038\n",
      "Epoch 164/200\n",
      "153/153 [==============================] - 0s 487us/step - loss: 0.4021 - accuracy: 0.8053\n",
      "Epoch 165/200\n",
      "153/153 [==============================] - 0s 445us/step - loss: 0.3995 - accuracy: 0.8014\n",
      "Epoch 166/200\n",
      "153/153 [==============================] - 0s 450us/step - loss: 0.3958 - accuracy: 0.8073\n",
      "Epoch 167/200\n",
      "153/153 [==============================] - 0s 452us/step - loss: 0.3984 - accuracy: 0.8067\n",
      "Epoch 168/200\n",
      "153/153 [==============================] - 0s 418us/step - loss: 0.3971 - accuracy: 0.8079\n",
      "Epoch 169/200\n",
      "153/153 [==============================] - 0s 450us/step - loss: 0.3992 - accuracy: 0.8046\n",
      "Epoch 170/200\n",
      "153/153 [==============================] - 0s 448us/step - loss: 0.3956 - accuracy: 0.8112\n",
      "Epoch 171/200\n",
      "153/153 [==============================] - 0s 431us/step - loss: 0.3974 - accuracy: 0.8067\n",
      "Epoch 172/200\n",
      "153/153 [==============================] - 0s 452us/step - loss: 0.3966 - accuracy: 0.8104\n",
      "Epoch 173/200\n",
      "153/153 [==============================] - 0s 443us/step - loss: 0.3974 - accuracy: 0.8046\n",
      "Epoch 174/200\n",
      "153/153 [==============================] - 0s 420us/step - loss: 0.3973 - accuracy: 0.8067\n",
      "Epoch 175/200\n",
      "153/153 [==============================] - 0s 441us/step - loss: 0.3971 - accuracy: 0.8085\n",
      "Epoch 176/200\n",
      "153/153 [==============================] - 0s 393us/step - loss: 0.3961 - accuracy: 0.8022\n",
      "Epoch 177/200\n",
      "153/153 [==============================] - 0s 444us/step - loss: 0.3991 - accuracy: 0.8030\n",
      "Epoch 178/200\n",
      "153/153 [==============================] - 0s 438us/step - loss: 0.3944 - accuracy: 0.8034\n",
      "Epoch 179/200\n",
      "153/153 [==============================] - 0s 446us/step - loss: 0.4002 - accuracy: 0.7999\n",
      "Epoch 180/200\n",
      "153/153 [==============================] - 0s 507us/step - loss: 0.3963 - accuracy: 0.8106\n",
      "Epoch 181/200\n",
      "153/153 [==============================] - 0s 443us/step - loss: 0.3926 - accuracy: 0.8094\n",
      "Epoch 182/200\n",
      "153/153 [==============================] - 0s 455us/step - loss: 0.3996 - accuracy: 0.8065\n",
      "Epoch 183/200\n",
      "153/153 [==============================] - 0s 699us/step - loss: 0.3928 - accuracy: 0.8079\n",
      "Epoch 184/200\n",
      "153/153 [==============================] - 0s 436us/step - loss: 0.3982 - accuracy: 0.8024\n",
      "Epoch 185/200\n",
      "153/153 [==============================] - 0s 456us/step - loss: 0.3944 - accuracy: 0.8092\n",
      "Epoch 186/200\n",
      "153/153 [==============================] - 0s 836us/step - loss: 0.3949 - accuracy: 0.8106\n",
      "Epoch 187/200\n",
      "153/153 [==============================] - 0s 466us/step - loss: 0.3952 - accuracy: 0.8059\n",
      "Epoch 188/200\n",
      "153/153 [==============================] - 0s 452us/step - loss: 0.3942 - accuracy: 0.8032\n",
      "Epoch 189/200\n",
      "153/153 [==============================] - 0s 449us/step - loss: 0.3973 - accuracy: 0.8053\n",
      "Epoch 190/200\n",
      "153/153 [==============================] - 0s 433us/step - loss: 0.3966 - accuracy: 0.8075\n",
      "Epoch 191/200\n",
      "153/153 [==============================] - 0s 439us/step - loss: 0.3970 - accuracy: 0.8100\n",
      "Epoch 192/200\n",
      "153/153 [==============================] - 0s 433us/step - loss: 0.3954 - accuracy: 0.8077\n",
      "Epoch 193/200\n",
      "153/153 [==============================] - 0s 483us/step - loss: 0.4010 - accuracy: 0.8038\n",
      "Epoch 194/200\n",
      "153/153 [==============================] - 0s 440us/step - loss: 0.3940 - accuracy: 0.8048\n",
      "Epoch 195/200\n",
      "153/153 [==============================] - 0s 438us/step - loss: 0.3971 - accuracy: 0.8079\n",
      "Epoch 196/200\n",
      "153/153 [==============================] - 0s 435us/step - loss: 0.3964 - accuracy: 0.8083\n",
      "Epoch 197/200\n",
      "153/153 [==============================] - 0s 430us/step - loss: 0.3992 - accuracy: 0.8046\n",
      "Epoch 198/200\n",
      "153/153 [==============================] - 0s 435us/step - loss: 0.3981 - accuracy: 0.8077\n",
      "Epoch 199/200\n",
      "153/153 [==============================] - 0s 435us/step - loss: 0.3976 - accuracy: 0.7997\n",
      "Epoch 200/200\n",
      "153/153 [==============================] - 0s 439us/step - loss: 0.3944 - accuracy: 0.8048\n",
      "39/39 [==============================] - 0s 343us/step\n",
      "Epoch 1/200\n",
      "191/191 [==============================] - 0s 487us/step - loss: 0.5504 - accuracy: 0.7372\n",
      "Epoch 2/200\n",
      "191/191 [==============================] - 0s 463us/step - loss: 0.4438 - accuracy: 0.7865\n",
      "Epoch 3/200\n",
      "191/191 [==============================] - 0s 482us/step - loss: 0.4338 - accuracy: 0.7898\n",
      "Epoch 4/200\n",
      "191/191 [==============================] - 0s 441us/step - loss: 0.4300 - accuracy: 0.7915\n",
      "Epoch 5/200\n",
      "191/191 [==============================] - 0s 434us/step - loss: 0.4307 - accuracy: 0.7974\n",
      "Epoch 6/200\n",
      "191/191 [==============================] - 0s 755us/step - loss: 0.4252 - accuracy: 0.7939\n",
      "Epoch 7/200\n",
      "191/191 [==============================] - 0s 480us/step - loss: 0.4239 - accuracy: 0.8005\n",
      "Epoch 8/200\n",
      "191/191 [==============================] - 0s 558us/step - loss: 0.4206 - accuracy: 0.7990\n",
      "Epoch 9/200\n",
      "191/191 [==============================] - 0s 441us/step - loss: 0.4172 - accuracy: 0.7974\n",
      "Epoch 10/200\n",
      "191/191 [==============================] - 0s 433us/step - loss: 0.4219 - accuracy: 0.7998\n",
      "Epoch 11/200\n",
      "191/191 [==============================] - 0s 459us/step - loss: 0.4172 - accuracy: 0.8007\n",
      "Epoch 12/200\n",
      "191/191 [==============================] - 0s 435us/step - loss: 0.4193 - accuracy: 0.8025\n",
      "Epoch 13/200\n",
      "191/191 [==============================] - 0s 453us/step - loss: 0.4173 - accuracy: 0.8031\n",
      "Epoch 14/200\n",
      "191/191 [==============================] - 0s 429us/step - loss: 0.4153 - accuracy: 0.7988\n",
      "Epoch 15/200\n",
      "191/191 [==============================] - 0s 437us/step - loss: 0.4179 - accuracy: 0.8008\n",
      "Epoch 16/200\n",
      "191/191 [==============================] - 0s 436us/step - loss: 0.4151 - accuracy: 0.8010\n",
      "Epoch 17/200\n",
      "191/191 [==============================] - 0s 433us/step - loss: 0.4126 - accuracy: 0.8016\n",
      "Epoch 18/200\n",
      "191/191 [==============================] - 0s 444us/step - loss: 0.4131 - accuracy: 0.8003\n",
      "Epoch 19/200\n",
      "191/191 [==============================] - 0s 433us/step - loss: 0.4109 - accuracy: 0.8067\n",
      "Epoch 20/200\n",
      "191/191 [==============================] - 0s 685us/step - loss: 0.4107 - accuracy: 0.8026\n",
      "Epoch 21/200\n",
      "191/191 [==============================] - 0s 615us/step - loss: 0.4048 - accuracy: 0.8069\n",
      "Epoch 22/200\n",
      "191/191 [==============================] - 0s 606us/step - loss: 0.4089 - accuracy: 0.8028\n",
      "Epoch 23/200\n",
      "191/191 [==============================] - 0s 636us/step - loss: 0.4104 - accuracy: 0.8044\n",
      "Epoch 24/200\n",
      "191/191 [==============================] - 0s 586us/step - loss: 0.4092 - accuracy: 0.8007\n",
      "Epoch 25/200\n",
      "191/191 [==============================] - 0s 496us/step - loss: 0.4071 - accuracy: 0.8079\n",
      "Epoch 26/200\n",
      "191/191 [==============================] - 0s 475us/step - loss: 0.4048 - accuracy: 0.8082\n",
      "Epoch 27/200\n",
      "191/191 [==============================] - 0s 505us/step - loss: 0.4086 - accuracy: 0.8039\n",
      "Epoch 28/200\n",
      "191/191 [==============================] - 0s 459us/step - loss: 0.4066 - accuracy: 0.8064\n",
      "Epoch 29/200\n",
      "191/191 [==============================] - 0s 510us/step - loss: 0.4084 - accuracy: 0.8085\n",
      "Epoch 30/200\n",
      "191/191 [==============================] - 0s 449us/step - loss: 0.4095 - accuracy: 0.8058\n",
      "Epoch 31/200\n",
      "191/191 [==============================] - 0s 447us/step - loss: 0.4096 - accuracy: 0.8026\n",
      "Epoch 32/200\n",
      "191/191 [==============================] - 0s 439us/step - loss: 0.4069 - accuracy: 0.8038\n",
      "Epoch 33/200\n",
      "191/191 [==============================] - 0s 440us/step - loss: 0.4081 - accuracy: 0.8054\n",
      "Epoch 34/200\n",
      "191/191 [==============================] - 0s 447us/step - loss: 0.4042 - accuracy: 0.8082\n",
      "Epoch 35/200\n",
      "191/191 [==============================] - 0s 437us/step - loss: 0.4061 - accuracy: 0.8046\n",
      "Epoch 36/200\n",
      "191/191 [==============================] - 0s 434us/step - loss: 0.4019 - accuracy: 0.8102\n",
      "Epoch 37/200\n",
      "191/191 [==============================] - 0s 443us/step - loss: 0.4039 - accuracy: 0.8127\n",
      "Epoch 38/200\n",
      "191/191 [==============================] - 0s 447us/step - loss: 0.4024 - accuracy: 0.8115\n",
      "Epoch 39/200\n",
      "191/191 [==============================] - 0s 464us/step - loss: 0.4022 - accuracy: 0.8090\n",
      "Epoch 40/200\n",
      "191/191 [==============================] - 0s 444us/step - loss: 0.4023 - accuracy: 0.8074\n",
      "Epoch 41/200\n",
      "191/191 [==============================] - 0s 453us/step - loss: 0.4038 - accuracy: 0.8077\n",
      "Epoch 42/200\n",
      "191/191 [==============================] - 0s 395us/step - loss: 0.4004 - accuracy: 0.8143\n",
      "Epoch 43/200\n",
      "191/191 [==============================] - 0s 403us/step - loss: 0.3987 - accuracy: 0.8092\n",
      "Epoch 44/200\n",
      "191/191 [==============================] - 0s 569us/step - loss: 0.4002 - accuracy: 0.8110\n",
      "Epoch 45/200\n",
      "191/191 [==============================] - 0s 694us/step - loss: 0.4018 - accuracy: 0.8100\n",
      "Epoch 46/200\n",
      "191/191 [==============================] - 0s 606us/step - loss: 0.4014 - accuracy: 0.8110\n",
      "Epoch 47/200\n",
      "191/191 [==============================] - 0s 850us/step - loss: 0.4028 - accuracy: 0.8053\n",
      "Epoch 48/200\n",
      "191/191 [==============================] - 0s 445us/step - loss: 0.4048 - accuracy: 0.8076\n",
      "Epoch 49/200\n",
      "191/191 [==============================] - 0s 439us/step - loss: 0.4026 - accuracy: 0.8085\n",
      "Epoch 50/200\n",
      "191/191 [==============================] - 0s 443us/step - loss: 0.3983 - accuracy: 0.8154\n",
      "Epoch 51/200\n",
      "191/191 [==============================] - 0s 448us/step - loss: 0.4063 - accuracy: 0.8054\n",
      "Epoch 52/200\n",
      "191/191 [==============================] - 0s 582us/step - loss: 0.4013 - accuracy: 0.8031\n",
      "Epoch 53/200\n",
      "191/191 [==============================] - 0s 464us/step - loss: 0.4000 - accuracy: 0.8110\n",
      "Epoch 54/200\n",
      "191/191 [==============================] - 0s 527us/step - loss: 0.3980 - accuracy: 0.8092\n",
      "Epoch 55/200\n",
      "191/191 [==============================] - 0s 653us/step - loss: 0.3997 - accuracy: 0.8089\n",
      "Epoch 56/200\n",
      "191/191 [==============================] - 0s 423us/step - loss: 0.4001 - accuracy: 0.8087\n",
      "Epoch 57/200\n",
      "191/191 [==============================] - 0s 442us/step - loss: 0.4024 - accuracy: 0.8061\n",
      "Epoch 58/200\n",
      "191/191 [==============================] - 0s 430us/step - loss: 0.4021 - accuracy: 0.8077\n",
      "Epoch 59/200\n",
      "191/191 [==============================] - 0s 443us/step - loss: 0.4005 - accuracy: 0.8107\n",
      "Epoch 60/200\n",
      "191/191 [==============================] - 0s 437us/step - loss: 0.3992 - accuracy: 0.8113\n",
      "Epoch 61/200\n",
      "191/191 [==============================] - 0s 444us/step - loss: 0.4012 - accuracy: 0.8123\n",
      "Epoch 62/200\n",
      "191/191 [==============================] - 0s 437us/step - loss: 0.4000 - accuracy: 0.8095\n",
      "Epoch 63/200\n",
      "191/191 [==============================] - 0s 477us/step - loss: 0.4031 - accuracy: 0.8090\n",
      "Epoch 64/200\n",
      "191/191 [==============================] - 0s 415us/step - loss: 0.3971 - accuracy: 0.8130\n",
      "Epoch 65/200\n",
      "191/191 [==============================] - 0s 436us/step - loss: 0.3977 - accuracy: 0.8102\n",
      "Epoch 66/200\n",
      "191/191 [==============================] - 0s 434us/step - loss: 0.4007 - accuracy: 0.8082\n",
      "Epoch 67/200\n",
      "191/191 [==============================] - 0s 511us/step - loss: 0.3988 - accuracy: 0.8117\n",
      "Epoch 68/200\n",
      "191/191 [==============================] - 0s 410us/step - loss: 0.3991 - accuracy: 0.8107\n",
      "Epoch 69/200\n",
      "191/191 [==============================] - 0s 425us/step - loss: 0.3993 - accuracy: 0.8120\n",
      "Epoch 70/200\n",
      "191/191 [==============================] - 0s 437us/step - loss: 0.3980 - accuracy: 0.8108\n",
      "Epoch 71/200\n",
      "191/191 [==============================] - 0s 420us/step - loss: 0.3960 - accuracy: 0.8123\n",
      "Epoch 72/200\n",
      "191/191 [==============================] - 0s 452us/step - loss: 0.3980 - accuracy: 0.8115\n",
      "Epoch 73/200\n",
      "191/191 [==============================] - 0s 424us/step - loss: 0.3979 - accuracy: 0.8112\n",
      "Epoch 74/200\n",
      "191/191 [==============================] - 0s 434us/step - loss: 0.3957 - accuracy: 0.8153\n",
      "Epoch 75/200\n",
      "191/191 [==============================] - 0s 773us/step - loss: 0.3990 - accuracy: 0.8122\n",
      "Epoch 76/200\n",
      "191/191 [==============================] - 0s 441us/step - loss: 0.3958 - accuracy: 0.8143\n",
      "Epoch 77/200\n",
      "191/191 [==============================] - 0s 472us/step - loss: 0.3966 - accuracy: 0.8194\n",
      "Epoch 78/200\n",
      "191/191 [==============================] - 0s 531us/step - loss: 0.3986 - accuracy: 0.8107\n",
      "Epoch 79/200\n",
      "191/191 [==============================] - 0s 438us/step - loss: 0.3922 - accuracy: 0.8146\n",
      "Epoch 80/200\n",
      "191/191 [==============================] - 0s 434us/step - loss: 0.3965 - accuracy: 0.8159\n",
      "Epoch 81/200\n",
      "191/191 [==============================] - 0s 462us/step - loss: 0.3970 - accuracy: 0.8127\n",
      "Epoch 82/200\n",
      "191/191 [==============================] - 0s 437us/step - loss: 0.3990 - accuracy: 0.8097\n",
      "Epoch 83/200\n",
      "191/191 [==============================] - 0s 446us/step - loss: 0.4015 - accuracy: 0.8051\n",
      "Epoch 84/200\n",
      "191/191 [==============================] - 0s 439us/step - loss: 0.3957 - accuracy: 0.8143\n",
      "Epoch 85/200\n",
      "191/191 [==============================] - 0s 468us/step - loss: 0.3929 - accuracy: 0.8148\n",
      "Epoch 86/200\n",
      "191/191 [==============================] - 0s 446us/step - loss: 0.3929 - accuracy: 0.8151\n",
      "Epoch 87/200\n",
      "191/191 [==============================] - 0s 454us/step - loss: 0.3974 - accuracy: 0.8148\n",
      "Epoch 88/200\n",
      "191/191 [==============================] - 0s 497us/step - loss: 0.3944 - accuracy: 0.8161\n",
      "Epoch 89/200\n",
      "191/191 [==============================] - 0s 450us/step - loss: 0.3968 - accuracy: 0.8156\n",
      "Epoch 90/200\n",
      "191/191 [==============================] - 0s 451us/step - loss: 0.3948 - accuracy: 0.8102\n",
      "Epoch 91/200\n",
      "191/191 [==============================] - 0s 441us/step - loss: 0.3991 - accuracy: 0.8143\n",
      "Epoch 92/200\n",
      "191/191 [==============================] - 0s 455us/step - loss: 0.3959 - accuracy: 0.8143\n",
      "Epoch 93/200\n",
      "191/191 [==============================] - 0s 438us/step - loss: 0.3940 - accuracy: 0.8154\n",
      "Epoch 94/200\n",
      "191/191 [==============================] - 0s 459us/step - loss: 0.3944 - accuracy: 0.8140\n",
      "Epoch 95/200\n",
      "191/191 [==============================] - 0s 440us/step - loss: 0.3915 - accuracy: 0.8136\n",
      "Epoch 96/200\n",
      "191/191 [==============================] - 0s 463us/step - loss: 0.3934 - accuracy: 0.8128\n",
      "Epoch 97/200\n",
      "191/191 [==============================] - 0s 444us/step - loss: 0.3927 - accuracy: 0.8154\n",
      "Epoch 98/200\n",
      "191/191 [==============================] - 0s 443us/step - loss: 0.3937 - accuracy: 0.8127\n",
      "Epoch 99/200\n",
      "191/191 [==============================] - 0s 444us/step - loss: 0.3924 - accuracy: 0.8145\n",
      "Epoch 100/200\n",
      "191/191 [==============================] - 0s 436us/step - loss: 0.3941 - accuracy: 0.8166\n",
      "Epoch 101/200\n",
      "191/191 [==============================] - 0s 436us/step - loss: 0.3965 - accuracy: 0.8154\n",
      "Epoch 102/200\n",
      "191/191 [==============================] - 0s 442us/step - loss: 0.3964 - accuracy: 0.8112\n",
      "Epoch 103/200\n",
      "191/191 [==============================] - 0s 452us/step - loss: 0.3962 - accuracy: 0.8128\n",
      "Epoch 104/200\n",
      "191/191 [==============================] - 0s 426us/step - loss: 0.3970 - accuracy: 0.8133\n",
      "Epoch 105/200\n",
      "191/191 [==============================] - 0s 456us/step - loss: 0.3954 - accuracy: 0.8131\n",
      "Epoch 106/200\n",
      "191/191 [==============================] - 0s 438us/step - loss: 0.3947 - accuracy: 0.8128\n",
      "Epoch 107/200\n",
      "191/191 [==============================] - 0s 443us/step - loss: 0.3950 - accuracy: 0.8097\n",
      "Epoch 108/200\n",
      "191/191 [==============================] - 0s 432us/step - loss: 0.3943 - accuracy: 0.8138\n",
      "Epoch 109/200\n",
      "191/191 [==============================] - 0s 435us/step - loss: 0.3932 - accuracy: 0.8154\n",
      "Epoch 110/200\n",
      "191/191 [==============================] - 0s 433us/step - loss: 0.3956 - accuracy: 0.8153\n",
      "Epoch 111/200\n",
      "191/191 [==============================] - 0s 658us/step - loss: 0.3933 - accuracy: 0.8161\n",
      "Epoch 112/200\n",
      "191/191 [==============================] - 0s 498us/step - loss: 0.3930 - accuracy: 0.8107\n",
      "Epoch 113/200\n",
      "191/191 [==============================] - 0s 516us/step - loss: 0.3923 - accuracy: 0.8135\n",
      "Epoch 114/200\n",
      "191/191 [==============================] - 0s 571us/step - loss: 0.3912 - accuracy: 0.8128\n",
      "Epoch 115/200\n",
      "191/191 [==============================] - 0s 453us/step - loss: 0.3930 - accuracy: 0.8163\n",
      "Epoch 116/200\n",
      "191/191 [==============================] - 0s 446us/step - loss: 0.3906 - accuracy: 0.8174\n",
      "Epoch 117/200\n",
      "191/191 [==============================] - 0s 460us/step - loss: 0.3898 - accuracy: 0.8179\n",
      "Epoch 118/200\n",
      "191/191 [==============================] - 0s 454us/step - loss: 0.3938 - accuracy: 0.8181\n",
      "Epoch 119/200\n",
      "191/191 [==============================] - 0s 443us/step - loss: 0.3957 - accuracy: 0.8166\n",
      "Epoch 120/200\n",
      "191/191 [==============================] - 0s 463us/step - loss: 0.3913 - accuracy: 0.8174\n",
      "Epoch 121/200\n",
      "191/191 [==============================] - 0s 467us/step - loss: 0.3933 - accuracy: 0.8140\n",
      "Epoch 122/200\n",
      "191/191 [==============================] - 0s 492us/step - loss: 0.3926 - accuracy: 0.8169\n",
      "Epoch 123/200\n",
      "191/191 [==============================] - 0s 449us/step - loss: 0.3912 - accuracy: 0.8117\n",
      "Epoch 124/200\n",
      "191/191 [==============================] - 0s 438us/step - loss: 0.3944 - accuracy: 0.8166\n",
      "Epoch 125/200\n",
      "191/191 [==============================] - 0s 424us/step - loss: 0.3916 - accuracy: 0.8136\n",
      "Epoch 126/200\n",
      "191/191 [==============================] - 0s 426us/step - loss: 0.3895 - accuracy: 0.8166\n",
      "Epoch 127/200\n",
      "191/191 [==============================] - 0s 425us/step - loss: 0.3896 - accuracy: 0.8174\n",
      "Epoch 128/200\n",
      "191/191 [==============================] - 0s 435us/step - loss: 0.3906 - accuracy: 0.8192\n",
      "Epoch 129/200\n",
      "191/191 [==============================] - 0s 449us/step - loss: 0.3941 - accuracy: 0.8140\n",
      "Epoch 130/200\n",
      "191/191 [==============================] - 0s 456us/step - loss: 0.3875 - accuracy: 0.8179\n",
      "Epoch 131/200\n",
      "191/191 [==============================] - 0s 425us/step - loss: 0.3936 - accuracy: 0.8168\n",
      "Epoch 132/200\n",
      "191/191 [==============================] - 0s 437us/step - loss: 0.3920 - accuracy: 0.8131\n",
      "Epoch 133/200\n",
      "191/191 [==============================] - 0s 430us/step - loss: 0.3890 - accuracy: 0.8184\n",
      "Epoch 134/200\n",
      "191/191 [==============================] - 0s 413us/step - loss: 0.3917 - accuracy: 0.8166\n",
      "Epoch 135/200\n",
      "191/191 [==============================] - 0s 422us/step - loss: 0.3922 - accuracy: 0.8174\n",
      "Epoch 136/200\n",
      "191/191 [==============================] - 0s 426us/step - loss: 0.3899 - accuracy: 0.8141\n",
      "Epoch 137/200\n",
      "191/191 [==============================] - 0s 416us/step - loss: 0.3937 - accuracy: 0.8127\n",
      "Epoch 138/200\n",
      "191/191 [==============================] - 0s 416us/step - loss: 0.3937 - accuracy: 0.8156\n",
      "Epoch 139/200\n",
      "191/191 [==============================] - 0s 471us/step - loss: 0.3876 - accuracy: 0.8200\n",
      "Epoch 140/200\n",
      "191/191 [==============================] - 0s 434us/step - loss: 0.3910 - accuracy: 0.8179\n",
      "Epoch 141/200\n",
      "191/191 [==============================] - 0s 430us/step - loss: 0.3929 - accuracy: 0.8153\n",
      "Epoch 142/200\n",
      "191/191 [==============================] - 0s 444us/step - loss: 0.3918 - accuracy: 0.8100\n",
      "Epoch 143/200\n",
      "191/191 [==============================] - 0s 446us/step - loss: 0.3914 - accuracy: 0.8177\n",
      "Epoch 144/200\n",
      "191/191 [==============================] - 0s 847us/step - loss: 0.3891 - accuracy: 0.8153\n",
      "Epoch 145/200\n",
      "191/191 [==============================] - 0s 502us/step - loss: 0.3894 - accuracy: 0.8150\n",
      "Epoch 146/200\n",
      "191/191 [==============================] - 0s 665us/step - loss: 0.3903 - accuracy: 0.8197\n",
      "Epoch 147/200\n",
      "191/191 [==============================] - 0s 446us/step - loss: 0.3882 - accuracy: 0.8181\n",
      "Epoch 148/200\n",
      "191/191 [==============================] - 0s 857us/step - loss: 0.3900 - accuracy: 0.8191\n",
      "Epoch 149/200\n",
      "191/191 [==============================] - 0s 744us/step - loss: 0.3903 - accuracy: 0.8164\n",
      "Epoch 150/200\n",
      "191/191 [==============================] - 0s 434us/step - loss: 0.3881 - accuracy: 0.8143\n",
      "Epoch 151/200\n",
      "191/191 [==============================] - 0s 469us/step - loss: 0.3881 - accuracy: 0.8179\n",
      "Epoch 152/200\n",
      "191/191 [==============================] - 0s 438us/step - loss: 0.3918 - accuracy: 0.8163\n",
      "Epoch 153/200\n",
      "191/191 [==============================] - 0s 443us/step - loss: 0.3915 - accuracy: 0.8154\n",
      "Epoch 154/200\n",
      "191/191 [==============================] - 0s 562us/step - loss: 0.3876 - accuracy: 0.8205\n",
      "Epoch 155/200\n",
      "191/191 [==============================] - 0s 472us/step - loss: 0.3896 - accuracy: 0.8166\n",
      "Epoch 156/200\n",
      "191/191 [==============================] - 0s 479us/step - loss: 0.3886 - accuracy: 0.8189\n",
      "Epoch 157/200\n",
      "191/191 [==============================] - 0s 493us/step - loss: 0.3903 - accuracy: 0.8179\n",
      "Epoch 158/200\n",
      "191/191 [==============================] - 0s 494us/step - loss: 0.3917 - accuracy: 0.8136\n",
      "Epoch 159/200\n",
      "191/191 [==============================] - 0s 498us/step - loss: 0.3899 - accuracy: 0.8176\n",
      "Epoch 160/200\n",
      "191/191 [==============================] - 0s 516us/step - loss: 0.3878 - accuracy: 0.8153\n",
      "Epoch 161/200\n",
      "191/191 [==============================] - 0s 468us/step - loss: 0.3877 - accuracy: 0.8173\n",
      "Epoch 162/200\n",
      "191/191 [==============================] - 0s 441us/step - loss: 0.3914 - accuracy: 0.8108\n",
      "Epoch 163/200\n",
      "191/191 [==============================] - 0s 457us/step - loss: 0.3897 - accuracy: 0.8184\n",
      "Epoch 164/200\n",
      "191/191 [==============================] - 0s 436us/step - loss: 0.3922 - accuracy: 0.8150\n",
      "Epoch 165/200\n",
      "191/191 [==============================] - 0s 439us/step - loss: 0.3874 - accuracy: 0.8168\n",
      "Epoch 166/200\n",
      "191/191 [==============================] - 0s 462us/step - loss: 0.3890 - accuracy: 0.8135\n",
      "Epoch 167/200\n",
      "191/191 [==============================] - 0s 797us/step - loss: 0.3892 - accuracy: 0.8154\n",
      "Epoch 168/200\n",
      "191/191 [==============================] - 0s 458us/step - loss: 0.3884 - accuracy: 0.8187\n",
      "Epoch 169/200\n",
      "191/191 [==============================] - 0s 476us/step - loss: 0.3893 - accuracy: 0.8154\n",
      "Epoch 170/200\n",
      "191/191 [==============================] - 0s 658us/step - loss: 0.3913 - accuracy: 0.8148\n",
      "Epoch 171/200\n",
      "191/191 [==============================] - 0s 473us/step - loss: 0.3867 - accuracy: 0.8194\n",
      "Epoch 172/200\n",
      "191/191 [==============================] - 0s 462us/step - loss: 0.3878 - accuracy: 0.8222\n",
      "Epoch 173/200\n",
      "191/191 [==============================] - 0s 453us/step - loss: 0.3883 - accuracy: 0.8184\n",
      "Epoch 174/200\n",
      "191/191 [==============================] - 0s 486us/step - loss: 0.3894 - accuracy: 0.8182\n",
      "Epoch 175/200\n",
      "191/191 [==============================] - 0s 498us/step - loss: 0.3857 - accuracy: 0.8202\n",
      "Epoch 176/200\n",
      "191/191 [==============================] - 0s 488us/step - loss: 0.3862 - accuracy: 0.8189\n",
      "Epoch 177/200\n",
      "191/191 [==============================] - 0s 443us/step - loss: 0.3885 - accuracy: 0.8174\n",
      "Epoch 178/200\n",
      "191/191 [==============================] - 0s 452us/step - loss: 0.3888 - accuracy: 0.8209\n",
      "Epoch 179/200\n",
      "191/191 [==============================] - 0s 450us/step - loss: 0.3900 - accuracy: 0.8151\n",
      "Epoch 180/200\n",
      "191/191 [==============================] - 0s 454us/step - loss: 0.3869 - accuracy: 0.8204\n",
      "Epoch 181/200\n",
      "191/191 [==============================] - 0s 442us/step - loss: 0.3912 - accuracy: 0.8163\n",
      "Epoch 182/200\n",
      "191/191 [==============================] - 0s 444us/step - loss: 0.3877 - accuracy: 0.8194\n",
      "Epoch 183/200\n",
      "191/191 [==============================] - 0s 453us/step - loss: 0.3868 - accuracy: 0.8204\n",
      "Epoch 184/200\n",
      "191/191 [==============================] - 0s 459us/step - loss: 0.3875 - accuracy: 0.8192\n",
      "Epoch 185/200\n",
      "191/191 [==============================] - 0s 454us/step - loss: 0.3879 - accuracy: 0.8192\n",
      "Epoch 186/200\n",
      "191/191 [==============================] - 0s 508us/step - loss: 0.3899 - accuracy: 0.8154\n",
      "Epoch 187/200\n",
      "191/191 [==============================] - 0s 455us/step - loss: 0.3878 - accuracy: 0.8205\n",
      "Epoch 188/200\n",
      "191/191 [==============================] - 0s 472us/step - loss: 0.3850 - accuracy: 0.8184\n",
      "Epoch 189/200\n",
      "191/191 [==============================] - 0s 439us/step - loss: 0.3876 - accuracy: 0.8212\n",
      "Epoch 190/200\n",
      "191/191 [==============================] - 0s 433us/step - loss: 0.3906 - accuracy: 0.8156\n",
      "Epoch 191/200\n",
      "191/191 [==============================] - 0s 429us/step - loss: 0.3902 - accuracy: 0.8158\n",
      "Epoch 192/200\n",
      "191/191 [==============================] - 0s 481us/step - loss: 0.3866 - accuracy: 0.8179\n",
      "Epoch 193/200\n",
      "191/191 [==============================] - 0s 437us/step - loss: 0.3804 - accuracy: 0.8260\n",
      "Epoch 194/200\n",
      "191/191 [==============================] - 0s 448us/step - loss: 0.3832 - accuracy: 0.8199\n",
      "Epoch 195/200\n",
      "191/191 [==============================] - 0s 905us/step - loss: 0.3868 - accuracy: 0.8187\n",
      "Epoch 196/200\n",
      "191/191 [==============================] - 0s 447us/step - loss: 0.3891 - accuracy: 0.8154\n",
      "Epoch 197/200\n",
      "191/191 [==============================] - 0s 470us/step - loss: 0.3868 - accuracy: 0.8224\n",
      "Epoch 198/200\n",
      "191/191 [==============================] - 0s 527us/step - loss: 0.3910 - accuracy: 0.8163\n",
      "Epoch 199/200\n",
      "191/191 [==============================] - 0s 486us/step - loss: 0.3897 - accuracy: 0.8184\n",
      "Epoch 200/200\n",
      "191/191 [==============================] - 0s 434us/step - loss: 0.3830 - accuracy: 0.8219\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "classifier = KerasClassifier(build_fn = build_classifier)\n",
    "param_grid = dict(optimizer = ['Adam'],\n",
    "                  epochs=[100, 200],\n",
    "                  batch_size=[16, 32])\n",
    "grid = GridSearchCV(estimator=classifier, \n",
    "                    param_grid=param_grid, \n",
    "                    scoring='accuracy', \n",
    "                    verbose=0)\n",
    "\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=50)\n",
    "\n",
    "grid_result = grid.fit(X_train, y_train, callbacks=[early_stopping])\n",
    "best_parameters = grid.best_params_\n",
    "best_accuracy = grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "43cb79f1-ea38-4bf1-95a7-f0d8bdba3438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_accuracy: 0.8054231717337714\n"
     ]
    }
   ],
   "source": [
    "best_parameters = grid.best_params_\n",
    "best_accuracy = grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "71ad0160-4abc-4dac-9c60-5b0e52a24fc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.805423 using {'batch_size': 32, 'epochs': 200, 'optimizer': 'Adam'}\n",
      "0.799507 (0.019403) with: {'batch_size': 16, 'epochs': 100, 'optimizer': 'Adam'}\n",
      "0.801479 (0.016700) with: {'batch_size': 16, 'epochs': 200, 'optimizer': 'Adam'}\n",
      "0.800657 (0.017780) with: {'batch_size': 32, 'epochs': 100, 'optimizer': 'Adam'}\n",
      "0.805423 (0.010386) with: {'batch_size': 32, 'epochs': 200, 'optimizer': 'Adam'}\n"
     ]
    }
   ],
   "source": [
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid.best_score_, grid.best_params_))\n",
    "means = grid.cv_results_['mean_test_score']\n",
    "stds = grid.cv_results_['std_test_score']\n",
    "params = grid.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4b9efdf0-6218-461d-a1fb-3cf95d7c5ed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qp/5z2vy03j04s0yht5rwlccksw0000gn/T/ipykernel_58696/3483121816.py:1: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  classifier = KerasClassifier(build_fn = build_classifier,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "191/191 [==============================] - 1s 451us/step - loss: 0.5675 - accuracy: 0.7195\n",
      "Epoch 2/200\n",
      "191/191 [==============================] - 0s 449us/step - loss: 0.4509 - accuracy: 0.7814\n",
      "Epoch 3/200\n",
      "191/191 [==============================] - 0s 555us/step - loss: 0.4324 - accuracy: 0.7905\n",
      "Epoch 4/200\n",
      "191/191 [==============================] - 0s 447us/step - loss: 0.4269 - accuracy: 0.7919\n",
      "Epoch 5/200\n",
      "191/191 [==============================] - 0s 471us/step - loss: 0.4301 - accuracy: 0.7918\n",
      "Epoch 6/200\n",
      "191/191 [==============================] - 0s 454us/step - loss: 0.4266 - accuracy: 0.7895\n",
      "Epoch 7/200\n",
      "191/191 [==============================] - 0s 442us/step - loss: 0.4233 - accuracy: 0.7957\n",
      "Epoch 8/200\n",
      "191/191 [==============================] - 0s 433us/step - loss: 0.4225 - accuracy: 0.7984\n",
      "Epoch 9/200\n",
      "191/191 [==============================] - 0s 459us/step - loss: 0.4247 - accuracy: 0.7941\n",
      "Epoch 10/200\n",
      "191/191 [==============================] - 0s 444us/step - loss: 0.4234 - accuracy: 0.7952\n",
      "Epoch 11/200\n",
      "191/191 [==============================] - 0s 449us/step - loss: 0.4209 - accuracy: 0.7998\n",
      "Epoch 12/200\n",
      "191/191 [==============================] - 0s 437us/step - loss: 0.4198 - accuracy: 0.8010\n",
      "Epoch 13/200\n",
      "191/191 [==============================] - 0s 444us/step - loss: 0.4200 - accuracy: 0.7974\n",
      "Epoch 14/200\n",
      "191/191 [==============================] - 0s 427us/step - loss: 0.4160 - accuracy: 0.7997\n",
      "Epoch 15/200\n",
      "191/191 [==============================] - 0s 429us/step - loss: 0.4152 - accuracy: 0.7970\n",
      "Epoch 16/200\n",
      "191/191 [==============================] - 0s 425us/step - loss: 0.4183 - accuracy: 0.7982\n",
      "Epoch 17/200\n",
      "191/191 [==============================] - 0s 435us/step - loss: 0.4133 - accuracy: 0.8003\n",
      "Epoch 18/200\n",
      "191/191 [==============================] - 0s 428us/step - loss: 0.4181 - accuracy: 0.7965\n",
      "Epoch 19/200\n",
      "191/191 [==============================] - 0s 429us/step - loss: 0.4120 - accuracy: 0.8023\n",
      "Epoch 20/200\n",
      "191/191 [==============================] - 0s 422us/step - loss: 0.4165 - accuracy: 0.8025\n",
      "Epoch 21/200\n",
      "191/191 [==============================] - 0s 440us/step - loss: 0.4088 - accuracy: 0.8046\n",
      "Epoch 22/200\n",
      "191/191 [==============================] - 0s 433us/step - loss: 0.4132 - accuracy: 0.7979\n",
      "Epoch 23/200\n",
      "191/191 [==============================] - 0s 431us/step - loss: 0.4136 - accuracy: 0.7992\n",
      "Epoch 24/200\n",
      "191/191 [==============================] - 0s 423us/step - loss: 0.4093 - accuracy: 0.8033\n",
      "Epoch 25/200\n",
      "191/191 [==============================] - 0s 429us/step - loss: 0.4112 - accuracy: 0.7992\n",
      "Epoch 26/200\n",
      "191/191 [==============================] - 0s 431us/step - loss: 0.4129 - accuracy: 0.8020\n",
      "Epoch 27/200\n",
      "191/191 [==============================] - 0s 433us/step - loss: 0.4102 - accuracy: 0.7993\n",
      "Epoch 28/200\n",
      "191/191 [==============================] - 0s 523us/step - loss: 0.4114 - accuracy: 0.8061\n",
      "Epoch 29/200\n",
      "191/191 [==============================] - 0s 479us/step - loss: 0.4105 - accuracy: 0.8039\n",
      "Epoch 30/200\n",
      "191/191 [==============================] - 0s 423us/step - loss: 0.4083 - accuracy: 0.8049\n",
      "Epoch 31/200\n",
      "191/191 [==============================] - 0s 422us/step - loss: 0.4085 - accuracy: 0.8031\n",
      "Epoch 32/200\n",
      "191/191 [==============================] - 0s 421us/step - loss: 0.4039 - accuracy: 0.8058\n",
      "Epoch 33/200\n",
      "191/191 [==============================] - 0s 435us/step - loss: 0.4066 - accuracy: 0.8053\n",
      "Epoch 34/200\n",
      "191/191 [==============================] - 0s 417us/step - loss: 0.4042 - accuracy: 0.8051\n",
      "Epoch 35/200\n",
      "191/191 [==============================] - 0s 427us/step - loss: 0.4062 - accuracy: 0.8015\n",
      "Epoch 36/200\n",
      "191/191 [==============================] - 0s 455us/step - loss: 0.4068 - accuracy: 0.8018\n",
      "Epoch 37/200\n",
      "191/191 [==============================] - 0s 447us/step - loss: 0.4045 - accuracy: 0.8066\n",
      "Epoch 38/200\n",
      "191/191 [==============================] - 0s 428us/step - loss: 0.4055 - accuracy: 0.8010\n",
      "Epoch 39/200\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.4069 - accuracy: 0.8018\n",
      "Epoch 40/200\n",
      "191/191 [==============================] - 0s 435us/step - loss: 0.4062 - accuracy: 0.8013\n",
      "Epoch 41/200\n",
      "191/191 [==============================] - 0s 435us/step - loss: 0.4053 - accuracy: 0.8049\n",
      "Epoch 42/200\n",
      "191/191 [==============================] - 0s 469us/step - loss: 0.4065 - accuracy: 0.7992\n",
      "Epoch 43/200\n",
      "191/191 [==============================] - 0s 442us/step - loss: 0.4042 - accuracy: 0.8074\n",
      "Epoch 44/200\n",
      "191/191 [==============================] - 0s 433us/step - loss: 0.4039 - accuracy: 0.8074\n",
      "Epoch 45/200\n",
      "191/191 [==============================] - 0s 434us/step - loss: 0.4051 - accuracy: 0.8035\n",
      "Epoch 46/200\n",
      "191/191 [==============================] - 0s 426us/step - loss: 0.4028 - accuracy: 0.8056\n",
      "Epoch 47/200\n",
      "191/191 [==============================] - 0s 429us/step - loss: 0.4018 - accuracy: 0.8048\n",
      "Epoch 48/200\n",
      "191/191 [==============================] - 0s 435us/step - loss: 0.4022 - accuracy: 0.8102\n",
      "Epoch 49/200\n",
      "191/191 [==============================] - 0s 442us/step - loss: 0.4038 - accuracy: 0.8036\n",
      "Epoch 50/200\n",
      "191/191 [==============================] - 0s 437us/step - loss: 0.4051 - accuracy: 0.8053\n",
      "Epoch 51/200\n",
      "191/191 [==============================] - 0s 433us/step - loss: 0.4016 - accuracy: 0.8079\n",
      "Epoch 52/200\n",
      "191/191 [==============================] - 0s 431us/step - loss: 0.4060 - accuracy: 0.8023\n",
      "Epoch 53/200\n",
      "191/191 [==============================] - 0s 430us/step - loss: 0.4055 - accuracy: 0.8018\n",
      "Epoch 54/200\n",
      "191/191 [==============================] - 0s 429us/step - loss: 0.3978 - accuracy: 0.8074\n",
      "Epoch 55/200\n",
      "191/191 [==============================] - 0s 438us/step - loss: 0.4008 - accuracy: 0.8066\n",
      "Epoch 56/200\n",
      "191/191 [==============================] - 0s 440us/step - loss: 0.4015 - accuracy: 0.8072\n",
      "Epoch 57/200\n",
      "191/191 [==============================] - 0s 436us/step - loss: 0.4028 - accuracy: 0.8015\n",
      "Epoch 58/200\n",
      "191/191 [==============================] - 0s 440us/step - loss: 0.4013 - accuracy: 0.8099\n",
      "Epoch 59/200\n",
      "191/191 [==============================] - 0s 438us/step - loss: 0.3953 - accuracy: 0.8058\n",
      "Epoch 60/200\n",
      "191/191 [==============================] - 0s 443us/step - loss: 0.4015 - accuracy: 0.8085\n",
      "Epoch 61/200\n",
      "191/191 [==============================] - 0s 437us/step - loss: 0.4003 - accuracy: 0.8054\n",
      "Epoch 62/200\n",
      "191/191 [==============================] - 0s 430us/step - loss: 0.4005 - accuracy: 0.8090\n",
      "Epoch 63/200\n",
      "191/191 [==============================] - 0s 436us/step - loss: 0.4009 - accuracy: 0.8079\n",
      "Epoch 64/200\n",
      "191/191 [==============================] - 0s 431us/step - loss: 0.3996 - accuracy: 0.8099\n",
      "Epoch 65/200\n",
      "191/191 [==============================] - 0s 446us/step - loss: 0.3994 - accuracy: 0.8082\n",
      "Epoch 66/200\n",
      "191/191 [==============================] - 0s 433us/step - loss: 0.3979 - accuracy: 0.8079\n",
      "Epoch 67/200\n",
      "191/191 [==============================] - 0s 435us/step - loss: 0.3959 - accuracy: 0.8087\n",
      "Epoch 68/200\n",
      "191/191 [==============================] - 0s 430us/step - loss: 0.4009 - accuracy: 0.8067\n",
      "Epoch 69/200\n",
      "191/191 [==============================] - 0s 426us/step - loss: 0.3952 - accuracy: 0.8094\n",
      "Epoch 70/200\n",
      "191/191 [==============================] - 0s 435us/step - loss: 0.3983 - accuracy: 0.8104\n",
      "Epoch 71/200\n",
      "191/191 [==============================] - 0s 429us/step - loss: 0.3998 - accuracy: 0.8100\n",
      "Epoch 72/200\n",
      "191/191 [==============================] - 0s 432us/step - loss: 0.3950 - accuracy: 0.8107\n",
      "Epoch 73/200\n",
      "191/191 [==============================] - 0s 442us/step - loss: 0.4014 - accuracy: 0.8036\n",
      "Epoch 74/200\n",
      "191/191 [==============================] - 0s 435us/step - loss: 0.4003 - accuracy: 0.8049\n",
      "Epoch 75/200\n",
      "191/191 [==============================] - 0s 435us/step - loss: 0.4025 - accuracy: 0.8048\n",
      "Epoch 76/200\n",
      "191/191 [==============================] - 0s 422us/step - loss: 0.3992 - accuracy: 0.8108\n",
      "Epoch 77/200\n",
      "191/191 [==============================] - 0s 434us/step - loss: 0.3999 - accuracy: 0.8048\n",
      "Epoch 78/200\n",
      "191/191 [==============================] - 0s 442us/step - loss: 0.3971 - accuracy: 0.8113\n",
      "Epoch 79/200\n",
      "191/191 [==============================] - 0s 433us/step - loss: 0.3955 - accuracy: 0.8105\n",
      "Epoch 80/200\n",
      "191/191 [==============================] - 0s 434us/step - loss: 0.3957 - accuracy: 0.8127\n",
      "Epoch 81/200\n",
      "191/191 [==============================] - 0s 436us/step - loss: 0.3958 - accuracy: 0.8084\n",
      "Epoch 82/200\n",
      "191/191 [==============================] - 0s 446us/step - loss: 0.3981 - accuracy: 0.8056\n",
      "Epoch 83/200\n",
      "191/191 [==============================] - 0s 429us/step - loss: 0.3977 - accuracy: 0.8084\n",
      "Epoch 84/200\n",
      "191/191 [==============================] - 0s 437us/step - loss: 0.3991 - accuracy: 0.8033\n",
      "Epoch 85/200\n",
      "191/191 [==============================] - 0s 437us/step - loss: 0.3984 - accuracy: 0.8067\n",
      "Epoch 86/200\n",
      "191/191 [==============================] - 0s 433us/step - loss: 0.3977 - accuracy: 0.8074\n",
      "Epoch 87/200\n",
      "191/191 [==============================] - 0s 440us/step - loss: 0.3964 - accuracy: 0.8084\n",
      "Epoch 88/200\n",
      "191/191 [==============================] - 0s 430us/step - loss: 0.3972 - accuracy: 0.8044\n",
      "Epoch 89/200\n",
      "191/191 [==============================] - 0s 440us/step - loss: 0.3977 - accuracy: 0.8092\n",
      "Epoch 90/200\n",
      "191/191 [==============================] - 0s 440us/step - loss: 0.3948 - accuracy: 0.8104\n",
      "Epoch 91/200\n",
      "191/191 [==============================] - 0s 450us/step - loss: 0.3962 - accuracy: 0.8058\n",
      "Epoch 92/200\n",
      "191/191 [==============================] - 0s 434us/step - loss: 0.3950 - accuracy: 0.8125\n",
      "Epoch 93/200\n",
      "191/191 [==============================] - 0s 430us/step - loss: 0.3948 - accuracy: 0.8102\n",
      "Epoch 94/200\n",
      "191/191 [==============================] - 0s 438us/step - loss: 0.3913 - accuracy: 0.8140\n",
      "Epoch 95/200\n",
      "191/191 [==============================] - 0s 435us/step - loss: 0.3971 - accuracy: 0.8064\n",
      "Epoch 96/200\n",
      "191/191 [==============================] - 0s 457us/step - loss: 0.3983 - accuracy: 0.8041\n",
      "Epoch 97/200\n",
      "191/191 [==============================] - 0s 436us/step - loss: 0.3981 - accuracy: 0.8069\n",
      "Epoch 98/200\n",
      "191/191 [==============================] - 0s 434us/step - loss: 0.3965 - accuracy: 0.8102\n",
      "Epoch 99/200\n",
      "191/191 [==============================] - 0s 433us/step - loss: 0.3919 - accuracy: 0.8148\n",
      "Epoch 100/200\n",
      "191/191 [==============================] - 0s 437us/step - loss: 0.3974 - accuracy: 0.8108\n",
      "Epoch 101/200\n",
      "191/191 [==============================] - 0s 434us/step - loss: 0.3952 - accuracy: 0.8058\n",
      "Epoch 102/200\n",
      "191/191 [==============================] - 0s 434us/step - loss: 0.3981 - accuracy: 0.8092\n",
      "Epoch 103/200\n",
      "191/191 [==============================] - 0s 435us/step - loss: 0.3989 - accuracy: 0.8064\n",
      "Epoch 104/200\n",
      "191/191 [==============================] - 0s 444us/step - loss: 0.3930 - accuracy: 0.8113\n",
      "Epoch 105/200\n",
      "191/191 [==============================] - 0s 435us/step - loss: 0.3971 - accuracy: 0.8120\n",
      "Epoch 106/200\n",
      "191/191 [==============================] - 0s 438us/step - loss: 0.3961 - accuracy: 0.8107\n",
      "Epoch 107/200\n",
      "191/191 [==============================] - 0s 441us/step - loss: 0.3926 - accuracy: 0.8108\n",
      "Epoch 108/200\n",
      "191/191 [==============================] - 0s 442us/step - loss: 0.3959 - accuracy: 0.8051\n",
      "Epoch 109/200\n",
      "191/191 [==============================] - 0s 439us/step - loss: 0.3926 - accuracy: 0.8085\n",
      "Epoch 110/200\n",
      "191/191 [==============================] - 0s 457us/step - loss: 0.3968 - accuracy: 0.8085\n",
      "Epoch 111/200\n",
      "191/191 [==============================] - 0s 431us/step - loss: 0.3950 - accuracy: 0.8077\n",
      "Epoch 112/200\n",
      "191/191 [==============================] - 0s 444us/step - loss: 0.3928 - accuracy: 0.8131\n",
      "Epoch 113/200\n",
      "191/191 [==============================] - 0s 461us/step - loss: 0.3968 - accuracy: 0.8067\n",
      "Epoch 114/200\n",
      "191/191 [==============================] - 0s 527us/step - loss: 0.3934 - accuracy: 0.8138\n",
      "Epoch 115/200\n",
      "191/191 [==============================] - 0s 443us/step - loss: 0.3925 - accuracy: 0.8115\n",
      "Epoch 116/200\n",
      "191/191 [==============================] - 0s 448us/step - loss: 0.3940 - accuracy: 0.8112\n",
      "Epoch 117/200\n",
      "191/191 [==============================] - 0s 435us/step - loss: 0.3892 - accuracy: 0.8140\n",
      "Epoch 118/200\n",
      "191/191 [==============================] - 0s 447us/step - loss: 0.3935 - accuracy: 0.8141\n",
      "Epoch 119/200\n",
      "191/191 [==============================] - 0s 476us/step - loss: 0.3968 - accuracy: 0.8082\n",
      "Epoch 120/200\n",
      "191/191 [==============================] - 0s 456us/step - loss: 0.3898 - accuracy: 0.8117\n",
      "Epoch 121/200\n",
      "191/191 [==============================] - 0s 451us/step - loss: 0.3962 - accuracy: 0.8049\n",
      "Epoch 122/200\n",
      "191/191 [==============================] - 0s 445us/step - loss: 0.3924 - accuracy: 0.8128\n",
      "Epoch 123/200\n",
      "191/191 [==============================] - 0s 430us/step - loss: 0.3941 - accuracy: 0.8094\n",
      "Epoch 124/200\n",
      "191/191 [==============================] - 0s 434us/step - loss: 0.3932 - accuracy: 0.8082\n",
      "Epoch 125/200\n",
      "191/191 [==============================] - 0s 437us/step - loss: 0.3928 - accuracy: 0.8122\n",
      "Epoch 126/200\n",
      "191/191 [==============================] - 0s 464us/step - loss: 0.3957 - accuracy: 0.8115\n",
      "Epoch 127/200\n",
      "191/191 [==============================] - 0s 443us/step - loss: 0.3905 - accuracy: 0.8164\n",
      "Epoch 128/200\n",
      "191/191 [==============================] - 0s 439us/step - loss: 0.3942 - accuracy: 0.8082\n",
      "Epoch 129/200\n",
      "191/191 [==============================] - 0s 451us/step - loss: 0.3956 - accuracy: 0.8108\n",
      "Epoch 130/200\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.3953 - accuracy: 0.8077\n",
      "Epoch 131/200\n",
      "191/191 [==============================] - 0s 568us/step - loss: 0.3907 - accuracy: 0.8156\n",
      "Epoch 132/200\n",
      "191/191 [==============================] - 0s 439us/step - loss: 0.3913 - accuracy: 0.8105\n",
      "Epoch 133/200\n",
      "191/191 [==============================] - 0s 444us/step - loss: 0.3893 - accuracy: 0.8117\n",
      "Epoch 134/200\n",
      "191/191 [==============================] - 0s 447us/step - loss: 0.3914 - accuracy: 0.8069\n",
      "Epoch 135/200\n",
      "191/191 [==============================] - 0s 439us/step - loss: 0.3942 - accuracy: 0.8074\n",
      "Epoch 136/200\n",
      "191/191 [==============================] - 0s 441us/step - loss: 0.3910 - accuracy: 0.8151\n",
      "Epoch 137/200\n",
      "191/191 [==============================] - 0s 429us/step - loss: 0.3976 - accuracy: 0.8076\n",
      "Epoch 138/200\n",
      "191/191 [==============================] - 0s 453us/step - loss: 0.3913 - accuracy: 0.8138\n",
      "Epoch 139/200\n",
      "191/191 [==============================] - 0s 437us/step - loss: 0.3942 - accuracy: 0.8092\n",
      "Epoch 140/200\n",
      "191/191 [==============================] - 0s 442us/step - loss: 0.3881 - accuracy: 0.8181\n",
      "Epoch 141/200\n",
      "191/191 [==============================] - 0s 484us/step - loss: 0.3946 - accuracy: 0.8097\n",
      "Epoch 142/200\n",
      "191/191 [==============================] - 0s 453us/step - loss: 0.3905 - accuracy: 0.8092\n",
      "Epoch 143/200\n",
      "191/191 [==============================] - 0s 439us/step - loss: 0.3912 - accuracy: 0.8105\n",
      "Epoch 144/200\n",
      "191/191 [==============================] - 0s 437us/step - loss: 0.3921 - accuracy: 0.8082\n",
      "Epoch 145/200\n",
      "191/191 [==============================] - 0s 442us/step - loss: 0.3915 - accuracy: 0.8148\n",
      "Epoch 146/200\n",
      "191/191 [==============================] - 0s 441us/step - loss: 0.3911 - accuracy: 0.8102\n",
      "Epoch 147/200\n",
      "191/191 [==============================] - 0s 448us/step - loss: 0.3897 - accuracy: 0.8100\n",
      "Epoch 148/200\n",
      "191/191 [==============================] - 0s 445us/step - loss: 0.3910 - accuracy: 0.8122\n",
      "Epoch 149/200\n",
      "191/191 [==============================] - 0s 435us/step - loss: 0.3909 - accuracy: 0.8136\n",
      "Epoch 150/200\n",
      "191/191 [==============================] - 0s 437us/step - loss: 0.3886 - accuracy: 0.8159\n",
      "Epoch 151/200\n",
      "191/191 [==============================] - 0s 444us/step - loss: 0.3958 - accuracy: 0.8067\n",
      "Epoch 152/200\n",
      "191/191 [==============================] - 0s 438us/step - loss: 0.3937 - accuracy: 0.8105\n",
      "Epoch 153/200\n",
      "191/191 [==============================] - 0s 437us/step - loss: 0.3932 - accuracy: 0.8105\n",
      "Epoch 154/200\n",
      "191/191 [==============================] - 0s 447us/step - loss: 0.3906 - accuracy: 0.8110\n",
      "Epoch 155/200\n",
      "191/191 [==============================] - 0s 443us/step - loss: 0.3930 - accuracy: 0.8099\n",
      "Epoch 156/200\n",
      "191/191 [==============================] - 0s 444us/step - loss: 0.3917 - accuracy: 0.8118\n",
      "Epoch 157/200\n",
      "191/191 [==============================] - 0s 439us/step - loss: 0.3905 - accuracy: 0.8136\n",
      "Epoch 158/200\n",
      "191/191 [==============================] - 0s 430us/step - loss: 0.3909 - accuracy: 0.8115\n",
      "Epoch 159/200\n",
      "191/191 [==============================] - 0s 454us/step - loss: 0.3873 - accuracy: 0.8104\n",
      "Epoch 160/200\n",
      "191/191 [==============================] - 0s 489us/step - loss: 0.3900 - accuracy: 0.8122\n",
      "Epoch 161/200\n",
      "191/191 [==============================] - 0s 462us/step - loss: 0.3899 - accuracy: 0.8104\n",
      "Epoch 162/200\n",
      "191/191 [==============================] - 0s 467us/step - loss: 0.3909 - accuracy: 0.8125\n",
      "Epoch 163/200\n",
      "191/191 [==============================] - 0s 460us/step - loss: 0.3874 - accuracy: 0.8102\n",
      "Epoch 164/200\n",
      "191/191 [==============================] - 0s 456us/step - loss: 0.3940 - accuracy: 0.8113\n",
      "Epoch 165/200\n",
      "191/191 [==============================] - 0s 463us/step - loss: 0.3880 - accuracy: 0.8133\n",
      "Epoch 166/200\n",
      "191/191 [==============================] - 0s 455us/step - loss: 0.3936 - accuracy: 0.8131\n",
      "Epoch 167/200\n",
      "191/191 [==============================] - 0s 462us/step - loss: 0.3934 - accuracy: 0.8097\n",
      "Epoch 168/200\n",
      "191/191 [==============================] - 0s 446us/step - loss: 0.3897 - accuracy: 0.8118\n",
      "Epoch 169/200\n",
      "191/191 [==============================] - 0s 431us/step - loss: 0.3889 - accuracy: 0.8145\n",
      "Epoch 170/200\n",
      "191/191 [==============================] - 0s 435us/step - loss: 0.3903 - accuracy: 0.8099\n",
      "Epoch 171/200\n",
      "191/191 [==============================] - 0s 434us/step - loss: 0.3897 - accuracy: 0.8108\n",
      "Epoch 172/200\n",
      "191/191 [==============================] - 0s 429us/step - loss: 0.3915 - accuracy: 0.8130\n",
      "Epoch 173/200\n",
      "191/191 [==============================] - 0s 435us/step - loss: 0.3899 - accuracy: 0.8153\n",
      "Epoch 174/200\n",
      "191/191 [==============================] - 0s 428us/step - loss: 0.3929 - accuracy: 0.8039\n",
      "Epoch 175/200\n",
      "191/191 [==============================] - 0s 448us/step - loss: 0.3886 - accuracy: 0.8053\n",
      "Epoch 176/200\n",
      "191/191 [==============================] - 0s 440us/step - loss: 0.3918 - accuracy: 0.8077\n",
      "Epoch 177/200\n",
      "191/191 [==============================] - 0s 442us/step - loss: 0.3942 - accuracy: 0.8089\n",
      "Epoch 178/200\n",
      "191/191 [==============================] - 0s 439us/step - loss: 0.3868 - accuracy: 0.8146\n",
      "Epoch 179/200\n",
      "191/191 [==============================] - 0s 442us/step - loss: 0.3895 - accuracy: 0.8090\n",
      "Epoch 180/200\n",
      "191/191 [==============================] - 0s 445us/step - loss: 0.3904 - accuracy: 0.8115\n",
      "Epoch 181/200\n",
      "191/191 [==============================] - 0s 439us/step - loss: 0.3895 - accuracy: 0.8128\n",
      "Epoch 182/200\n",
      "191/191 [==============================] - 0s 441us/step - loss: 0.3894 - accuracy: 0.8127\n",
      "Epoch 183/200\n",
      "191/191 [==============================] - 0s 435us/step - loss: 0.3893 - accuracy: 0.8117\n",
      "Epoch 184/200\n",
      "191/191 [==============================] - 0s 436us/step - loss: 0.3926 - accuracy: 0.8095\n",
      "Epoch 185/200\n",
      "191/191 [==============================] - 0s 428us/step - loss: 0.3890 - accuracy: 0.8125\n",
      "Epoch 186/200\n",
      "191/191 [==============================] - 0s 441us/step - loss: 0.3891 - accuracy: 0.8163\n",
      "Epoch 187/200\n",
      "191/191 [==============================] - 0s 433us/step - loss: 0.3891 - accuracy: 0.8143\n",
      "Epoch 188/200\n",
      "191/191 [==============================] - 0s 451us/step - loss: 0.3879 - accuracy: 0.8153\n",
      "Epoch 189/200\n",
      "191/191 [==============================] - 0s 444us/step - loss: 0.3875 - accuracy: 0.8127\n",
      "Epoch 190/200\n",
      "191/191 [==============================] - 0s 447us/step - loss: 0.3887 - accuracy: 0.8158\n",
      "Epoch 191/200\n",
      "191/191 [==============================] - 0s 441us/step - loss: 0.3912 - accuracy: 0.8081\n",
      "Epoch 192/200\n",
      "191/191 [==============================] - 0s 434us/step - loss: 0.3880 - accuracy: 0.8077\n",
      "Epoch 193/200\n",
      "191/191 [==============================] - 0s 435us/step - loss: 0.3875 - accuracy: 0.8148\n",
      "Epoch 194/200\n",
      "191/191 [==============================] - 0s 454us/step - loss: 0.3922 - accuracy: 0.8128\n",
      "Epoch 195/200\n",
      "191/191 [==============================] - 0s 437us/step - loss: 0.3887 - accuracy: 0.8097\n",
      "Epoch 196/200\n",
      "191/191 [==============================] - 0s 439us/step - loss: 0.3890 - accuracy: 0.8115\n",
      "Epoch 197/200\n",
      "191/191 [==============================] - 0s 438us/step - loss: 0.3872 - accuracy: 0.8140\n",
      "Epoch 198/200\n",
      "191/191 [==============================] - 0s 439us/step - loss: 0.3902 - accuracy: 0.8085\n",
      "Epoch 199/200\n",
      "191/191 [==============================] - 0s 433us/step - loss: 0.3861 - accuracy: 0.8113\n",
      "Epoch 200/200\n",
      "191/191 [==============================] - 0s 428us/step - loss: 0.3895 - accuracy: 0.8117\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x299e9f160>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "classifier = KerasClassifier(build_fn = build_classifier,\n",
    "                             optimizer=best_parameters['optimizer'],\n",
    "                             batch_size=best_parameters['batch_size'],\n",
    "                             epochs=best_parameters['epochs'])\n",
    "\n",
    "# , X_val, y_train, y_val\n",
    "# _X_train_scaled.shape, y_train.shape\n",
    "classifier.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3d1e67bc-0685-4096-8b73-10a70f12b71d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cabin_A_A</th>\n",
       "      <th>Cabin_A_B</th>\n",
       "      <th>Cabin_A_C</th>\n",
       "      <th>Cabin_A_D</th>\n",
       "      <th>Cabin_A_E</th>\n",
       "      <th>Cabin_A_F</th>\n",
       "      <th>Cabin_A_G</th>\n",
       "      <th>Cabin_A_T</th>\n",
       "      <th>Cabin_C_P</th>\n",
       "      <th>Cabin_C_S</th>\n",
       "      <th>HomePlanet_Earth</th>\n",
       "      <th>HomePlanet_Europa</th>\n",
       "      <th>HomePlanet_Mars</th>\n",
       "      <th>Destination_55 Cancri e</th>\n",
       "      <th>Destination_PSO J318.5-22</th>\n",
       "      <th>Destination_TRAPPIST-1e</th>\n",
       "      <th>PassengerId_A</th>\n",
       "      <th>PassengerId_B</th>\n",
       "      <th>traveling_in_group</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Age</th>\n",
       "      <th>CryoSleep_bool</th>\n",
       "      <th>VIP_bool</th>\n",
       "      <th>Cabin_B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.174191</td>\n",
       "      <td>-0.313741</td>\n",
       "      <td>-0.306610</td>\n",
       "      <td>-0.241218</td>\n",
       "      <td>-0.334759</td>\n",
       "      <td>-0.724629</td>\n",
       "      <td>1.548235</td>\n",
       "      <td>-0.02399</td>\n",
       "      <td>-0.968181</td>\n",
       "      <td>0.968181</td>\n",
       "      <td>0.899950</td>\n",
       "      <td>-0.569867</td>\n",
       "      <td>-0.503664</td>\n",
       "      <td>-0.511013</td>\n",
       "      <td>-0.317487</td>\n",
       "      <td>0.652521</td>\n",
       "      <td>-1.729916</td>\n",
       "      <td>-0.491161</td>\n",
       "      <td>-0.899532</td>\n",
       "      <td>-0.333105</td>\n",
       "      <td>-0.281027</td>\n",
       "      <td>-0.283579</td>\n",
       "      <td>-0.270626</td>\n",
       "      <td>-0.263003</td>\n",
       "      <td>-1.274865e-01</td>\n",
       "      <td>1.364685</td>\n",
       "      <td>-0.153063</td>\n",
       "      <td>-1.180681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.174191</td>\n",
       "      <td>-0.313741</td>\n",
       "      <td>-0.306610</td>\n",
       "      <td>-0.241218</td>\n",
       "      <td>-0.334759</td>\n",
       "      <td>1.380016</td>\n",
       "      <td>-0.645897</td>\n",
       "      <td>-0.02399</td>\n",
       "      <td>-0.968181</td>\n",
       "      <td>0.968181</td>\n",
       "      <td>0.899950</td>\n",
       "      <td>-0.569867</td>\n",
       "      <td>-0.503664</td>\n",
       "      <td>-0.511013</td>\n",
       "      <td>-0.317487</td>\n",
       "      <td>0.652521</td>\n",
       "      <td>-1.728044</td>\n",
       "      <td>-0.491161</td>\n",
       "      <td>-0.899532</td>\n",
       "      <td>-0.333105</td>\n",
       "      <td>-0.275387</td>\n",
       "      <td>-0.283579</td>\n",
       "      <td>2.237598</td>\n",
       "      <td>-0.263003</td>\n",
       "      <td>-6.854354e-01</td>\n",
       "      <td>-0.732770</td>\n",
       "      <td>-0.153063</td>\n",
       "      <td>-1.178704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.174191</td>\n",
       "      <td>-0.313741</td>\n",
       "      <td>3.261474</td>\n",
       "      <td>-0.241218</td>\n",
       "      <td>-0.334759</td>\n",
       "      <td>-0.724629</td>\n",
       "      <td>-0.645897</td>\n",
       "      <td>-0.02399</td>\n",
       "      <td>-0.968181</td>\n",
       "      <td>0.968181</td>\n",
       "      <td>-1.111173</td>\n",
       "      <td>1.754795</td>\n",
       "      <td>-0.503664</td>\n",
       "      <td>1.956897</td>\n",
       "      <td>-0.317487</td>\n",
       "      <td>-1.532519</td>\n",
       "      <td>-1.727669</td>\n",
       "      <td>-0.491161</td>\n",
       "      <td>-0.899532</td>\n",
       "      <td>-0.333105</td>\n",
       "      <td>-0.281027</td>\n",
       "      <td>-0.283579</td>\n",
       "      <td>-0.270626</td>\n",
       "      <td>-0.263003</td>\n",
       "      <td>1.514880e-01</td>\n",
       "      <td>1.364685</td>\n",
       "      <td>-0.153063</td>\n",
       "      <td>-1.186610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.174191</td>\n",
       "      <td>-0.313741</td>\n",
       "      <td>3.261474</td>\n",
       "      <td>-0.241218</td>\n",
       "      <td>-0.334759</td>\n",
       "      <td>-0.724629</td>\n",
       "      <td>-0.645897</td>\n",
       "      <td>-0.02399</td>\n",
       "      <td>-0.968181</td>\n",
       "      <td>0.968181</td>\n",
       "      <td>-1.111173</td>\n",
       "      <td>1.754795</td>\n",
       "      <td>-0.503664</td>\n",
       "      <td>-0.511013</td>\n",
       "      <td>-0.317487</td>\n",
       "      <td>0.652521</td>\n",
       "      <td>-1.726921</td>\n",
       "      <td>-0.491161</td>\n",
       "      <td>-0.899532</td>\n",
       "      <td>-0.333105</td>\n",
       "      <td>3.887680</td>\n",
       "      <td>-0.283579</td>\n",
       "      <td>-0.109808</td>\n",
       "      <td>0.252842</td>\n",
       "      <td>6.396933e-01</td>\n",
       "      <td>-0.732770</td>\n",
       "      <td>-0.153063</td>\n",
       "      <td>-1.184634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.174191</td>\n",
       "      <td>-0.313741</td>\n",
       "      <td>-0.306610</td>\n",
       "      <td>-0.241218</td>\n",
       "      <td>-0.334759</td>\n",
       "      <td>1.380016</td>\n",
       "      <td>-0.645897</td>\n",
       "      <td>-0.02399</td>\n",
       "      <td>-0.968181</td>\n",
       "      <td>0.968181</td>\n",
       "      <td>0.899950</td>\n",
       "      <td>-0.569867</td>\n",
       "      <td>-0.503664</td>\n",
       "      <td>-0.511013</td>\n",
       "      <td>-0.317487</td>\n",
       "      <td>0.652521</td>\n",
       "      <td>-1.726172</td>\n",
       "      <td>-0.491161</td>\n",
       "      <td>-0.899532</td>\n",
       "      <td>-0.317964</td>\n",
       "      <td>-0.281027</td>\n",
       "      <td>0.778343</td>\n",
       "      <td>-0.270626</td>\n",
       "      <td>-0.263003</td>\n",
       "      <td>-6.156918e-01</td>\n",
       "      <td>-0.732770</td>\n",
       "      <td>-0.153063</td>\n",
       "      <td>-1.176728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4272</th>\n",
       "      <td>-0.174191</td>\n",
       "      <td>-0.313741</td>\n",
       "      <td>-0.306610</td>\n",
       "      <td>-0.241218</td>\n",
       "      <td>-0.334759</td>\n",
       "      <td>-0.724629</td>\n",
       "      <td>1.548235</td>\n",
       "      <td>-0.02399</td>\n",
       "      <td>-0.968181</td>\n",
       "      <td>0.968181</td>\n",
       "      <td>0.899950</td>\n",
       "      <td>-0.569867</td>\n",
       "      <td>-0.503664</td>\n",
       "      <td>-0.511013</td>\n",
       "      <td>-0.317487</td>\n",
       "      <td>0.652521</td>\n",
       "      <td>1.734492</td>\n",
       "      <td>0.457443</td>\n",
       "      <td>1.111690</td>\n",
       "      <td>-0.333105</td>\n",
       "      <td>-0.281027</td>\n",
       "      <td>-0.283579</td>\n",
       "      <td>-0.270626</td>\n",
       "      <td>-0.263003</td>\n",
       "      <td>3.607188e-01</td>\n",
       "      <td>1.364685</td>\n",
       "      <td>-0.153063</td>\n",
       "      <td>1.770234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4273</th>\n",
       "      <td>-0.174191</td>\n",
       "      <td>-0.313741</td>\n",
       "      <td>-0.306610</td>\n",
       "      <td>-0.241218</td>\n",
       "      <td>-0.334759</td>\n",
       "      <td>1.380016</td>\n",
       "      <td>-0.645897</td>\n",
       "      <td>-0.02399</td>\n",
       "      <td>-0.968181</td>\n",
       "      <td>0.968181</td>\n",
       "      <td>0.899950</td>\n",
       "      <td>-0.569867</td>\n",
       "      <td>-0.503664</td>\n",
       "      <td>-0.511013</td>\n",
       "      <td>-0.317487</td>\n",
       "      <td>0.652521</td>\n",
       "      <td>1.735615</td>\n",
       "      <td>-0.491161</td>\n",
       "      <td>-0.899532</td>\n",
       "      <td>-0.333105</td>\n",
       "      <td>0.249775</td>\n",
       "      <td>-0.255149</td>\n",
       "      <td>-0.261741</td>\n",
       "      <td>-0.136026</td>\n",
       "      <td>9.186678e-01</td>\n",
       "      <td>-0.732770</td>\n",
       "      <td>-0.153063</td>\n",
       "      <td>0.019055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4274</th>\n",
       "      <td>-0.174191</td>\n",
       "      <td>-0.313741</td>\n",
       "      <td>-0.306610</td>\n",
       "      <td>4.145623</td>\n",
       "      <td>-0.334759</td>\n",
       "      <td>-0.724629</td>\n",
       "      <td>-0.645897</td>\n",
       "      <td>-0.02399</td>\n",
       "      <td>1.032865</td>\n",
       "      <td>-1.032865</td>\n",
       "      <td>-1.111173</td>\n",
       "      <td>-0.569867</td>\n",
       "      <td>1.985450</td>\n",
       "      <td>1.956897</td>\n",
       "      <td>-0.317487</td>\n",
       "      <td>-1.532519</td>\n",
       "      <td>1.736364</td>\n",
       "      <td>-0.491161</td>\n",
       "      <td>-0.899532</td>\n",
       "      <td>-0.333105</td>\n",
       "      <td>-0.281027</td>\n",
       "      <td>-0.283579</td>\n",
       "      <td>-0.270626</td>\n",
       "      <td>-0.263003</td>\n",
       "      <td>-2.477791e-16</td>\n",
       "      <td>1.364685</td>\n",
       "      <td>-0.153063</td>\n",
       "      <td>-0.601566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4275</th>\n",
       "      <td>-0.174191</td>\n",
       "      <td>-0.313741</td>\n",
       "      <td>-0.306610</td>\n",
       "      <td>4.145623</td>\n",
       "      <td>-0.334759</td>\n",
       "      <td>-0.724629</td>\n",
       "      <td>-0.645897</td>\n",
       "      <td>-0.02399</td>\n",
       "      <td>1.032865</td>\n",
       "      <td>-1.032865</td>\n",
       "      <td>-1.111173</td>\n",
       "      <td>1.754795</td>\n",
       "      <td>-0.503664</td>\n",
       "      <td>-0.511013</td>\n",
       "      <td>-0.317487</td>\n",
       "      <td>0.652521</td>\n",
       "      <td>1.737112</td>\n",
       "      <td>-0.491161</td>\n",
       "      <td>-0.899532</td>\n",
       "      <td>-0.333105</td>\n",
       "      <td>1.398488</td>\n",
       "      <td>-0.283579</td>\n",
       "      <td>-0.270626</td>\n",
       "      <td>0.198171</td>\n",
       "      <td>-2.477791e-16</td>\n",
       "      <td>-0.732770</td>\n",
       "      <td>-0.153063</td>\n",
       "      <td>-0.599590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4276</th>\n",
       "      <td>-0.174191</td>\n",
       "      <td>-0.313741</td>\n",
       "      <td>-0.306610</td>\n",
       "      <td>-0.241218</td>\n",
       "      <td>-0.334759</td>\n",
       "      <td>-0.724629</td>\n",
       "      <td>1.548235</td>\n",
       "      <td>-0.02399</td>\n",
       "      <td>-0.968181</td>\n",
       "      <td>0.968181</td>\n",
       "      <td>0.899950</td>\n",
       "      <td>-0.569867</td>\n",
       "      <td>-0.503664</td>\n",
       "      <td>-0.511013</td>\n",
       "      <td>3.149739</td>\n",
       "      <td>-1.532519</td>\n",
       "      <td>1.738610</td>\n",
       "      <td>-0.491161</td>\n",
       "      <td>-0.899532</td>\n",
       "      <td>-0.333105</td>\n",
       "      <td>-0.281027</td>\n",
       "      <td>-0.283579</td>\n",
       "      <td>-0.270626</td>\n",
       "      <td>-0.263003</td>\n",
       "      <td>9.884114e-01</td>\n",
       "      <td>1.364685</td>\n",
       "      <td>-0.153063</td>\n",
       "      <td>1.774187</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4277 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Cabin_A_A  Cabin_A_B  Cabin_A_C  Cabin_A_D  Cabin_A_E  Cabin_A_F  \\\n",
       "0     -0.174191  -0.313741  -0.306610  -0.241218  -0.334759  -0.724629   \n",
       "1     -0.174191  -0.313741  -0.306610  -0.241218  -0.334759   1.380016   \n",
       "2     -0.174191  -0.313741   3.261474  -0.241218  -0.334759  -0.724629   \n",
       "3     -0.174191  -0.313741   3.261474  -0.241218  -0.334759  -0.724629   \n",
       "4     -0.174191  -0.313741  -0.306610  -0.241218  -0.334759   1.380016   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "4272  -0.174191  -0.313741  -0.306610  -0.241218  -0.334759  -0.724629   \n",
       "4273  -0.174191  -0.313741  -0.306610  -0.241218  -0.334759   1.380016   \n",
       "4274  -0.174191  -0.313741  -0.306610   4.145623  -0.334759  -0.724629   \n",
       "4275  -0.174191  -0.313741  -0.306610   4.145623  -0.334759  -0.724629   \n",
       "4276  -0.174191  -0.313741  -0.306610  -0.241218  -0.334759  -0.724629   \n",
       "\n",
       "      Cabin_A_G  Cabin_A_T  Cabin_C_P  Cabin_C_S  HomePlanet_Earth  \\\n",
       "0      1.548235   -0.02399  -0.968181   0.968181          0.899950   \n",
       "1     -0.645897   -0.02399  -0.968181   0.968181          0.899950   \n",
       "2     -0.645897   -0.02399  -0.968181   0.968181         -1.111173   \n",
       "3     -0.645897   -0.02399  -0.968181   0.968181         -1.111173   \n",
       "4     -0.645897   -0.02399  -0.968181   0.968181          0.899950   \n",
       "...         ...        ...        ...        ...               ...   \n",
       "4272   1.548235   -0.02399  -0.968181   0.968181          0.899950   \n",
       "4273  -0.645897   -0.02399  -0.968181   0.968181          0.899950   \n",
       "4274  -0.645897   -0.02399   1.032865  -1.032865         -1.111173   \n",
       "4275  -0.645897   -0.02399   1.032865  -1.032865         -1.111173   \n",
       "4276   1.548235   -0.02399  -0.968181   0.968181          0.899950   \n",
       "\n",
       "      HomePlanet_Europa  HomePlanet_Mars  Destination_55 Cancri e  \\\n",
       "0             -0.569867        -0.503664                -0.511013   \n",
       "1             -0.569867        -0.503664                -0.511013   \n",
       "2              1.754795        -0.503664                 1.956897   \n",
       "3              1.754795        -0.503664                -0.511013   \n",
       "4             -0.569867        -0.503664                -0.511013   \n",
       "...                 ...              ...                      ...   \n",
       "4272          -0.569867        -0.503664                -0.511013   \n",
       "4273          -0.569867        -0.503664                -0.511013   \n",
       "4274          -0.569867         1.985450                 1.956897   \n",
       "4275           1.754795        -0.503664                -0.511013   \n",
       "4276          -0.569867        -0.503664                -0.511013   \n",
       "\n",
       "      Destination_PSO J318.5-22  Destination_TRAPPIST-1e  PassengerId_A  \\\n",
       "0                     -0.317487                 0.652521      -1.729916   \n",
       "1                     -0.317487                 0.652521      -1.728044   \n",
       "2                     -0.317487                -1.532519      -1.727669   \n",
       "3                     -0.317487                 0.652521      -1.726921   \n",
       "4                     -0.317487                 0.652521      -1.726172   \n",
       "...                         ...                      ...            ...   \n",
       "4272                  -0.317487                 0.652521       1.734492   \n",
       "4273                  -0.317487                 0.652521       1.735615   \n",
       "4274                  -0.317487                -1.532519       1.736364   \n",
       "4275                  -0.317487                 0.652521       1.737112   \n",
       "4276                   3.149739                -1.532519       1.738610   \n",
       "\n",
       "      PassengerId_B  traveling_in_group  RoomService  FoodCourt  ShoppingMall  \\\n",
       "0         -0.491161           -0.899532    -0.333105  -0.281027     -0.283579   \n",
       "1         -0.491161           -0.899532    -0.333105  -0.275387     -0.283579   \n",
       "2         -0.491161           -0.899532    -0.333105  -0.281027     -0.283579   \n",
       "3         -0.491161           -0.899532    -0.333105   3.887680     -0.283579   \n",
       "4         -0.491161           -0.899532    -0.317964  -0.281027      0.778343   \n",
       "...             ...                 ...          ...        ...           ...   \n",
       "4272       0.457443            1.111690    -0.333105  -0.281027     -0.283579   \n",
       "4273      -0.491161           -0.899532    -0.333105   0.249775     -0.255149   \n",
       "4274      -0.491161           -0.899532    -0.333105  -0.281027     -0.283579   \n",
       "4275      -0.491161           -0.899532    -0.333105   1.398488     -0.283579   \n",
       "4276      -0.491161           -0.899532    -0.333105  -0.281027     -0.283579   \n",
       "\n",
       "           Spa    VRDeck           Age  CryoSleep_bool  VIP_bool   Cabin_B  \n",
       "0    -0.270626 -0.263003 -1.274865e-01        1.364685 -0.153063 -1.180681  \n",
       "1     2.237598 -0.263003 -6.854354e-01       -0.732770 -0.153063 -1.178704  \n",
       "2    -0.270626 -0.263003  1.514880e-01        1.364685 -0.153063 -1.186610  \n",
       "3    -0.109808  0.252842  6.396933e-01       -0.732770 -0.153063 -1.184634  \n",
       "4    -0.270626 -0.263003 -6.156918e-01       -0.732770 -0.153063 -1.176728  \n",
       "...        ...       ...           ...             ...       ...       ...  \n",
       "4272 -0.270626 -0.263003  3.607188e-01        1.364685 -0.153063  1.770234  \n",
       "4273 -0.261741 -0.136026  9.186678e-01       -0.732770 -0.153063  0.019055  \n",
       "4274 -0.270626 -0.263003 -2.477791e-16        1.364685 -0.153063 -0.601566  \n",
       "4275 -0.270626  0.198171 -2.477791e-16       -0.732770 -0.153063 -0.599590  \n",
       "4276 -0.270626 -0.263003  9.884114e-01        1.364685 -0.153063  1.774187  \n",
       "\n",
       "[4277 rows x 28 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_X_test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3bfd1bd2-89c2-44fc-91b1-9764e4d8dca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 0s 280us/step\n"
     ]
    }
   ],
   "source": [
    "# y_pred_best_model\n",
    "y_pred_neural_network_gs_cv_pred = classifier.predict(_X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "4aa6ac88-4c82-484d-bf24-d57289ffe3c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       ...,\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_neural_network_gs_cv_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "35cc47c4-aadc-459b-a68a-0a368c953542",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_neural_network_gs_cv_pred = [x[0] for x in y_pred_neural_network_gs_cv_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "839bffce-c0f3-4a15-890d-734452d5afc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred_best_model = [True if x>.6 else False for x in y_pred_best_model]\n",
    "y_pred_best_model_df = pd.DataFrame({'Transported':y_pred_neural_network_gs_cv_pred, 'PassengerId':_X_test['PassengerId']})\n",
    "y_pred_best_model_df['Transported'].value_counts()\n",
    "\n",
    "y_pred_best_model_df.to_csv('./kaggle/input/spaceship-titanic/neural_network_gs_cv_pred.csv', index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a2a71c48-edf7-4034-9d56-a55577dc9849",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Transported</th>\n",
       "      <th>PassengerId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>0013_01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>0018_01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>0019_01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>0021_01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>0023_01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4272</th>\n",
       "      <td>False</td>\n",
       "      <td>9266_02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4273</th>\n",
       "      <td>False</td>\n",
       "      <td>9269_01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4274</th>\n",
       "      <td>True</td>\n",
       "      <td>9271_01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4275</th>\n",
       "      <td>True</td>\n",
       "      <td>9273_01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4276</th>\n",
       "      <td>False</td>\n",
       "      <td>9277_01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4277 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Transported PassengerId\n",
       "0          False     0013_01\n",
       "1          False     0018_01\n",
       "2           True     0019_01\n",
       "3           True     0021_01\n",
       "4          False     0023_01\n",
       "...          ...         ...\n",
       "4272       False     9266_02\n",
       "4273       False     9269_01\n",
       "4274        True     9271_01\n",
       "4275        True     9273_01\n",
       "4276       False     9277_01\n",
       "\n",
       "[4277 rows x 2 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_best_model_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470d9508-af9e-4d3b-a5a2-dbb5f27e0f3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lewagon3",
   "language": "python",
   "name": "lewagon3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
